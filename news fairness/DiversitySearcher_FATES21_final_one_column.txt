Fairness beyond “equal”: The Diversity Searcher as a Tool to Detect and
Enhance the Representation of Socio-political Actors in News Media
Bettina Berendt
TU Berlin, Weizenbaum Institute, and KU Leuven, bettina.berendt@kuleuven.be

ÖZGÜR KARADENIZ
Dept. Computer Science, KU Leuven, oguzozgur.karadeniz@kuleuven.be

STEFAN MERTENS
Institute for Media Studies, KU Leuven, stefan.mertens@kuleuven.be

LEEN D’HAENENS
Institute for Media Studies, KU Leuven, leen.dhaenens@kuleuven.be
“Fairness” is a multi-faceted concept that is contested within and across disciplines. In machine learning, it usually denotes
some form of equality of measurable outcomes of algorithmic decision making. In this paper, we start from a viewpoint of
sociology and media studies, which highlights that to even claim fair treatment, individuals and groups first have to be
visible. We draw on a notion and a quantitative measure of diversity that expresses this wider requirement. We used the
measure to design and build the Diversity Searcher, a Web-based tool to detect and enhance the representation of sociopolitical actors in news media. We show how the tool’s combination of natural language processing and a rich user interface
can help news producers and consumers detect and understand diversity-relevant aspects of representation, which can
ultimately contribute to enhancing diversity and fairness in media. We comment on our observation that, through
interactions with target users during the construction of the tool, NLP results and interface questions became increasingly
important, such that the formal measure of diversity has become a catalyst for functionality, but in itself less important.
CCS CONCEPTS • Information systems ➝Information Retrieval ➝Content analysis and feature selection •

Applied computing ➝Law, social and behavioral sciences ➝Sociology • Applied computing ➝Computers in
other domains ➝Publishing
Additional Keywords and Phrases:Fairness-aware recommender systems and diversity in

recommendation, Innovative methods for studying/analyzing the fairness / accountability /
transparency and ethics of web platforms, Usability challenges of machine learning
1 INTRODUCTION
“Fairness” is a multi-faceted and contested concept. In machine learning, it most often refers to some form of
equality of measurable outcomes of algorithmic decision-making, where all components of the definition,

including what exactly should be equal (or diverge by only a small quantity) are being disputed [40, 19].
However, classifications of people into (e.g.) “protected group” and “unprotected group” and the equalisation
of some measures of outcomes or natural-language associations that dominate the AI fairness literature can
only capture some aspects of a wider notion of distributive justice [7]. In the present paper, we argue that a
key prerequisite for being treated fairly in this sense is that an individual or group has to “exist”, to be
perceived. We investigate a formalisation of diversity that encompasses these two ideas by modelling both
distribution and (prior to this) inclusion. We present the Diversity Searcher, a tool that helps investigate these
questions by analysing diversity in news media texts.
The concepts of pluralism and diversity are quite established in the literature. While pluralism refers to the
normative orientation of a media landscape and the democratic role of journalism, diversity is considered as a
measure of heterogeneity of the various media outlets in that media landscape, e.g. [20]. Napoli [26, 27]
proposed a threefold approach to information diversity: source diversity (referring to media ownership and
outlets), content diversity (i.e. formats and viewpoints), and exposure diversity. The latter addresses either the
variety of information provided by different outlets available to consumers (horizontal diversity) or the variety
of information provided by a single media outlet (vertical diversity). The journalism imperative of news
diversity is its “multi-perspectivality” [15]. Comparing journalism in the US and France, Benson [4] remarks
that ‘balance’ is the most used word in the US, whereas ‘polyphony’ is more incorporated in the French
debate on what journalism ought to be. Nevertheless, both notions echo the same journalism imperative: as
people rely on media to make their political decisions, it is important that they are exposed to a wide range of
possible perspectives. This supply of diverse perspectives is the key support for the very idea of democracy
itself. As governance is controlled by the people, they should be well-informed. Building further on Napoli’s
content diversity, with a focus on viewpoint diversity, and from our concern for increased exposure diversity,
we argue that while our ultimate goal is a depth of text understanding that is (certainly today) beyond the limits
of machines, Natural Language Processing (NLP) techniques together with metrics akin to fairness metrics
and rich human-computer interfaces can help news media producers and news consumers achieve this goal.
The Diversity Searcher is a Web-based tool for the analysis and comparison of news media texts. It
currently works on English-language and Dutch-language texts, and it is generalizable to other languages. It
identifies socio-political actors in text via techniques for named-entity recognition, enhanced by techniques for
1
the recognition of unnamed entities .
Our design rests on two approaches: (a) a quantitative measure of content diversity (as a more
comprehensive notion that encompasses aspects of fairness, and that is often a prerequisite for fairness), and
(b) the provision of a rich user interface that allows news producers and news consumers to explore a text
with regards to who is present / represented, and how different they are from one another. The tool provides
the user many means of customization of its ontology, making it possible to adapt to new domains and entity
types. This design also aims to alleviate the possible bias in crowdsourced data, models and classification
based on them by letting the user have a say in the information the tool produces.

1

Further context and materials of DIAMOND (Diversity and Information Media: New Tools for a
Multifaceted Public Debate) can be found at https://soc.kuleuven.be/fsw/diamond

2

2 AN EXAMPLE: HOW TO APPROACH FAIRNESS AND DIVERSITY IN A NEWS TEXT?
Our enhanced notion of fairness (i.e., our conception of diversity) is best explained with an example, taken
from a blog post by Khadijah Abdurahman [1]:
“If demands for corporate transparency crystalized in the Standing with Dr. Timnit Gebru Petition defines
the horizon for tech worker resistance, we are doomed. […] We need a radical reframing away from the lone
researcher against Goliath, to reckon with the failure of the Fairness, Accountability, Transparency and
broader ethics frameworks that have allowed opportunists to build their brand, taking up the space required to
address the core issues of Big Tech’s hegemonic violence as described in Timnit [and colleagues]’s paper.
We must support Timnit and acknowledge that support isn’t enough. I appreciate the amount of public support
Timnit Gebru has received from the professional community but real friends tell each other that representation
politics of the urban elite are not adequate […] We’re ruminating about Jeff Dean’s feelings instead of building
a cross class labor movement that defines tech workers broadly, ie researchers, engineers, Uber drivers,
Amazon warehouse workers, content moderators etc. […] You people […] with your AI resistance headbands
on, with access to capital [:] refugees, the homeless, the policed etc are for better or worse counting on you
and you’re out here talking about corporate diversity.” [1]
The event around which this blogpost revolves is the termination of researcher Timnit Gebru’s work
contract at Google (Google’s firing her for some, her resignation for others) in December 2020. The event was
widely perceived as relevant for the AI fairness (and ethics in general) discussion, since Gebru was
presumably hired in large parts for her achievements in fairness, accountability and transparency research,
but then met resistance in her efforts to increase recruitment of people of colour into the company as well as
in the submission of a research paper on shortcomings in Big Tech’s real-life dealings with fairness in the
software they deploy. The blogpost, however, does more than this. It questions core assumptions in the
(Twitter mainstream) discussion of the event. It reminds us that fairness itself is often debated from the
privileged standpoint of an “urban elite” of engineers and it calls for a broader notion of “tech workers” as well
as the inclusion of marginalised groups as key indirect stakeholders. It criticises “representation politics” as
too narrow by pushing the representation – in the discourse – of those oft-forgotten stakeholders.
The text is complex, requiring background knowledge of the case, the academic field, and the current techcorporation environment. Its argument probably eludes current AI’s/NLP’s capacities for language
understanding. However, as we will show, NLP can capture the facts that the text (a) contains mentions not
only of Timnit Gebru, Jeff Dean, and tech workers (like many other articles on the event), but also of Uber
drivers, Amazon warehouse workers, refugees, and homeless people. Not only are these latter groups of
people often absent in news texts, but (b) they are also more distinct from the former individuals and groups
than these (Gebru, Dean, tech workers in the often-used sense of researchers and engineers) are among
themselves. Of course, this claim of distinctness may be debated, and the formal definition of “being distinct”
needs to be motivated, discussed, and probably contested.
One can go further and observe (or claim) that (c) a text in which these different individuals and groups
take up “equal space” would, all else being equal, be more balanced and more fair in the sense of a more
uniform distribution of attention.
Aspects (a)-(c) identify three components of the definition of diversity that we use in the Diversity Searcher
and that we explain in Section 3.4.

3

3 BACKGROUND AND RELATED WORK
The Diversity Searcher is based on work around diversity in media texts, computational tools in media studies
and journalism, NLP methods, in particular NER and NEL, and the formalisation of diversity.
3.1 Media texts and diversity
As stated in the introduction, in order to be treated fairly, people and groups first need to exist and be
perceived. Bourdieu [8] argues that the categories through which social agents exist and are known is an
issue of continuous political struggle over knowledge of the social world:
“[T]his work of categorisation, i.e., of making- explicit and of classification, is performed incessantly, at
every moment of ordinary existence, in the struggles in which agents clash over the meaning of the social
world and of their position within it.” [8]
According to Bourdieu, the social world is organised according to the logic of difference in terms of the
properties and their distributions subject to this struggle, making it a symbolic system like language. At the
same time, the social world is a topology where agents take positions within various semi-autonomous fields
constituting it, giving socio-political differences with respect to these properties and symbolic capitals the
spatial quality of distinction. Agents’ symbolic power, understood as the power to produce and impose
classifications, depends on their position in the social world as well as the classifications inscribed in that
position [8]. It follows that the categorisation of social actors is simultaneously political, symbolic (assigning
meaning) and spatial (distinction based on properties). It is important to emphasise that agents or fields are
not equally powerful in this production of meanings, with the political field and the field of cultural production
(including media) having privilege [14].
3.2 Computational Tools in Media Studies
Traditionally used for automation of tasks for which humans are inefficient, computational methods can now
be used for insight driven research questions [28]. Their contemporary usage in media studies include
automatic fact checking, topic detection, analysis of (fake) news dissemination, detection of certain types of
discourses such as hate speech, ad hominem, irony, e.g. [9, 3, 11, 38]. Media monitoring projects such as
2

3

GDELT and Europe Media Monitor , which periodically monitor traditional and social media and produce
impressive data sets with the extracted information, are another application class relevant to media studies
4

[16, 13]. For the issue of diversity, the NLP tool Gender Meme [17] and the commercial service CeretAI [10]
focus on digital analysis of content in terms gender representation. Both tools aim to answer the question
“who is speaking”, rather than “who is present”. Gender Meme achieves this by counting how many words are
quoted from each gendered individual in a text [18]. CeretAI offers a similar analysis, but on audio-visual
media [10].
While gender is a crucial aspect of diversity, our focus on socio-political actors required us to include entity
types (organizations, geopolitical entities) for which gender is not applicable as it is for individuals. Other
socio-politically relevant features such as party membership or ideology needed to be included. This focus on

2

https://www.gdeltproject.org/
https://emm.newsbrief.eu/overview.html
4
https://www.gendermeme.org/
3

4

socio-political actors and features necessitated implementing actor detection and classification, to which we
will turn next.
3.3 NER and NEL in actor detection and classification
Our task specifically involves measuring actor diversity. This requires, first of all, recognizing them in a news
text. One approach that is potentially suitable for this task is Named Entity Recognition (NER). NER refers to
the task of recognition and classification of information units in a text into a set of entities [21, 25]. Existing
applications typically also perform a coarse-grained classification with categories such as person, geopolitical
entity and organisation entities [21].
While a coarse-grained classification is a good start for analysing diversity, it is not sufficient for our chosen
field of socio-political actors, as actors of the same type may have very disparate positions in the sociopolitical field. This is further complicated by the fact that actors in news texts are not always named entities.
For example, a language model could identify Donald Trump correctly as a “Person”, but would treat him as
having a disparity of 0 with Joe Biden despite very different political positions, and not recognise “immigrant”
as an actor at all.
This problem was addressed in an earlier version of our tool, which used a rich hierarchical ontology with
235 nodes and 176 leaves to represent diversity in named and unnamed socio-political actors [30]. This
ontology was based on annotations, by social scientists, on a corpus of 580 news articles. The ontology was
imbalanced and fine-grained. The previous version of the tool addressed this by flattening and pruning the
ontology, resulting in relatively high F1 scores for some categories. More fine-grained classifications have
been proposed in different work, e.g. [12, 22]. However, there is no agreement yet in this field on techniques
[30].
A related approach is Name Entity Linking (NEL), the process of linking entities to a knowledge base. An
NEL pipeline typically includes spotting entities, determining candidates, and named entity disambiguation,
which refers to mapping mentions in the document to the real world entities based on a ranking of candidates
[23, 32]. These steps make NEL an important subtask of tasks like knowledge base population and
information retrieval [32].
The knowledge bases used in NEL are typically crowdsourced linked open databases such as Wikidata
and DBpedia. These knowledge bases are often structured in accordance with semantic web principles in the
form of graphs of RDF triples [6]. URIs resulting from the disambiguation make it possible to enrich the
entities with the data retrieved from the knowledge graph. This data can then be used to summarise features
of the entities that are relevant to the domain in order to formulate feedback to the user about the text. Similar
5
6
enrichment tools that can be used for journalistic tasks exist, such as Open Calais [29] and Enrycher [35] ,
yet they are more general-purpose, as their focus is not on socio-political entities or diversity.
3.4 A quantitative measure of diversity
Once actors (or other entities) have been identified, one can investigate how diverse the entities in a given
text are. The question is how to measure such diversity. This question has been investigated in a wide set of

5
6

https://developers.refinitiv.com/en/api-catalog/open-perm-id/intelligent-tagging-restful-api
https://ailab.ijs.si/tools/enrycher/

5

domains including ecology, physical, social, life and information sciences, economic and policy studies,
communication, and cultural analysis [36, 31]. For our measure, we draw on an influential proposal of a
quantitative measure that draws on a meta-analysis of this wider literature. Andy Stirling identified three
components, which all enhance diversity [36]:
Variety: many distinct entities are present, e.g. a number of people of different backgrounds in mix;
-

Disparity: the entities are different from one another, they come from a wide range;
Balance: the different entities are evenly distributed. This component is a simple form of the “equality

of …” concept found in the fairness literature.
Stirling further proposed a simple formula for capturing these three components. Diversity Δ is defined as

with variety being captured by the cardinality of the set of all entities i, j ∈ E present in the domain (e.g. a
text, a population, …), balance by the frequencies pi (the more uniform the distribution, the higher this
multiplicative factor), and disparity by a measure of distance or dissimilarity d(.,.). In addition, the parameters
α and β allow for a weighting of the importance of balance or disparity.
Stirling’s formula captures all three elements of diversity as well as the requirements of our first two subgoals (a) and (b), derived at the end of Section 2. Variety measures how wide the inclusion is, disparity grows
with the variety of included people, and balance measures the equality of the distribution, i.e. our third subgoal (c).
More recent work has proposed different operationalisations of variety, disparity, balance, and/or the way
in which they should be combined mathematically, e.g. [37]. Since to the best of our knowledge, there are no
theoretical investigations of whether other measures than the basic form by Stirling are better suited to
measuring diversity in news texts, we employed the basic form.
We treat named (and unnamed) entities in the text as our set E. More specifically, we focus on sociopolitical actors. As Beckers and Van Aelst [2] point out, there is no consensus on their classification into types.
The term ‘actor’ broadly refers to entities with social agency; encompassing individuals, organisations, and
nation states [24].
Variety is then straightforwardly defined via those entities that the tool (with possible user help) can identify
as actors. Balance is equally straightforward, derived from the counts of these entities considered as
frequencies. Disparity, however, presents interesting challenges. We operationalise it with respect to an
ontology and a dissimilarity measure defined on it. This will be described in the subsequent section.
The absolute value of this diversity measure (unless it is 0 or 1) is not meaningful and should therefore not
be interpreted. It can be useful to compare different inputs (such as, in our case, texts), but also ordinal
interpretations should keep in mind that the difference can arise from the three components disparity, variety
and balance. This is one of the reasons why a black-box tool that only outputs a diversity score would not be
useful in our domain.

6

4 THE DISPARITY OF SOCIO-POLITICAL ACTORS
7

The Diversity Searcher identifies socio-political actors in text via techniques for named-entity recognition and
named entity linking, enhanced by techniques for the recognition of unnamed entities (an example in Section
2 are “tech workers”). For this, it relies on a well-established methodology and off-the-shelf NLP tools.
However, how “different” are the identified entities? As Ranaivoson [31] points out, the component
“disparity” in Stirling’s formula can prove to be a hurdle as it requires huge assumptions about formulating
disparity in numeric terms. Clearly, for an unknown text, in general no a priori pairwise distances will be
available. Instead, our tool draws on an ontology that is sourced from three directions. The first is based on
feature representations, the second and third draw on user input.
4.1 Feature-based representations and disparity
A common technique for disparity computations is based on path distances in the underlying tree-shaped (or
sometimes also DAG-shaped) ontology. However, results can be distorted for example if some parts of the
ontology are more fine-grained (have more levels) than others, e.g. [5, 34]. A further important limitation,
especially in tree-shaped ontologies, is that the ontology is created with regard to one criterion for subclassing. However, we also recognise that addressing socio-political disparity requires taking into account that
actors will rarely fit any single pigeonhole, no matter how fine-grained the ontology may be. They usually have
many overlapping facets relevant to their position takings in the socio-political field. To address this
complexity, we start from the traditional categories of actors (person, organisation, and geopolitical entity). A
measure that can also take similarities and dissimilarities along different facets is then needed. It should also
recognise that even if (say) a person and a political party are of very different basic ontological types (person
and organisation), they can still be quite similar (e.g. because they stand for the same political ideology).
Table 1 shows a (simplified) example. Donald Trump and Hillary Clinton can be considered similar in that
they are both American politicians. However, they are also distinct from each other in that they are associated
with conservative and liberal parties. When we add other actors to the context, the issue of disparity becomes
more complex. For instance, Tayyip Erdogan is similar to Trump and Clinton in that he is a politician. He is
more similar to Trump than to Clinton because of his gender, ideology of his party, and holding an office as a
president. However, he differs from both of them as he is based in a developing country, making Trump and
Clinton more similar in this aspect. This example can be extended by adding other features, as well as other
types of actors such as institutions, political parties and NGOs. This illustrates that socio-political actors can
have many features that can be common or non-common among these actors. We say that a feature (e.g.,
being male) is common between two actors if both have a certain property (e.g., gender) and both have the
same value (e.g., male) on this property. The value can in itself be an actor or other entity (e.g., Republican
Party) that has properties. If two actors have a certain property, but different values on it (e.g., male vs.
female), we say that the feature is non-common. Properties held by only one of the compared actors are
disregarded in comparing the actors.

7

The tool is available at http://diversitysearcher.net:4000. Please contact the authors to obtain a test
account.

7

4.2 DBpedia
8

9

The Diversity Searcher DBpedia , a Linked Open Database (LOD) based on Wikipedia . Like most LOD,
DBpedia uses Semantic Web principles, organizing information from Wikipedia in a machine-processable
format. One can garner detailed information about any socio-political actor that has an entry in this knowledge
10

base by using SPARQL , the query language for RDF databases. For the current application the public
SPARQL access point with 2016-10 datasets is used.
Table 1: Some socio-political features of Donald Trump, Hillary Clinton and Tayyip Erdoğan

Type
Donald Trump Person
Hillary Clinton Person
Tayyip Erdogan Person

Subtype

Gender Party

Party Ideology

Politician
Politician
Politician

Male
Republican Party
Female Democratic Party
Male
AKP

Conservative
Liberal
Conservative

Holds Office
Country
(currently/2020)
President
US
US
President
Turkey

4.2.1 Knowledge representation
11

DBpedia is used in conjunction with the open source Named Entity Linking service DBpedia Spotlight ,
which identifies the entities in the text and returns the links to the corresponding DBpedia entries. The
Diversity Searcher then retrieves information about the identified entities from DBpedia, and filters it to keep
only the properties and features relevant to our task. The current version focuses on socio-political properties
of the entities, which include political party membership and ideologies for people and organisations,
memberships in international organisations such as the EU, and economic parameters for geopolitical entities.
These properties and features are then used to calculate how similar and different two entities in the text are
from each other.
The socio-political properties of an entity are extracted from DBpedia and transformed into a feature vector
as follows.
1. The basic idea is to select the following attribute information that is often (though not always) explicitly
asserted as an RDF triple: gender, religion and ideology for a Person, ideology for a political party or other
Organisation, geography (e.g. which continent/sub-continent), form of government, and membership in
international organisations for countries or other Populated Places. In addition, entity information is enriched
via relational information: a person receives additional features via the political party they belong to and by the
country of this party. A political party’s information is enriched by its country information.
2. This would normally result in fixed feature vectors for persons, organisations, and countries. However,
we found that due to the irregularity of the ontological information in DBpedia, this fixed approach yields only
sparsely populated feature vectors. We therefore developed a more flexible approach, which is realized by
iterated filtering, see Table 2, especially lines (5) to (8).
The instruction block from lines (9) to (11) uses a function fp to filter and classify information that is
relevant, but stored in DBpedia under the (underspecified) predicates “type” and “subject”. For example, the

8

http://dbpedia.org/sparql
https://www.wikipedia.org/
10
https://wiki.dbpedia.org/public-sparql-endpoint
11
https://www.dbpedia-spotlight.org/
9

8

category of Membership of the Commonwealth appears as “subject”, but for our purposes needs to be
transferred into a value for the feature International Memberships. This mapping is implemented by an Excel
configuration file that presents the function fp as an enumeration of its tuples, such that the test and the
retrieval in line (11) become table look-up operations. This declarative and explicit notation enables also nonexperts to configure the algorithm (for example, if they want to add demographic person features as relevant
for disparity calculation).
In case of conflicting information (two values found for the same feature name of a given entity), we use
the first value found. This ensures that more specific information is preferred (e.g. the person’s “own” ideology
rather than that of their party), a heuristic inspired by the common strategy, in knowledge representation, of
using the more specific information (e.g. located at the subclass) where available.
Our inspection of the obtained results suggests that this strategy leads to better knowledge enrichment. In
particular, it gathers (in the cases we have seen) relevant but distributed information about, e.g., the ideology
of politicians, which is directly linked to some but distributed over their associated entities for others. Thus,
coverage is larger than for a fixed feature-retrieval strategy. In future work, this conjecture needs to be
evaluated, in particular with precision-oriented measures of whether correct information is added (recalloriented measures would require a gold-standard ontology, which does not exist).
4.2.2 Feature-based disparity calculation
In the example from Table 1, Hillary Clinton and Donald Trump have three common features, Donald
Trump and Tayyip Erdogan have five, and Hillary Clinton and Tayyip Erdogan have two. The three pairs of
actors have further, non-common 14, 26 and 28 features (not shown in Table 1). Using the Jaccard similarity
12

coefficient , we derive a feature-based measure of disparity for each pair : the number of non-common
features divided by the total number of features. We refer to this measure as the “Jaccard Disparity” in the
user interface. For example, Hillary Clinton and Donald Trump have a disparity value of (14 / 19 = 0.74). The
measure ranges from 0 (all features are shared, equality) to 1 (no common features, maximum disparity).
The disparity information is then combined with the variety (operationalised as the set {Hillary Clinton,
Donald Trump, Tayyip Erdogan}), and balance is determined by the number of mentions of these actors in the
text, via the Stirling equation shown in Section 3.4.

12

The Jaccard similarity coefficient is (number of common features / number of all features). Using (1 –
Jaccard similarity) gives us a measure of disparity.

9

INPUT: an entity a recognised by DBpedia Spotlight, with a type in {Person, Organisation, PopulatedPlace}
OUTPUT: a feature vector describing a
(1) Add feature “TYPE” with value DBpedia type to a
(2) PUSH a ONTO QUEUE.
(3) REPEAT UNTIL QUEUE EMPTY:
(4) TAKE s FROM QUEUE
(5) Retrieve all triples with subject s and predicate p ∈ {gender, religion, party, ideology, country}
(6) FOR EACH triple:
(7) add a feature to a with feature name p and feature value o
(8) IF o is a URI & has a triple (o,type,X) with X ∈ {Person, Organisation, PopulatedPlace}
THEN PUSH o ONTO QUEUE
(9) Retrieve all triples with subject s and predicate p ∈ {type,subject}
(10) FOR EACH triple:
(11) IF fp(o)  NULL THEN add a feature with feature name fp(o) and feature value o
Table 2: Creating feature values from DBpedia

13

4.3 Custom ontologies and spaCy
14

15

DBpedia Spotlight can link surface forms to more than 3.5 million entities found in DBpedia [23]. However,
our analyses of the depth, breadth and quality of this ontology, both in its Dutch-language and in its Englishlanguage versions, showed that some of the relevant named entities in our corpora are not recognised in this
way. Reasons can be simple, including a comparatively recent rise in popularity of a person, whose entry is
however not included in the most recent online API of DBpedia that we work with (Greta Thunberg is a case in
point as of January 2021).
Other reasons include accuracy and bias issues arising from using DBpedia Spotlight and DBpedia, both
of which are based on Wikipedia [39]. Moreover, DBpedia Spotlight favour candidate entities with more inlinks in order to rule out more exotic entities [23]. While the approach is well-suited to a general-purpose
model, it resulted in erroneous recognitions in our use tests, such as nation states recognized as football
teams, or political parties recognized as “the history of” the said party. The blacklisting by type feature of
Spotlight is of little use in cases like the former, where both entities are of the same type. We therefore
complemented Spotlight and the DBpedia ontology with our custom ontology, and with functionality that
allows the user to provide further input and corrections.

13

https://spacy.io/
https://github.com/dbpedia-spotlight/dbpedia-spotlight-model
15
The most recent version of the Spotlight models (18 November 2020) can be found at
https://databus.dbpedia.org/dbpedia/spotlight/spotlight-model/2020.11.18
14

10

4.3.1 Knowledge representation
This custom ontology contains unnamed entities, compiled from the custom ontology tree based on [30] (see
above) and named entities relevant to our context such as Belgian political parties. These custom entities are
spotted using spaCy’s ‘rule based matcher’. This is supplemented with spaCy’s own named entity recognition
module to spot other named entities in the text that are not recognised by Spotlight or do not have a custom
rule in Diversity Searcher, but may have significance in the text (as in the Greta Thunberg example).
For the entities recognised using a custom rule containing a URI, we attempt to acquire the type
information from DBpedia in the way described in 1.1 to ensure consistency. If the rule does not contain a
URI, we then use the type entered by the user when populating the rule. Finally, for the remaining entities we
default to the types recognised by spaCy’s NER.
4.3.2 Disparity calculation
For entities identified in this way, we have no access to feature information. As a simple heuristic, we give
default value 0.25 (“small”) to entity pairs of the same type and 1 to other pairs. These default assignments
can be edited by the user, as explained in (3) below.
4.4 Direct user input
DBpedia is a general-purpose ontology, spaCy’s functionality is generic, and also the custom ontology we
employ was built for a specific purpose. As an unavoidable consequence, some entities relevant to the
domain of news articles or the even more scope-restricted domains of news such as migration, and/or
contained in a concrete article or corpus to be analysed, may not or not sufficiently be represented or
recognised. To allow the user to describe these and thereby the Diversity Searcher to process them, we
added an interactive component to the tool in which users can add entities.
This component offers the user a table to add or remove custom matching patterns for spaCy’s matcher to
use temporarily or save for later sessions. The patterns entered by the user are processed the same way as
the custom ontology described above, with the options for the user to choose match type (“case sensitive”,
“case insensitive”, “lemma”), DBpedia link if available, and type of entity (person, organisation, geo-political
entity).
The overall methodology results in ontologies that are richer than custom-built ontologies (since they draw
on a worldwide community of ontology creators and/or the tool users, rather than the – by nature – very
limited efforts of dedicated research teams), and they are also more sustainable (as crowd-sourced and/or
user-sourced ontologies, they are more up-to-date and do not depend on the temporally bounded funding for
ontology engineering in a research project).
5 USER INTERFACE AND INTERACTIVITY
The interface aims to give feedback to the user about the socio-political actors in the text or corpus, their
features, their disparities, and diversity. Based on our findings in the workshops and user tests, we strive to
make this feedback as intuitive and accessible as possible for all user types.

11

Figure 1. Colour-coded annotations of the three actor types in an excerpt of an article from Guardian 16

Figure 2. Actors found in the text, displayed on a histogram in the “Actors” tab.

Figure 3. The interface tab for editing actor recognition patterns.

16

https://www.theguardian.com/us-news/2021/jan/07/georgia-senate-runoff-black-voters-stacey-abrams

12

Figure 4. The interface tab for pairwise actor disparities.

The most accessible types of feedback the application provides include colour-coded annotations of actors
(Fig. 1), hover info-boxes populated with their features, descriptions and photographs retrieved from
DBpedia/Wikipedia, a word-cloud representation of these actors, and histograms and frequency tables for the
actors (Fig. 2) and analogously for their features. Entities for which additional information is available in a
hover-box are highlighted in bright colours; other entities in light colours (Fig. 1). All of the frequency tables
can be exported as a single Excel file with separate tabs for each of them, providing a convenient way for the
user to process the data further, for example with Excel or SPSS. When a corpus is uploaded, every
document within it is represented as a row in the frequency tables in the interface and the exported files.
For disparity, a visualisation using multidimensional scaling is provided, on which the actors are colourcoded according to type, scaled according to relative frequency, and positioned within a 2D space with
respect to their feature vectors. Pairwise disparities are also presented in a chart editable by the user, with
hover info-boxes about their method of calculation (Jaccard disparity, or default value if no features are found)
and the number of common features they share. Diversity is calculated using Stirling’s [36] formula based on
these disparities and relative frequencies of the actors, and displayed numerically for each article and
individual text. Thus, users can compare different articles or corpora.
One issue that surfaced recurringly in user tests was the entities misrecognised or unrecognised by
Spotlight. To address this, we added a component where the user can customise the rules for recognising
named and unnamed entities (Fig. 3). This component consists of a table populated with all the potential
entities recognised by spaCy as a default, with options to add or remove rows representing each recognition
rule. The rules consist of “words to match”, the matching method (“case sensitive”, “case insensitive”,
“lemma”), DBpedia link (if available), type of entity (person, geopolitical entity, organisation), and whether to
ignore that match in the case of misrecognised entities. The rules can be used in a current session, or saved
by the user for future use. For example, the user may want to change the wrong classification for “black” from

13

“GPE” to “PERSON” (Fig. 1), or add “black voter” as a new actor type depending on their current interest.
This interface also enables user to instruct Diversity Searcher to remove falsely recognized entities.
A similar interface is also provided for pairwise disparities, where the user can modify disparities of actors
(Fig. 4). Users can change the coarse values (low/medium/high) in the basic mode or enter numeric values in
advanced mode. Such edits are especially useful for entities that do not have entries in DBpedia, for which a
feature-based Jaccard disparity cannot be calculated. Finally, the resulting Stirling diversity score is also
shown in the same interface.
After consulting with various user groups, we have decided to bundle all functionalities in one user
interface. While the current version only supports basic authentication, a more sophisticated user
management is planned for the future which would limit/enable functionality based on user groups such as
news producers and news consumers. In addition, the application has a simple/advanced mode switch, which
modifies the data presented to the user as well as the interface, allowing for a selection between more
intuitive access vs. more control.
The application includes a corpus upload function. Using this function, users can upload XML files
17
exported from GoPress and batch process them, and export the results as an Excel file to be used in further
analysis in Excel or SPSS.
6

SUMMARY, LIMITATIONS AND OUTLOOK ON FUTURE WORK

The Diversity Searcher tool described in this paper was motivated by the question how we can increase
diversity and fairness in media reporting. In our theoretical grounding, we started from a viewpoint of
sociology and media studies, which highlights that to even claim fair treatment, individuals and groups first
have to be visible. We drew on Stirling’s quantitative measure of diversity that expresses this wider
requirement. We used the measure to design and build the tool to detect and enhance the representation of
socio-political actors in news media. The tool’s combination of natural language processing and a rich user
interface can help news producers and consumers detect and understand diversity-relevant aspects of
representation, which can ultimately contribute to enhancing diversity and fairness in media.
While the core functionality gives valuable information about entities present in the texts, there are multiple
avenues for improvement and additional features.
One limitation concerns the downstream effects of re-using third party resources, services and tools.
Despite having advantages, dependence on third party tools and services posed limitations in the
performance of the application. Firstly, using Spotlight for actor recognition limits the recognised actors to
those that have a resource on DBpedia. We attempted to alleviate this by using spaCy's NER module to
include recognised entities that do not have a resource in Dbpedia, and its pattern based matcher to add
named and unnamed custom entities. Secondly, dependence on DBpedia brought also limitations in the data
quality and performance. Currently we attempt to remedy the missing/inaccurate depictions of actors by
enabling user input of pairwise disparities, but a future solution may be populating a local knowledge base,

17

Go Press (gopress.be) is an online press database covering a large number of international and Belgian
news sources, where journalists and media researchers can search and export corpora. The specific source
and therefore its XML format are relevant for our target users, but the schema could easily be made
configurable. https://www.gopress.be/info/nl

14

possibly using multiple resources such as Wikidata

18

19

and ConceptNet

to improve both issues. A further

limitation is created by the complex relations between named and unnamed entities. In future work, we plan to
develop coreference resolution between named and unnamed entities, as well as entities and pronouns. An
implementation of gendered coreference resolution would also improve the statistics related to actor genders,
which currently only use DBpedia data for named entities.
The current tool gives insights about the presence of actors in texts. However, the presence itself does not
necessarily imply a favourable representation, or one that is comparable between the different represented
actors. An actor like “refugee” could be represented as a passive actor, lacking agency, or as the subject of a
crime. This points to other avenues for future work. One is the detection and categorisation of the verbs that
co-occur with the actor entities. A second and related feature would be to determine the active/passive voice
in which entities appear within the sentence using dependency trees, these two features will provide
additional insight into the representation of the entities. Topic detection is another interesting prospect related
to this aspect of the issue, revealing actors that regularly occur in certain topics. Future work that addresses
these aspects of representations would result in an application that can provide more in-depth insight to actor
diversity media texts, contributing to fairness in media.
The tool was constructed in continuing collaboration between computer scientists and media studies
scholars, and requirements were iteratively adjusted based on input from target users. Throughout, users
were more interested in the rich interface functionality that helps them explore diversity-related aspects of the
texts, and less in the final numerical diversity score. This proved to be an interesting demonstration of how
such a formal measure can serve as motivation and heuristic, but then end up in the background of what is
really used. At the same time of course, the measure and the ensuing design decisions embody a collection
of decisions and symbolic power.
To return to Bourdieu, the categories that make knowledge of the social world possible constitute the
stakes in political struggles as they revolve around conserving or transforming them [8]. As the main functions
of Diversity Searcher involve categorisation and making explicit of actors, it runs the risk of reproducing the
very biases and inequalities it attempts to critique/deconstruct. Relying on third party tools based on
crowdsourced knowledge may aggravate this limitation, as exemplified by the demonstrable gender bias in
Wikipedia [39]. While containing biases, crowdsourced knowledge also represents a more democratic and
critical mode of knowledge production than most alternatives. This makes it a suitable aid in critically and
reflexively engaging with texts that are produced by individual authors within a media subfield with its own
capitals, stakes and interests. In addition, Diversity Searcher gives the user means to alter the ontology and
entity recognition rules, further negating the biases that may be in the models of DBpedia Spotlight, spaCy, as
well as our own ontology.
Last but not least, evaluations at different levels will need to complement the implementation-driven work
so far. Where we use third-party resources and software, we have used standard state-of-the-art choices
such as DBpedia or DBpedia Spotlight. As highlighted in Section 4.2.1, our knowledge-representation
heuristics require a systematic evaluation with information-retrieval methods and measures. Most importantly,
we need to evaluate the usability and usefulness of the tool in user studies. While feedback from user

18
19

https://www.wikidata.org/wiki/Wikidata:Main_Pag e
https://conceptnet.io/

15

partners of our project has been encouraging, we have not yet conducted a summative evaluation. Most
design guidelines for the Diversity Searcher resulted from interviews with four key stakeholders from major
Flemish news media (the editors-in-chief of two alternative (non-mainstream) magazines, the head of
production of one of the leading TV newsrooms and a journalist of a national newspaper) and collaboration
with media-studies researchers [30, 2]. Individual features resulted from formative evaluation sessions as well
as focus-group interviews with students from journalism and Digital Humanities programmes and media21
studies scholars . These sessions showed that physical presence is needed to explain the tool and get
feedback.
The tool is ultimately designed as a means towards improving journalism. Journalism is an institution in
society, but many institutions tend to be somewhat conservative. Although implementing diversity echoes a
journalism imperative, the tool is new and relies on some conceptual background. “Diversity consciousness”
and “multimedia consciousness” are both logical parts of contemporary journalism education, but every new
tool requires an “enculturating” process [18], accompanied by a well-constructed pedagogical approach.
Future work also requires us to implement the tool, so that the tool is not only theoretically relevant but also
practically used. As Siitonen et al. [33] demonstrate, the interaction between computer science students and
journalism students in pedagogical settings can be valuable in thinking out how to use new applications.
Eventually our goal is not only to integrate the tool in journalism education, but also to present the tool to
journalists who are currently on the job and hence maximise its impact. Due to corona-induced restrictions,
the planned evaluation study had to be postponed into 2021. These studies will contribute to fine-tuning both
backend and frontend of the Diversity Searcher for relevant practitioners, and will allow us to gauge its
usefulness in practice.
ACKNOWLEDGMENTS
We thank the Fonds Wetenschappelijk Onderzoek – Vlaanderen (FWO) for funding DIAMOND under project
code S008817N.
REFERENCES
[1]

J. Khadijah Abdurahman. 2020. On the Moral Collapse of AI Ethics. Retrieved Dec, 7 2020 from

https://upfromthecracks.medium.com/on-the-moral-collapse-of-ai-ethics-791cbc7df872
[2]
Kathleen Beckers and Peter Van Aelst. 2019. Look who’s talking: An analysis of actors in television
news
(2003–2016).
Journalism
Studies
DOI:https://doi.org/10.1080/1461670X.2018.1463169

20,

6

(April

2019),

872–890.

[3]
Yochai Benkler, Rob Faris, and Hal Roberts. 2018. Network propaganda: manipulation,
disinformation, and radicalization in American politics. Oxford University Press, New York.

21

Workshops with students from KU Leuven Journalism and KU Leuven Digital Humanities programs were
carried out in October and December 2019 respectively. In these workshops, participants used an early
version of Diversity Searcher to analyze online news articles. The design and development continued with
regular meetings with colleagues from KU Leuven Media Studies department (beginning February 2020),
with their continuous feedback on interface and entity recognition.

16

[4]

Rodney Benson. 2013. Shaping Immigration News: A French-American Comparison. Cambridge

University Press, New York. DOI:https://doi.org/10.1017/CBO9781139034326
[5]
Berendt, B. & Navigli, R. (2006). Finding your way through blogspace: Using semantics for crossdomain blog analysis. In Proceedings of the AAAI 2006 Symposium on Computational Approaches to
Analysing Weblogs. Stanford, CA: March 2006 (pp. 1-8). Technical Report SS-06-03. Menlo Park, CA: AAAI
Press.
[6]

Tim Berners-Lee, James Hendler, and Ora Lassila. 2001. The Semantic Web: A New Form of Web

Content That is Meaningful
ScientificAmerican.com (2001).

to

Computers

Will

Unleash

a

Revolution

of

New

Possibilities.

[7]
R Binns, ‘Fairness in Machine Learning: Lessons from Political Philosophy’ in Conference on
Fairness, Accountability and Transparency, FAT 2018 (Proceedings of Machine Learning Research 81, 2018)
149
[8]

Pierre Bourdieu. 1985. The Social Space and the Genesis of Groups. Theory and Society 14, 6

(Nov. 1985), 723-744 Retrieved January 9, 2021 from www.jstor.org/stable/657373
[9]
Giovanni Luca Ciampaglia, Prashant Shiralkar, Luis M. Rocha, Johan Bollen, Filippo Menczer, and
Alessandro Flammini. 2015. Computational Fact Checking from Knowledge Networks. PLOS ONE 10, 6
(2015), 1–13. DOI:https://doi.org/10.1371/journal.pone.0128193
[10]
[11]

Ceretai n.d. Retreived from https://ceretai.com/ on January 5, 2020.
Pieter Delobelle, Murilo Cunha, Eric Massip Cano, Jeroen Peperkamp, and Bettina Berendt. 2019.

Computational Ad Hominem Detection. In Proceedings of the 57th Annual Meeting of the Association for
Computational Linguistics: Student Research Workshop, Association for Computational Linguistics, Florence,
Italy, 203–209. DOI:https://doi.org/10.18653/v1/P19-2028
[12]
Bart Desmet and Véronique Hoste. 2014. Fine-grained Dutch named entity recognition. Lang
Resources & Evaluation 48, 2 (June 2014), 307–343. DOI:https://doi.org/10.1007/s10579-013-9255-y
[13]
Europe Media Monitor. n.d. Retrieved from https://ec.europa.eu/jrc/en/scientific-tool/europe-mediamonitor-newsbrief on January 5 2020
[14]
William A. Gamson, David Croteau, William Hoynes, and Theodore Sasson. 1992. Media Images
and the Social Construction of Reality. Annual Review of Sociology 18, 1 (1992), 373–393.
DOI:https://doi.org/10.1146/annurev.so.18.080192.002105
[15]
Herbert J Gans. 2011. Multiperspectival news revisited: Journalism and representative democracy.
Journalism 12, 1 (Jan. 2011), 3–13. DOI:https://doi.org/10.1177/1464884910385289
[16]
[17]

The GDELT Project. n.d. Retrieved from https://www.gdeltproject.org/ on January 5, 2021
Gender Meme. n.d. Retrieved from https://www.gendermeme.org/ on January 5, 2020

[18]
Debbie Goh and Ugur Kale. 2015. From Print to Digital Platforms: A PBL Framework for Fostering
Multimedia Competencies and Consciousness in Traditional Journalism Education. Journalism & Mass
Communication Educator 70, 3 (September 2015), 307–323.
[19]
B Hutchinson and M Mitchell, ‘50 years of test (un)fairness: Lessons for machine learning’ in
Proceedings of the Conference on Fairness, Accountability, and Transparency. FAT* 2019 (ACM 2019) 49
[20]
Kari Karpinen. Journalism, Pluralism, and Diversity. Tim P. Vos (Ed.). In Journalism. De Gruyter
Mouton, 2018. 493–510. DOI:https://doi.org/10.1515/9781501500084-025

17

[21]

Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li. 2020. A Survey on Deep Learning for Named

Entity Recognition. arXiv:1812.09449
http://arxiv.org/abs/1812.09449

[cs]

(March

2020).

Retrieved

January

12,

2021

from

[22]
Xiao Ling and Daniel S. Weld. 2012. Fine-Grained Entity Recognition. In Proceedings of the TwentySixth AAAI Conference on Artificial Intelligence (AAAI’12), AAAI Press, 94–100.
[23]
Pablo N. Mendes, Max Jakob, Andrés García-Silva, and Christian Bizer. 2011. DBpedia spotlight:
shedding light on the web of documents. In Proceedings of the 7th International Conference on Semantic
Systems - I-Semantics ’11, ACM Press, Graz, Austria, 1–8.
[24]
John W. Meyer and Ronald L. Jepperson. 2000. The “Actors” of Modern Society: The Cultural
Construction
of
Social
Agency.
Sociological
DOI:https://doi.org/10.1111/0735-2751.00090

Theory

18,

1

(March

2000),

100–120.

[25]
David Nadeau and Satoshi Sekine. 2007. A Survey of Named Entity Recognition and Classification.
Lingvisticae Investigationes 30, (2007). DOI:https://doi.org/10.1075/li.30.1.03nad
[26]
Philip M. Napoli. 1999. Deconstructing the diversity principle. Journal of Communication 49,4 (Dec.
1999) 7-34. DOI: https://doi.org/10.1111/j.1460-2466.1999.tb02815.x
[27]
Philip M. Napoli. 2003. Audience Economics: Media Institutions and the Audience Marketplace.
Columbia University Press.
[28]
Dong Nguyen, Maria Liakata, Simon DeDeo, Jacob Eisenstein, David Mimno, Rebekah Tromble,
and Jane Winters. 2019. How we do things with words: Analyzing text as social and cultural data.
arXiv:1907.01468 [cs] (July 2019). Retrieved December 7, 2019 from http://arxiv.org/abs/1907.01468
[29]
Open Calais. n.d. Intelligent Tagging – RESTful API | Refinitiv Developers. Retrieved from
https://www.refinitiv.com/en/products/intelligent-tagging-text-analytics
[30]
Peperkamp, Jeroen; Berendt, Bettina: Diversity Checker: Toward recommendations for improving
journalism with respect to diversity, In UMAP '18 Adjunct Publication of the 26th Conference on User
Modeling, Adaptation and Personalization (pp. 35-41). New York: ACM.
[31]
Heritiana Ranaivoson. 2013. “Measuring Cultural Diversity with the Stirling Model.” in proceedings of
New Techniques and Technologies for Statistics 2013. March 5-7, 2013. 10.2901/Eurostat.C2013.001
[32]
Wei Shen, Jianyong Wang, and Jiawei Han. 2015. Entity Linking with a Knowledge Base: Issues,
Techniques, and Solutions. IEEE Trans. Knowl. Data Eng. 27, 2 (February 2015), 443–460.
DOI:https://doi.org/10.1109/TKDE.2014.2327028
[33]
Marko Siitonen, Panu Uotila, Turo Uskali, Jukka Varsaluoma, and Tanja Välisalo. 2019. A Pilot Study
on Developing Newsgames in Collaboration between Journalism and Computer Science Students. Nordicom
Review 40, 2 (March 2019), 143–155.
[34]
Thabet Slimani. Description and Evaluation of Semantic Similarity Measures Approaches. CoRR
abs/1310.8059 (2013)
[35]
Tadej Stajner, Delia Rusu, Lorand Dali, Blaž Fortuna, Dunja Mladenić, and Marko Grobelnik. 2010. A
Service Oriented Framework for Natural Language Text Enrichment. Informatica (Slovenia) 34, (2010), 307–
313.
[36]

Andy Stirling. 2007. A general framework for analysing diversity in science, technology and society.

J. R. Soc. Interface (2007) 4, 707–719. DOI:10.1098/rsif.2007.0213

18

[37]

Alje van Dam. 2019. Diversity and its decomposition into variety, balance and disparity. R. Soc. open

sci. 6, 7 (July 2019), 190452. DOI:https://doi.org/10.1098/rsos.190452
[38]
Tony Veale and Yanfen Hao. Detecting Ironic Intent in Creative Comparisons.In proceedings of the
2010 conference on ECAI 2010: 19th European conference on artificial intelligence. Lisbon, Portugal, August
16-20
[39]
Claudia Wagner, David Garcia, Mohsen Jadidi, and Markus Strohmaier. 2015. It’s a Man’s
Wikipedia? Assessing Gender Inequality in an Online Encyclopedia. arXiv:1501.06307 [cs] (March 2015).
Retrieved January 14, 2021 from http://arxiv.org/abs/1501.06307
[40]
I Zliobaite, ‘Measuring discrimination in algorithmic decision making’ (2017) 31 (4) Data Mining and
Knowledge Discovery 1060

19

