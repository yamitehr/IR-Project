Analysis of DCTCP: Stability, Convergence, and Fairness
Mohammad Alizadeh, Adel Javanmard, and Balaji Prabhakar
Department of Electrical Engineering, Stanford University

{alizade, adelj, balaji}@stanford.edu

ABSTRACT
Cloud computing, social networking and information networks (for search, news feeds, etc) are driving interest in
the deployment of large data centers. TCP is the dominant Layer 3 transport protocol in these networks. However, the operating conditions—very high bandwidth links,
low round-trip times, small-buffered switches—and traffic
patterns cause TCP to perform very poorly. The Data Center TCP (DCTCP) algorithm has recently been proposed as
a TCP variant for data centers and addresses these shortcomings.
In this paper, we provide a mathematical analysis of DCTCP.
We develop a fluid model of DCTCP and use it to analyze
the throughput and delay performance of the algorithm, as a
function of the design parameters and of network conditions
like link speeds, round-trip times and the number of active
flows. Unlike fluid model representations of standard congestion control loops, the DCTCP fluid model exhibits limit
cycle behavior. Therefore, it is not amenable to analysis by
linearization around a fixed point and we undertake a direct
analysis of the limit cycles, proving their stability. Using
a hybrid (continuous- and discrete-time) model, we analyze
the convergence of DCTCP sources to their fair share, obtaining an explicit characterization of the convergence rate.
Finally, we investigate the “RTT-fairness” of DCTCP; i.e.,
the rate obtained by DCTCP sources as a function of their
RTTs. We find a very simple change to DCTCP which is
suggested by the fluid model and which significantly improves DCTCP’s RTT-fairness. We corroborate our results
with ns2 simulations.
Categories and Subject Descriptors:
C.2.2 [Computer-Communication Networks]: Network Protocols
General Terms:
Algorithms, Performance, Theory
Keywords:
Data center network, Congestion control, Analysis, TCP

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGMETRICS’11, June 7–11, 2011, San Jose, California, USA.
Copyright 2011 ACM 978-1-4503-0262-3/11/06 ...$10.00.

1.

INTRODUCTION

1.1

Background and Motivation

TCP is the dominant transport protocol in the Internet
and has proven to be scalable and robust to network operating conditions. It is also the dominant Layer 3 protocol in the data center environment, notably in data centers
associated with cloud computing, social networking and information networks delivering services such as search, news,
advertisement, etc. Its performance in data center environments, however, is quite poor. As detailed in [1], this is
mainly because data centers have switches with very small
buffers, high speed links, and low round-trip times. Moreover, the nature of traffic and the requirements of applications in data centers are quite different from that in the wide
area Internet; data center applications generate a mixture
of bursty query traffic, delay-sensitive short messages, and
throughput-intensive long flows and often have strict deadlines for the completion of flows.
These differences in operating conditions have caused TCP
to underperform in the following ways: (i) It requires large
buffers so as to not under-run links, and these buffers can
be expensive at high line rates. (ii) It uses all the available
buffering; therefore, it induces unacceptably large queuing
delays. (iii) It does not handle bursty traffic well, especially
under ‘Incast’ [20] scenarios. See [1] for a more detailed
discussion of TCP performance in data centers.
Data Center TCP (DCTCP) has been proposed in [1] to
address these shortcomings of TCP. Figure 1, taken from [1],
compares the operation of TCP and DCTCP in an actual
hardware testbed. It is seen that DCTCP achieves full
throughput (the buffer does not underflow) while maintaining a very low buffer occupancy compared to TCP. This
allows DCTCP to simultaneously provide low latency and
good burst tolerance for the short flows, and high throughput for the long flows.
The key mechanisms used by DCTCP are a simple active
queue management scheme at the switch, based on Explicit
Congestion Notification (ECN) [16], and a window control
scheme at the source which reacts to ECN marks by reducing the window size in proportion to the fraction of packets
that are marked (contrast this with TCP which always cuts
the window by half if at least one packet is marked). The
performance of DCTCP is determined by two parameters:
(i) K, the marking threshold on the queue at the switch
above which all packets are marked; and (ii) g, the weight
used for exponentially averaging ECN mark values at the
source. See Section 2.1 for details.

Inst. Queue Len(KB)

TCP
DCTCP

600

and obtain the following bounds
βDCT CP < βT CP < 1.4 × βDCT CP .

400
200
0
0

500

1000

1500
ms

2000

2500

3000

Figure 1: Taken from [1]. Queue length measured
on a Broadcom Triumph switch. Two long flows are
launched from distinct 1Gbps ports to a common
1Gbps port. The switch allocates about 600KB of
buffer to the congested port.

1.2 Main Contributions and Organization
This paper undertakes a rigorous analysis of DCTCP. The
following are our main contributions:
1. DCTCP fluid model. We briefly review the DCTCP
algorithm and derive a fluid model for it in Section 2. The
model comprises of a system of nonlinear delay-differential
equations. Using ns2 [15] simulations, we find that the fluid
model is very accurate and that it is more accurate across
a wider range of parameters than a simple model presented
in [1]. A key step in developing the fluid model is accurately
capturing the bursty (0–1 type) marking at the switch which
DCTCP employs.1
2. Steady state. We analyze the steady state behavior of
DCTCP using the fluid model in Section 3. Due to its 0–1
style marking function, the fluid model does not have a fixed
point. Instead, it exhibits a (periodic) limit cycle behavior
in steady state. Theorem 1 provides a necessary and sufficient condition for local stability of the limit cycles using
the so-called Poincaré map technique [4, 10, 14, 22]. We
verify this condition (numerically) for a wide range of parameter values. We then explore the throughput and delay
performance of DCTCP by explicitly evaluating the limit
cycle solutions. Here we find that for DCTCP to achieve
100% throughput, the marking threshold, K, needs to be
about 17% of the bandwidth-delay product. For smaller
values of K, we determine the throughput loss; i.e., we obtain the throughput-delay tradeoff curve. A key result is
that DCTCP’s throughput remains higher than 94% even as
K → 0. This is much higher than the limiting throughput
of 75% for a TCP source as the buffer size goes to zero [21].
3. Convergence. We analyze how quickly DCTCP flows
converge to their fair equilibrium window sizes (equivalently,
sending rates) in Section 4. This is important to determine since DCTCP reduces its sending rate by factors much
smaller than TCP; therefore, DCTCP sources may take much
longer to converge. Theorem 2 gives the following explicit
characterization: For N flows (with identical RTTs) sharing
a single bottleneck link, the window sizes at the nth congestion episode, Wi (Tn ), converge to the fair share, W ∗ , as
follows:
|Wi (Tn ) − W ∗ | < O(n2 ) exp (−βDCT CP Tn ) ,
where an explicit expression is given for βDCT CP . Using
this, we compare the rate of convergence of TCP and DCTCP
1
This is similar to the difficulty of modeling TCP–Drop-tail
using fluid models.

Thus, even though DCTCP converges slower than TCP, it
is at most 1.4 times slower.
We note that the convergence results are obtained using a
different model from the fluid model, since the fluid model
is not suitable for conducting transient analyses. This new
model of DCTCP, which we call the Hybrid Model, employs
continuous- and discrete-time variables and is similar to the
AIMD models used in the analysis of TCP–Drop-tail [5, 17,
18]. While the AIMD models are linear and can be used to
determine convergence rates via an analysis of the eigenvalues of linear operators [17, 18], the Hybrid Model is more
challenging because it is nonlinear.
4. RTT-fairness. We investigate the fairness properties
of DCTCP for flows with diverse RTTs in Section 5. RTTfairness is defined as the ratio of the throughput achieved
by two groups of flows as a function of the ratio of their
RTTs [23, 11, 6, 2]. Using ns2 simulations, we find that
DCTCP’s RTT-fairness is better than TCP–Drop-tail but
worse than TCP with RED [7] marking. We identify a very
simple change to the DCTCP algorithm, suggested by the
fluid model, which considerably improves its RTT-fairness.
The modified DCTCP is shown to have linear RTT-fairness
(T hroughput ∝ RT T −1 ) and achieve a better fairness than
TCP–RED.
5. DCTCP Parameter Guidelines. Our analysis of
DCTCP’s steady state and convergence properties yields
guidelines for choosing algorithm parameters. Let C and d
respectively denote the bottleneck capacity (in packets/sec)
and propagation delay (in sec). Then,
K ≈ 0.17Cd,
5
1
/g/ √
.
Cd + K
Cd + K

(1)
(2)

For example, when C = 10Gbps and d = 300µs, assuming 1500Byte packets, K needs to be about 42 packets and
0.02 / g / 0.06.

2.

DCTCP: ALGORITHM AND MODEL

2.1

The Algorithm

First, we briefly review the DCTCP algorithm. We focus
on those aspects relevant to this paper and refer to [1] for
more details.
Switch Side. DCTCP uses a very simple active queue management scheme: When a packet arrives at the switch buffer
and the buffer occupancy is at least K packets, the packet is
“marked” using the ECN mechanism. Note that the arriving
packet is marked if (and only if) it finds the instantaneous
buffer occupancy to be larger than K packets.
Source Side. DCTCP is designed to simultaneously achieve
high throughput and very low queue occupancies. It does
this by reducing its current window (hence, sending rate)
in proportion to the extent of congestion. Specifically, a
DCTCP source reduces its window by a factor that is proportional to the fraction of marked packets: the larger the
fraction, the larger the decrease factor. This is in contrast to
the behavior a TCP source which reacts to marked packets
by always halving its window size.

Figure 2: Comparison between fluid model and ns2. The fluid model results are shown in solid black.
Operationally, the source maintains a running estimate of
the fraction of its packets that are marked. This estimate,
α, is updated once for every window of data (roughly each
round-trip time) as follows:
α ← (1 − g)α + gF,

(3)

where F is the fraction of packets that were marked in the
most recent window of data, and g ∈ (0, 1) is a fixed parameter. DCTCP uses α to cut its window size in response to a
marked ACK as follows:
α
(4)
W ← (1 − )W.
2
Thus when α is close to 0 (low congestion), the window
is only slightly reduced, whereas when α is close to 1 (high
congestion), the window is cut nearly in half. It is important
to note that, as in TCP, DCTCP cuts its window size at most
once per window of data (or round-trip time) [16].
This is the only difference between a DCTCP source and
a TCP source. Other aspects of the TCP algorithm, such
as slow start, additive increase during congestion avoidance,
or recovery from packet loss remain unchanged.

2.2 The Fluid Model
We now develop a fluid model for DCTCP by considering
N long-lived flows traversing a single bottleneck switch port
with capacity C. The following non-linear, delay-differential
equations describe the dynamics of W (t), α(t), and the
queue size at the switch, q(t):

W (t)α(t)
1
dW
=
−
p(t − R∗ ),
dt
R(t)
2R(t)
g
dα
=
(p(t − R∗ ) − α(t)) ,
dt
R(t)
W (t)
dq
=N
− C.
dt
R(t)

(5)
(6)
(7)

Here p(t) indicates the packet marking process at the switch
and is given by
p(t) = 1{q(t)>K} ,

(8)

and R(t) = d+q(t)/C is the round-trip time (RTT), where d
is the propagation delay (assumed to be equal for all flows),
and q(t)/C is the queueing delay.
Equations (5) and (6) describe the DCTCP source, while (7)
and (8) describe the queue process at the switch and the
DCTCP marking scheme. The source equations are coupled
with the switch equations through the packet marking process p(t) which gets fed back to the source with some delay.
This feedback delay is the round-trip time R(t), and varies
with q(t). However, as a simplification—and following [9]
and [12]—we use the approximate fixed value R∗ = d + K/C
for the delay. The approximation aligns well with DCTCP’s
attempt to strictly hold the queue size at around K packets.
Equation (5) models the window evolution and consists
of the standard additive increase term, 1/R(t), and a multiplicative decrease term, −W (t)α(t)/2R(t). The latter term

models the source’s reduction of its window size by a factor
α(t)/2 when packets are marked (i.e., p(t − R∗ ) = 1), and
this occurs once per RTT. Equation (6) is a continuous approximation of (3). Finally, equation (7) models the queue
evolution: N · W (t)/R(t) is the net input rate and C is the
service rate.
Remark 1. In standard TCP fluid models [19, 13, 8, 12],
the multiplicative decrease term is given by
−

W (t) W (t − R∗ )
p(t − R∗ ),
2 R(t − R∗ )

(9)

with the interpretation that W (t−R∗ )/R(t−R∗ )×p(t−R∗ )
is the rate at which marked ACKs arrive at the source, each
causing a window reduction of W (t)/2. As explained in [13],
this model is accurate when the packet marks can be assumed to occur as a Poisson process, for example, when the
RED algorithm [7] marks packets. In DCTCP, the marking process is bursty, as captured by the function p(t) at
equation (8). Hence, the natural adaptation of (9):
−

W (t)α(t) W (t − R∗ )
p(t − R∗ ),
2
R(t − R∗ )

is not valid for DCTCP.
Simulation comparison of the model. Fig. 2 compares
the fluid model with packet-level simulations using the ns2
simulator [15]. The parameters used are: C = 10Gbps, d =
100µs, K = 65 packets, and g = 1/16 (K and g are chosen
to match those of the 10Gbps experiments in [1]). The fluid
model plots correspond to the evolution of W (·) and α(·),
whereas the ns2 plots show the evolutions of the window size
and α of each of the N sources, for N = 2, 10, 100. In the
case N = 100, the queue size climbs to about 120 packets,
even though the marking threshold, K, is 65. Thus every
arriving packet is marked at the switch buffer (captured by
α = 1) to signal congestion to each of the 100 sources. The
window size at each source is reduced to the minimum, equal
to 2 packets, corresponding to a sending rate of 100 Mbps
per source.2
As can be seen, the fluid model matches the simulations
quite well. We have also compared the model with simulations for a wide range of line speeds, propagation delays,
number of sources and DCTCP parameters. Our findings
are that the model has very good fidelity and that, as is
typical, the fidelity increases with the number of sources.
Comparison with the Sawtooth model. The DCTCP
paper [1] presents a simplified model of the steady state
behavior of long-lived DCTCP flows sharing a single bottleneck. We call this the ‘Sawtooth’ model. It is based on
the assumption that the window sizes of the N flows and
the queue size can be thought of as being perfectly synchronized, described by periodic sawtooth processes. This makes
it possible to compute the steady state fraction of packets
marked at the switch, which can be used to completely specify the sawtooth processes in the model. See [1] for details.
The Sawtooth model provides simple closed form approximations to quantities of interest, such as the amplitude of
queue oscillations, leading to some guidelines on how to set
the DCTCP parameters. But the accuracy of the Sawtooth
2

Note that, when N = 100, the RTT equals 240 microseconds, since d = 100 microseconds and q/C = 140 microseconds. With these numbers, the sending rate of each source,
W/RT T , equals 100 Mbps, as required.

Figure 3: Comparison of the fluid and Sawtooth
models with ns2 simulations.
model rests heavily on the validity of the synchronization assumption. As mentioned in [1], this holds when N is small,
typically less than 10. Further, the Sawtooth model assumes
that sources know the exact fraction of marked packets and
does not include the variations in α resulting from the exponentially weighted moving average at equation (3). In
particular, the model is only accurate for small values of g
and does not capture the effect of g on system dynamics.
This is demonstrated in Fig. 3, which repeats the previous
simulation with N = 2, this time setting g = 0.4. Because
the Sawtooth model assumes α is a constant, its prediction
of the queue size evolution is very poor. The fluid model presented above captures the fluctuations in α and is, therefore,
much more accurate.

3.

ANALYSIS: STEADY STATE

3.1

The Normalized Fluid Model

We change variables
W̃ (t) = W (R∗ t), α̃(t) = α(R∗ t), q̃(t) =

q(R∗ t) − K
, (10)
CR∗

and rewrite the fluid model equations (5)–(8):
W̃ (t)α̃(t)
dW̃
1
=
(1 −
p̃(t − 1)),
dt
1 + q̃(t)
2
dα̃
g
=
(p̃(t − 1) − α̃(t)),
dt
1 + q̃(t)
dq̃
1 W̃ (t)
=
− 1.
dt
w̄ (1 + q̃(t))

(11)
(12)
(13)

Here
p̃(t) = 1{q̃(t)>0} ,

(14)

and w̄ = (Cd + K)/N is the average per-flow window size.
Henceforth, we refer to this as the normalized fluid model.
The normalized model immediately reveals that while the
DCTCP fluid model has 5 parameters (C, N , d, K and g),
the system dynamics is completely determined by: (i) the
average per-flow window size w̄, and (ii) the parameter g.
We now discuss the existence of possible fixed points for
the normalized fluid model. A fixed point of the system,
(W̃ , α̃, q̃), must satisfy the following equations:
1−

W̃ α̃
p̃ = 0,
2

p̃ − α̃ = 0,

1 W̃
− 1 = 0,
w̄ (1 + q̃)

(15)

where p̃ = 1{q̃ > 0}. The above equations have a solution only if w̄ ≤ 2. Therefore, we have the following two
operating regimes:

0.4

!!

0.3

!!

0.2

!!!

q̃(t)

0.1
0

!

−0.1
−0.2

! !!

−0.3
−0.4
6

8

10

12

14

W̃ (t)

Figure 4: Phase diagram showing occurrence of limit
cycle for w̄ = 10, g = 1/16 (the projection on the W̃ –q̃
plane is shown).

!!

!!

Figure 5: Periodic system trajectory and the
Poincaré map.
Definition 1. The limit cycle X ∗ is

(i) w̄ ≤ 2: In this regime, the normalized model has a unique
fixed point, namely (W̃ , α̃, q̃) = (2, 1, w̄2 −1). Equivalently, (5)–
(8) has the fixed point (W, α, q) = (2, 1, 2N − Cd). This
regime corresponds to the large N case, where the system
has a very simple steady state behavior: each source transmits two packets per RTT, of which Cd fill the link capacity,
and the remaining 2N − Cd build up a queue. All packets
are marked as the queue constantly remains larger than K.
The N = 100 case of Fig. 2 is in this regime.
(ii) w̄ > 2: In this regime, the system does not have a fixed
point. Rather, it has a periodic solution or limit cycle,3
characterized by a closed trajectory in state space. Figure 4
shows a sample phase diagram of the limit cycle projected
onto the W̃ –q̃ plane for w̄ = 10 and g = 1/16. As shown, all
trajectories evolve toward the orbit of the limit cycle. Both
the N = 2 and N = 10 cases of Fig. 2 are in this regime.
The regime w̄ ≤ 2 will no longer be discussed since it is
trivial to show that the system converges to the unique fixed
point. In the next two sections, we study the stability and
structure of the limit cycle solution when w̄ > 2.

3.2 Stability of Limit Cycle
The analysis of the stability of limit cycles is complicated
and few analytical tools exist. Fortunately, a wealth of computational tools are available [14], and it is possible to compute the periodic solution of the system and determine its
stability properties numerically. A limitation of the computational approach is that it requires sweeping the different
parameters of the model to completely characterize the dynamics. However, our task is greatly simplified by the fact
that the dynamics of the normalized model is completely
determined by the two parameters w̄, and g. We proceed by
defining stability of limit cycles.
Let X ∗ denote the set of points in the state space belonging to the limit cycle. We define an ǫ-neighborhood of X ∗
by
Uǫ = {x ∈ Rn | dist(x, X ∗ ) < ǫ},

where dist(x, X ∗ ) is the minimum distance from x to a point
in X ∗ ; i.e., dist(x, X ∗ ) = inf y∈X ∗ ||x − y||.
3
Formally, a periodic solution is said to be a limit cycle
if there are no other periodic solutions sufficiently close to
it. In other words, a limit cycle corresponds to an isolated
periodic orbit in the state space [14].

(i) stable if for any ǫ > 0, there exists a δ > 0 such that
x(0) ∈ Uδ ⇒ x(t) ∈ Uǫ , ∀t ≥ 0.
(ii) locally asymptotically stable if it is stable and δ can
be chosen such that
x(0) ∈ Uδ ⇒ lim dist(x(t), X ∗ ) = 0.
t→∞

Figure 4 illustrates the local asymptotical stability of our
system for a choice of parameters: orbits initiated from
points close enough to the limit cycle are attracted to it.
To proceed, let x(t) = (W̃ (t), α̃(t), q̃(t))T denote the state
space of the fluid model equations at (11)–(14). It is convenient to represent the fluid model as:
ẋ(t) = F (x(t), u(t − 1)),

u(t) = 1{cx(t)>0} ,

(16)

where c = [0, 0, 1] and u(t) = p̃(t) is the system feedback.
Poincaré map. We analyze the stability of the limit cycle
via the ‘Poincaré map’, which we introduce after making
some definitions. Define the switching plane as S = {x ∈
R3 : cx = 0} and let S + = {x ∈ R3 : cx > 0} and S − =
{x ∈ R3 : cx < 0} (see Fig. 5 for an illustration). Note that
the switching plane is the q̃ = 0 (equivalently, q = K) plane
and corresponds to the DCTCP marking threshold. The
limit cycle crosses the switching plane twice in each period,
once from S + (at the point x∗α ) and once from S − (at the
point x∗β ).
The Poincaré map traces the evolution of the system at
the times when its trajectory crosses the switching plane in
a given direction. More precisely, let the successive intersections of the trajectory x(t) with S in direction S + to S −
be denoted by xi . The Poincaré map xi+1 = P (xi ), maps
the ith intersection to the subsequent one. Note that the
Poincaré map is well-defined for our system, because equations (11)–(14) guarantee that starting from any point in S +
or S − , the trajectory will eventually intersect with S.
The fixed point of the Poincaré map corresponds to the
intersection of the limit cycle with the switching plane, say
at x∗α . Therefore, local stability of the Poincaré map at x∗α
implies local stability of the limit cycle. We refer to [4, 10,
14, 22] for more details on the Poincaré map technique.
Next, there are two main steps to establish:
Step 1. The Poincaré map is locally stable. Theorem 1,

Qmin & Qmax (fraction of CR*)

0.3
0.2
0.1

Qmax: Increasing g

g = 0.01
g = 0.05
g = 0.1
g = 0.15
g = 0.2
g = 0.25

0

−0.1
Qmin: Increasing g

−0.2
0

50

100
150
w̄ (packets)

200

250

Figure 6: Limit cycle stability (Theorem 1).
Figure 7: Queue undershoot and overshoot.
which is an adaptation of Theorem 3.3.1 in [22] to our setting, provides a necessary and sufficient condition for local
stability of the Poincaré map, and consequently, the limit
cycle.
Step 2. Verify that our system satisfies the condition of
Theorem 1 for a wide range of w̄ and g.
Before proceeding with the statement of Theorem 1, we
need the following definitions. Let x∗ (t) denote the trajectory of the limit cycle of system (16). Assume that x∗ (t)
traverses the switching plane from S + to S − at time t0 = 0;
i.e., x∗ (0) = x∗α , and that the period of the limit cycle is
T = (1 + hα ) + (1 + hβ ) with hα > 0 and hβ > 0, where
1 + hα (resp. 1 + hβ ) is the time taken for the trajectory to
move from x∗α to x∗β (resp. from x∗β to x∗α ). For notational
convenience, define uα = 0 and uβ = 1. Let

Z T

F (x∗α , uβ )c 
∗
J
(x
(s),
u(s
−
1))ds
,
exp
Z1 = I −
F
cF (x∗α , uβ )
1+hα
Z


1+hα
F (x∗β , uα )c 
Z2 = I −
exp
JF (x∗ (s), u(s − 1))ds ,
∗
cF (xβ , uα )
0

where JF is the Jacobian matrix of F with respect to x, and I
is the identity matrix. The integral of the matrix JF is entry
wise. We assume that cF (x∗α , uβ ) 6= 0 and cF (x∗β , uα ) 6=
0; i.e., x∗ (t) is nontangent with the switching plane at the
traversing points. Note that Z1 and Z2 are 3 × 3 matrices.

Theorem 1. The Poincaré map (and its associated limit
cycle) is locally asymptotically stable if and only if
ρ(Z1 Z2 ) < 1.
Here, ρ(·) is the spectral radius.
A proof sketch is provided in Appendix A.
Verification. We use Theorem 1 to verify the stability of
DCTCP’s limit cycle. Since Z1 and Z2 do not have a closed
form, we sweep the parameters w̄ and g in the ranges of interest and compute ρ(Z1 Z2 ) numerically. This has been done
in Fig. 6 for the range g ∈ [0.001, 1], and w̄ ∈ [2.01, 1000].
Throughout this range, ρ < 1, and (local) stability is verified. We conjecture that the limit cycle is actually globally
stable for all g ∈ (0, 1], w̄ > 2.

3.3 Steady State Throughput & Delay
In this section, we study the key performance metrics of
throughput and delay of DCTCP, by analyzing the limit
cycle solution of equations (11)–(14).
A standard method for approximately determining the
amplitude and frequency of limit cycles is the so-called ‘Describing Function (DF) Method’ [10]. Unfortunately, the DF

method applied to system (11)–(14) yields very poor results.
This is because a key assumption of the DF method—that
the limit cycle can be well-approximated by a single frequency sinusoid—does not hold for this system. We therefore evaluate the exact limit cycle solutions numerically.

3.3.1

100% Throughput

The first question we consider is: How much buffering is
required for DCTCP to achieve 100% throughput? Since
queue underflow must be avoided for 100% throughput, we
need to determine how large the queue size oscillations are
about the operating point K.
Assume {(W̃ (t), α̃(t), q̃(t))|0 ≤ t < T } is the limit cycle of
our system (with period T ). Define Qmin = min0≤t<T q̃(t),
and Qmax = max0≤t≤T q̃(t) to be the maximum and minimum excursions of the (normalized) queue size during a
period. In Fig. 7, we plot Qmin and Qmax against w̄ for
some values of g.
There are three key observations:
(i) The queue overshoot is not sensitive to g and increases
as w̄ decreases. This follows because the queue overshoot
is primarily determined by the rate at which flows increase
their window size, and as w̄ decreases, the window increase
rate of 1 packet/RTT per source becomes increasingly large
compared to the bandwidth-delay product.
(ii) There is a worst case w̄ (about 12-16 packets for the
range of g values shown in Fig. 7) at which the queue undershoot is maximized. This implies an interesting property
of DCTCP: as per-flow window sizes increase—for example, due to higher and higher link speeds—DCTCP requires
less buffers as a fraction of the bandwidth-delay product to
achieve high utilization.
(iii) The amplitude of queue undershoot increases as g increases. This is to be expected: high values of g cause large
fluctuations in α which inhibit DCTCP’s ability to maintain
a steady sending rate (see Fig. 3 for an example).4
Choosing K. As seen in Fig. 7, Qmin ' −0.15 when g is
sufficiently small (the choice of g is discussed next). Therefore, to avoid queue underflow, we require K > |Qmin |CR∗ '
0.15CR∗ . Substituting R∗ = d+K/C in this inequality gives
the following guideline:
K ≈ 0.17Cd.

(17)

4
It is important to note that although α will cease to oscillate as g → 0, queue size oscillations cannot be made
arbitrary small by lowering g. In fact in Fig. 7, all g ≤ 0.01
values basically produce the same curve.

60

g = 0.01
g = 0.05
g = 0.1
g = 0.15
g = 0.2
g = 0.25

1

Increasing g

40

w̄

20
0
0

200

400
600
w̄ (packets)

800

1000

Figure 8: Limit cycle period of oscillations.
In words, about 17% of the bandwidth-delay product of
buffering is needed for 100% throughput; any more available
buffer can be used as headroom to absorb bursts. Note that
this value for K is quite close to the guideline K > (1/7)Cd,
suggested in [1]. This also confirms the validity of the simple
sawtooth model for small g.
Limit cycle period & an upper limit for g. Figure 8
plots the period of oscillations of the
√ limit cycle. The figure
suggests that the period grows as w̄ (for small g). Now,
the marking process {p(t − 1)} is a periodic ‘signal’ (with
period equal to the period of the limit cycle), which is input
to the low-pass filter defined at equation (12). Since the
filter has a cutoff frequency of about g, for it to be effective,
it is necessary that g be smaller
√ than the primary oscillation
frequency of the signal, 1/ w̄. But w̄ = (Cd + K)/N and
is maximized for N = 1. Therefore, we get the following
bound:
1
g/ √
.
(18)
Cd + K
Appendix C provides a different justification for (18) based
on the Hybrid Model, which we introduce in Section 4. We
will revisit the matter of choosing g in Section 4.2, where we
obtain a lower limit for g.

3.3.2

Throughput-Delay Tradeoff

We have seen that if K is at least 17% of the bandwidthdelay product, DCTCP achieves 100% throughput. However, when we require very low queueing delays, or when
switch buffers are extremely shallow, it may be desirable to
choose K even smaller than this. Inevitably, this will result
in some loss of throughput. We are interested in quantifying how much throughput is lost, and in effect, deriving a
throughput-delay tradeoff curve for DCTCP.
A more accurate model of the switch queue is needed to
study throughput loss. Equation (13) ignores the fact that
a real queue will never become negative. To account for this
and capture the correct behavior when queues underflow, we
define ψ , K/(Cd), and replace (13) with:

−ψ
 1 W̃ (t) − 1
q̃(t) > 1+ψ
,
dq̃
w̄ (1+q̃(t))


=
W̃
(t)
−ψ
max w̄1 (1+q̃(t)) − 1, 0
dt
q̃(t) = 1+ψ .

We can now explore the limit cycle solution as we vary ψ,
and compute the average throughput (over period T ):
Z
W̃ (t)
1 T
T hroughput =
dt.
T 0 w̄(1 + q̃(t))

0.98
g = 0.01
g = 0.05
g = 0.1
g = 0.1
g = 0.15
g = 0.2

0.96
0.94

Increasing g

0.92
0.9
0

0.05

0.1
0.15
0.2
ψ (Delay in RTT)

0.25

0.3

Figure 9: Worst Case Throughput vs Delay.
10000

Throughput (Mbps)

Period (RTT)

80

Throughput (Worst Case)

100

Lower Bound from
DCTCP Fluid Model

9500
9000
8500

DCTCP (N = 2)
DCTCP (N = 25)
TCP (N = 2)
TCP (N = 25)

8000
7500
0

5
10
15
20
Marking Threshold K (% of BDP)

25

Figure 10: Throughput vs marking threshold K in
ns2 simulation; K is varied from 4 to 100 packets
(1-25% of the BDP). Note that as predicted by the
analysis, the throughput remains higher than 94%
even for K as small as 1% of the BDP.
In Fig. 9, we plot the worst case throughput as ψ is varied.
At each value of ψ, the value of w̄ which yields the lowest
throughput is used. It should be noted that since the queue
size is maintained near the marking threshold, the ψ axis
also (roughly) corresponds to the average queueing delay.
As expected, when ψ ' 0.17, 100% throughput is achieved
(for small g). As ψ is lowered, the throughput decreases,
but is always at least 94% for g < 0.1. This indicates
that very small marking thresholds can be used in DCTCP,
with only a minor loss in throughput. We verify this next
through ns2 simulations.

3.3.3

Simulations

We use ns2 simulations to evaluate the throughput achieved
as the marking threshold K is varied. We choose C =
10Gbps and d = 480µs, for a bandwidth-delay product of
400 packets (each 1500 Bytes), and set g = 0.05. We consider two cases with N = 2 and N = 25 long-lived flows.
The results are shown in Fig. 10. For reference, we also
report the results for TCP in the same scenarios.
The simulations clearly show that DCTCP achieves high
throughput, even with marking threshold as low as 1% of the
bandwidth-delay product. In all cases, we find the throughput is indeed higher than the worst case lower bound predicted by the fluid model. Of course, we see a much worse
throughput loss with TCP. An interesting observation is
that unlike TCP, whose throughput improves as we increase

! "#

&"'()*%+",$-%

the number of flows, DCTCP gets lower throughput with
N = 25 flows than N = 2 flows. This is expected from
our analysis, because with DCTCP, the worst case queue
size fluctuations (and throughput loss) occur when the perflow window size is around 10-20 packets (see Fig. 7 and
observation (ii) in Section 3.3.1).

DCTCP uses the multi-bit information derived from estimating the fraction of marked packets to reduce its window
by factors smaller than two. As we have seen in the previous section, this allows it to very efficiently utilize shallow
buffers, achieving both high throughput and low queueing
delays. However, the reduced multiplicative decrease factors mean slower convergence times: it takes longer for a
flow with a large window size to relinquish bandwidth to a
flow with a small window size.
Since the convergence time is proportional to the RTT for
window-based algorithms and the RTTs in a data center are
only a few 100s of microseconds, it is argued in [1] the actual
time to converge is not substantial relative to the transfer
time of large data files. But an analysis of convergence time
has not been conducted in [1]. Based on simulations, [1]
reports that the convergence time of DCTCP is a factor 2-3
slower than TCP. The results of this section show that this
is, indeed, correct in general.
Our aim in this section is to derive rigorous bounds for
the rate of convergence of DCTCP. We consider how fast
N DCTCP flows with identical RTTs5 , starting with arbitrary window sizes and values of α, converge to their share
of the bottleneck bandwidth. Since this is an analysis of the
system in transience, the fluid model of the previous section is inadequate. Instead, we use a hybrid (continuousand discrete-time) model based on the AIMD models introduced in [5, 17]. A key difference between our model and
the AIMD models is that ours is non-linear because it models the DCTCP-style multiplicative decrease, whereas the
models in [5, 17] and are linear since they correspond to a
constant decrease factor (equal to 2 for TCP).

5

This ensures that in equilibrium, each flow gets (1/N )th of
the bottleneck bandwidth. See Section 5 for a discussion of
the bias against flows with longer RTTs.

! ! ""# !# $
! ! ""# #
! ! ""# # ! ""# #
!

!"#$%
!"$%%"
!"

#"

## "! #" "! #
! ! ! " !!
$

" !!

"

"

$

!"#$%

"

$%

Figure 11: Hybrid Model. The
P window sizes are
shown for 2 flows. Note that
Wi (Tk ) = Wmax for
all k.
and we have:
Wi (Tk+1 ) = (1 −

αi (Tk )
)Wi (Tk ) + ∆Tk − 1.
2

(20)

It only remains to specify the evolution of αi (t). This is
simply given by:
dαi
= g(p(t) − αi (t)).
dt
In particular, αi (Tk+1 ) is the solution of the following initial
value problem at time ∆Tk :

4.1 Hybrid Model
Consider N DCTCP flows whose window size and value
of α at time t (measured in units of RTT) are denoted by
Wi (t) and αi (t). Assume the window sizes of the N flows
are synchronized; i.e., each flow reduces its window at every
congestion event. See Fig. 11 for
P an illustration.
Let Wmax = Cd + K. When N
i=1 Wi (t) < Wmax , all window sizes increase linearly with slope 1 packet/RTT. Once
PN
i=1 Wi (t) = Wmax , a congestion event occurs and each
flow cuts its window size according to (4) using its current
value of α. Note that packets are marked (p(t) = 1) for 1
RTT after the window reductions because of the feedback
delay. Assume the kth congestion
PN event occurs at time Tk .
Since the total reduction in
i=1 Wi (t) at Tk is equal to
PN
W
(T
)α
(T
)/2,
which
is
regained at the rate of N
i
i
k
k
i=1
packets/RTT, the duration of the kth “congestion epoch” is
PN
Wi (Tk )αi (Tk )
,
(19)
∆Tk , Tk+1 − Tk = 1 + i=1
2N

!! ""# !! #

!! ""# #!! ""# #
$

./01%/2345"'6%74)891%

4. ANALYSIS: CONVERGENCE

!! ""# #

dx
= g(p(t) − x(t)),
dt
(

p(t) =

1
0

x(0) = αi (Tk )

0≤t<1
t≥1

Using this, it is not difficult to show:
αi (Tk+1 ) = e−g∆Tk (eg − 1 + αi (Tk )).

4.2

(21)

Rate of Convergence

We make the following assumptions regarding the system
parameters:
N ≥ 2,

Wmax ≥ 2N,

g≤ √

1
.
Wmax

(22)

The first two assumptions are natural for studying convergence, and the third is in accordance with the guidelines of the previous section regarding steady state. Let
W ∗ = Wmax /N . The main result of this section is given by
the following theorem.

Figure√12: ns2 simulation of convergence time for 2 flows. The chosen g values for DCTCP correspond to:
(b) 1/ Wmax , (c) 5/Wmax , and (d) 1/Wmax .
Theorem 2. Consider N DCTCP flows evolving according to (20) and (21), with parameters satisfying (22). Suppose that Wi (0) and αi (0) are arbitrary. Let 0 < α∗ ≤ 1 be
the unique positive solution of
∗

∗

α∗ = e−g(1+W α /2) (eg − 1 + α∗ ).

(23)

∗



6

|Wi (Tn ) − W | < 2Wmax 1 + g n

2



e

−β(Tn −TP 2 )

for all 1 ≤ i ≤ N , where:
 − log(1 − α∗ /2) 
β = min g,
,
1 + W ∗ α∗ /2
TP 2 =

,

(24)

(27)

Comparison with TCP. As mentioned in the beginning of
this section, DCTCP converges slower than TCP. But how
much slower is DCTCP? It is straight forward to show that
the convergence rate of TCP is given by:
βT CP =

(25)

log 2
2 log 2
.
≈
1 + W ∗ /2
W∗

Therefore, (25) and (26) imply that for g properly chosen
large enough:

log(2W ∗ /g 6 )
+ 2(1 + W ∗ /2).
g

The proof of Theorem 2 is given in Section 4.4. Here, we
make a few remarks about the convergence rate. The crucial
term in (24) is the exponential decay e−βTn . The convergence rate is therefore chiefly determined by (25), which
has the following interpretation. Two things occur (simultaneously) during convergence of DCTCP: (i) the αi (Tn )
converge to α∗ , and (ii) the Wi (Tn ) converge to W ∗ . It is
shown in the proof of Theorem 2 that (i) happens with rate
g, and (ii) with rate γ = − log(1 − α∗ /2)/(1 + W ∗ α∗ /2).
The overall convergence rate is determined by the slower of
the two.
Lower √
limit for g. We have seen that g should be smaller
than 1/ Wmax to not adversely affect steady state performance. Equation (25) suggests a lower bound for g, in order
to not slow down convergence. Note that:
−2 log(1 − α∗ /2)
1
2 log 2
<γ≈
<
.
∗
W
W ∗ α∗
W∗

5
1
.
/g/ √
Wmax
Wmax

∗

Then Wi (Tn ) → W (defined above), and αi (Tn ) → α for
all 1 ≤ i ≤ N as n → ∞. Moreover:
∗

of flows N , and so don’t know W ∗ . However, in data centers, there are typically a small number of large active flows
on a path6 . Therefore, we mainly need to focus on the small
N case, for which convergence is also slowest. With these
considerations, we propose the following guideline:

(26)

Therefore if g > (2 log 2)/W ∗ , it will not limit the convergence rate. Of course, in practice, we don’t know the number

βDCT CP < βT CP < (2 log 2)βDCT CP ≈ 1.4 × βDCT CP .
This means that the DCTCP convergence rate is at most
40% slower than TCP. It is important to note however that
this is a statement about the asymptotic rate of convergence.
In practice, all the terms present in (24) affect the convergence time. Therefore, in simulations, the actual time to
converge is about a factor 1.5-2 larger (see also [1]).
Bounds on α∗ . The following bounds are proven in Appendix C.
r
r
1
2
2
∗
−g <α <
+ g.
2 W∗
W∗

4.3

Simulations

We have verified the results of our analysis using extensive
ns2 simulations. Figure 12 shows a representative example
6
For example, measurements reported in [1] show at most 4
flows larger than 1MB concurrently active at a server in
any 50ms period. Note that only the large flows need to be
considered, as only they can possibly converge.

with 2 flows. The choice of parameters C = 10Gbps, d =
200µs, and K = 35 (or 17% of the BDP) gives Wmax ≈ 200
packets. One flow starts at the beginning of the simulation,
and grabs all the available capacity (its window size reaches
200). At time 1sec, a second flow begins with a window of 1
packet, and we are interested in how long it takes for both
window sizes to get within 10% of the fair share value (100
packets) for the first time. In order to have the worst case
convergence time with DCTCP, we begin the second flow
with α = 1, whereas the first flow has α = 0 before time
1sec; so the second flow actually cuts its window by much
larger factors initially.
√
We test three values of g for DCTCP. With g = 1/ Wmax ,
as expected from the analysis, the α variables converge much
quicker√than the window sizes (about 5x faster). Reducing
g to 5/ Wmax , the convergence times of the α and window
sizes get closer, with the α still converging about twice as
fast. Here, the increase in convergence time is small (67ms
up from 55ms). But when g is further reduced to 1/Wmax ,
the convergence of α and window sizes take about the same
amount of time, showing that the limiting factor is now the
convergence of α. In this case, the small value of g significantly increases the total convergence time (185ms). A final
observation is that when g is appropriately chosen according to (27), the convergence time of DCTCP is indeed up to
about a factor of 2 longer than TCP.

In particular, it is easy to check that given (22), g 6 TP 2 ≤ g,
which implies that for Tk ≥ TP 2 :
ζk , g 6 ke−g(Tk −TP 2 ) ≤ g 6 Tk e−g(Tk −TP 2 ) ≤ g.

Phase 3. The third and final phase begins with Tk ≥ TP 2 .
In Phase 3, the αi values are all close to α∗ , and the sources
essentially perform AIMD with a decrease factor of α∗ /2.
The following Lemma is the key ingredient for convergence
in Phase 3.
Lemma 2. For Tk ≥ TP 2 , and any 1 ≤ i, j ≤ N :
|Wi (Tk+1 )−Wj (Tk+1 )| ≤ e−γ∆Tk |Wi (Tk )−Wj (Tk )|+2Wmax ζk ,
(33)
where γ = − log(1 − α∗ /2)/(1 + W ∗ α∗ /2).
Proof. Using (20), (31), and (32), we have:
α∗
)|Wi (Tk ) − Wj (Tk )| +
2
|Wi (Tk )|
|Wj (Tk )|
|αi (Tk ) − α∗ | +
|αj (Tk ) − α∗ |,
2
2
α∗
)|Wi (Tk ) − Wj (Tk )| + Wmax ζk .
≤ (1 −
2

|Wi (Tk+1 ) − Wj (Tk+1 )| ≤ (1 −

Noting that

4.4 Proof of Theorem 2
The key idea in proving Theorem 2 is to consider convergence as happening in three separate phases.
Phase 1. Initially, the αi values get close to each other. In
fact (21) implies that for any i and j:
|αi (Tn ) − αj (Tn )| ≤ e−gTn |αi (T0 ) − αj (T0 )| ≤ e−gTn (28)
We have the following simple Lemma.
P
Lemma 1. Let ᾱ(Tk ) = N
i=1 αi (Tk )/N . Then:

(32)

∆Tk ≤ 1 + W ∗ α∗ /2 + W ∗ ζk /2,

(34)

the result follows from:
∗

(1 − α∗ /2) ≤ e−γ(∆Tk −W ζk /2) ≤ e−γ∆Tk (1 + ζk ),
where the last inequality is true because:
∗

∗

∗

eγW ζk /2 ≤ e−ζk log(1−α /2)/α

≤ eζk log 2 = 2ζk ≤ 1 + ζk .

(35)

This holds for ζk ≤ 1, which we have from (32).

|αi (Tn ) − ᾱ(Tn )| ≤ e−gTn

for all 1 ≤ i ≤ N .

Proof. This follows by applying the triangle inequality
and using (28).

We can now prove Theorem 2. Let r , inf{k|Tk ≥ TP 2 }
and β , min(g, γ). Similar as we did for Proposition 1, we
iterate (33) backwards starting from n ≥ r to get:

We take Phase 1 to last until time TP 1 , log(2W ∗ )/g, so
that:
1 −g(Tk −TP 1 )
e
.
(29)
|αi (Tk ) − ᾱ(Tk )| ≤ e−gTk =
2W ∗

|Wi (Tn ) − Wj (Tn )|
n−1

X β∆T  −β(T −T )
n
P2
k
≤ Wmax eβ(Tr −TP 2 ) + 2g 6
ke
e
.

Phase 2. The second phase begins with Tk ≥ TP 1 . In this
phase, the αi converge to a positive constant α∗ . The following proposition is the main convergence result for Phase 2
and is proved in Appendix B.

But:

Proposition 1. For n ≥ 1, and all 1 ≤ i ≤ N :
|αi (Tn ) − α∗ | ≤ A0 ne−g(Tn −TP 1 ) ,

(30)

∗

where A0 = e2g(1+W /2) .
We take Phase 2 to last until time
TP 2 , TP 1 + 2(1 + W ∗ /2) − 6 log(g)/g,
so that:
|αi (Tk ) − α∗ | ≤ A0 ke−g(Tk −TP 1 ) = g 6 ke−g(Tk −TP 2 ) . (31)

k=r

∗

∗

∗

eβ(Tr −TP 2 ) ≤ eγ(1+W /2) ≤ e− log(1−α /2)/α ≤ elog 2 = 2,
and using (34), (35), and (32):
n−1
X
k=r

keβ∆T k ≤

n−1
X

∗

∗

∗

keγ(1+W α /2) eγW ζk /2

k=r

≤ (1 − α∗ /2)(1 + g)
∗

1
N

PN

n−1
X

k < n2 .

k=r

Noting that |Wi (Tn ) − W | ≤
j=1 |Wi (Tn ) − Wj (Tn )|,
we have established (24) for n ≥ r. The result is trivial for
n < r, completing the proof.

5.1 Simulations
We consider the following ns2 simulation to investigate
RTT-fairness. Four flows share a single 10Gbps bottleneck
link in a “dumbbell” topology. The first two of these flows
have a fixed RTT of 100µs. The RTT of the other two flows
is varied from 100µs to 1ms. We measure the throughput for
all flows in each test, and compute the ratio of the throughput of the first two flows to that of the second two flows, as
a function of the RTT ratio.
The DCTCP parameters chosen are K = 35 packets and
g = 1/16. For reference, we compare the results with TCP
using the DCTCP style “Drop-tail” (0–1) marking, and also
TCP with RED marking7 . The results are shown in Fig.
13. The algorithm labeled “DCTCP–Improved Fairness” is
described in the next section.
As expected, DCTCP does exhibit a bias against flows
with longer RTTs. The simulations indicate that DCTCP’s
RTT-fairness is better than TCP–Drop-tail, which has approximately squared RTT-fairness (T hroughput ∝ RT T −2 ),
but worse than TCP–RED, which has approximately linear
RTT-fairness (T hroughput ∝ RT T −1 ). In this and other
simulations not reported here, we observed that when the
RTT ratio is moderate, DCTCP exhibits slightly worse than
linear RTT-fairness, but tends to squared RTT-fairness as
the RTT ratio becomes large. Apparently, the smooth window adjustments made by DCTCP help alleviate some of the
synchronization effects caused by the 0–1 marking strategy,
thereby improving DCTCP’s RTT-fairness.

7
For RED, the marking probability increases linearly
from 0 to 10% as the average queue length (EWMA with
weight 0.1) increases from 30 to 100 packets. These parameters are chosen to ensure stability of RED in this configuration and yield roughly the same queue lengths as DCTCP.

2

10

TCP with DCTCP Marking
TCP with RED Marking
DCTCP
DCTCP−Improved Fairness

1

It is well-known that TCP has a bias against flows with
long round-trip times; i.e., flows with longer RTTs get a
lower share of the bottleneck bandwidth when competing
with flows with shorter RTTs [11, 6, 2, 3, 23]. This is due to
the fact that the rate at which flows increase their window
size is inversely proportional to their RTT (one packet per
RTT). Therefore, flows with short RTTs grab bandwidth
much more quickly than flows with long RTTs and settle
at a higher rate in steady-state. In fact, it has been shown
that the throughput achieved by a TCP flow is inversely
proportional to RT T θ with 1 ≤ θ ≤ 2 [11].
Another important factor which affects RTT-fairness is
synchronization between flows. Typically, higher synchronization, in terms of detecting a loss or mark event, leads
to worse RTT-fairness. In fact, it has been argued that active queue management (AQM) schemes like RED [7] which
avoid synchronization by probabilistically dropping (or marking) packets improve RTT fairness compared to Drop-tail
queues [2, 23].
Since DCTCP employs the same additive increase mechanism used by TCP, it is expected that DCTCP also exhibits
a bias against flows with longer RTTs. Moreover, the active queue management of DCTCP is (by design) similar
to Drop-tail (albeit with marking instead of dropping) and
prone to causing synchronization. This makes a study of
how well DCTCP handles RTT diversity important.

2

Throughput Ratio (Thrput /Thrput )

5. RTT-FAIRNESS

Squared
RTT−fairness

1

10

Linear RTT−fairness
0

10 0
10

1

RTT Ratio (RTT /RTT )
2

10

1

Figure 13: RTT-fairness in ns2 simulation: 2 groups
each with 2 flows are activated. Flows in group 1
have RT T1 = 100µs. The RT T for flows in group 2
(RT T2 ) is varied from 100µs to 1ms. Note the loglog scale.

5.2

DCTCP–Improved Fairness

The DCTCP fluid model (Section 2.2) suggests a very simple change which considerably improves the RTT-fairness of
DCTCP. We will first state this change, contrasting it with
the DCTCP algorithm defined in Section 2.1. We will then
explain how the fluid model suggests this change.
Recall that the DCTCP algorithm reduces the window
size according to
W ← W (1 − α/2)
in response to a marked ACK, and that this is done at most
once for each window of data. Instead, we propose subtracting α/2 from the window size for each marked ACK,
resulting in the following simple window update equation:
for each received ACK:
(
1/W
if ECN = 0
W ←W +
(36)
1/W − α/2
if ECN = 1
Note that a full window of marked ACKs will cause a reduction of about W α/2, which is the same amount DCTCP
would reduce the window size upon receiving a mark. A nice
feature is that since (36) applies to every ACK, it does not
require maintaining extra state to prevent window reductions from happening more than once per window of data.
The simulation results in Fig. 13 confirm that this simple change significantly improves RTT-fairness (especially
at high RTT ratios), and does indeed achieve linear RTTfairness. In fact, it even achieves a slightly better RTTfairness than TCP–RED.
Connection with Fluid Model. Consider N flows with
round-trip times RT Ti (1 ≤ i ≤ N ) in steady-state. Recall
the source side equations:
Wi (t)αi (t)
dWi
1
−
p(t − RT Ti ),
=
dt
RT Ti
2RT Ti
g
dαi
(p(t − RT Ti ) − αi (t)) ,
=
dt
RT Ti

(37)
(38)

where, for simplicity, we neglect the contribution of the
(time-varying) queueing delay to the RTT. Note that each
flow sees a time-delayed version of the common marking

process p(·). Therefore, the αi (·) processes—each given by
passing p(·) through a low pass filter—all oscillate around
the same value, namely, the duty cycle of p(·). This leads
to the following key observation based on (37): the average
window size for flow i does not depend on RT Ti ; i.e., the
fluid model suggests that all flows should on average have
the same window size, thereby achieving linear RTT-fairness
(because T hroughputi = Wi /RT Ti ).
However, as seen in Fig. 13, simulation results indicate
that the actual RTT-fairness is worse than linear. The key
source of discrepancy between the fluid model and simulations lies in the continuous dynamics present in the fluid
model.8 In particular, let us consider the manner in which
the window size decreases in (37). While p(t − RT Ti ) = 1,
the window steadily decreases with rate Wi (t)αi (t)/(2RT Ti ).
In contrast, the packet-level algorithm reduces its window
instantaneously upon receiving a mark. This suggests the
change previously discussed to the DCTCP algorithm in
equation (36), which bridges the gap between the packetlevel and fluid dynamics.
Intuitively, this change improves the RTT-fairness by allowing flows with long RTTs to reduce their window sizes (on
average) by a smaller factor compared to flows with short
RTTs. This is because in a typical congestion event, flows
with short RTTs receive marks earlier and reduce their window sizes, thereby relieving congestion. In such cases, less
than a full window of packets from a flow with a long RTT
will be marked, and therefore, the net decrease to its window size based on (36) will be smaller than the standard
DCTCP window reduction, W α/2.

6. FINAL REMARKS
We analyzed DCTCP, a TCP variant for data centers
which has recently been proposed in [1]. Our analysis shows
that DCTCP can achieve very high throughput while maintaining low buffer occupancies. Specifically, we found that
with a marking threshold, K, of about 17% of the bandwidthdelay product, DCTCP achieves 100% throughput, and that
even for values of K as small as 1% of the bandwidth-delay
product, its throughput is at least 94%. While DCTCP
converges slower than TCP, we found that its convergence
rate is no more than a factor 1.4 slower than TCP. We also
evaluated the RTT-fairness of DCTCP, and found a simple
change to the algorithm, which considerably improves its
RTT-fairness.
In future, it is worth understanding the behavior of DCTCP
in general networks. The work in this paper has focused on
the case where there is a single bottleneck.

Acknowledgments
Mohammad Alizadeh and Adel Javanmard are supported by
Caroline and Fabian Pease Stanford Graduate Fellowships.
We thank the anonymous reviewers whose comments helped
us improve the paper.

8
We emphasize that the mentioned discrepancy affects the
accuracy of the fluid model only for heterogenous RTTs. As
shown in Section 2.2, the fluid model is very accurate when
sources have identical RTTs.

7.

REFERENCES

[1] M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye,
P. Patel, B. Prabhakar, S. Sengupta, and M. Sridharan.
Data center TCP (DCTCP). In Proceedings of SIGCOMM
’10, pages 63–74, New York, NY, USA, 2010. ACM.
[2] E. Altman, C. Barakat, E. Laborde, P. Brown, and
D. Collange. Fairness analysis of TCP/IP. In Proceedings of
the 39th IEEE Conference on Decision and Control, 2000.,
volume 1, pages 61 –66 vol.1, 2000.
[3] E. Altman, T. Jiménez, and R. Núñez Queija. Analysis of
two competing TCP/IP connections. Perform. Eval.,
49:43–55, September 2002.
[4] K. Astrom, G. Goodwin, and P. Kumar. Adaptive Control,
Filtering, and Signal Processing. SpringerVerlag, 1995.
[5] F. Baccelli and D. Hong. AIMD, fairness and fractal scaling
of TCP traffic. In INFOCOM, 2002.
[6] P. Brown. Resource sharing of TCP connections with
different round trip times. In INFOCOM, 2000.
[7] S. Floyd and V. Jacobson. Random early detection
gateways for congestion avoidance. IEEE/ACM Trans.
Netw., 1(4):397–413, 1993.
[8] C. V. Hollot, V. Misra, D. Towsley, and W. bo Gong. A
control theoretic analysis of RED. In Proceedings of IEEE
INFOCOM, pages 1510–1519, 2001.
[9] C. V. Hollot, V. Misra, D. Towsley, and W. Gong. Analysis
and Design of Controllers for AQM Routers Supporting
TCP Flows. IEEE Transactions on Automatic Control,
47:945–959, 2002.
[10] H. Khalil. Nonlinear Systems. Prentice Hall, 2002.
[11] T. Lakshman and U. Madhow. The performance of
TCP/IP for networks with high bandwidth-delay products
and random loss. Networking, IEEE/ACM Transactions
on, 5(3):336 –350, June 1997.
[12] H. Low, O. Paganini, and J. C. Doyle. Internet congestion
control. IEEE Control Systems Magazine, 22:28–43, 2002.
[13] V. Misra, W.-B. Gong, and D. Towsley. Fluid-based
analysis of a network of AQM routers supporting TCP
flows with an application to RED. SIGCOMM Comput.
Commun. Rev., 30(4):151–160, 2000.
[14] A. H. Nayfeh and B. Balachandran. Applied Nonlinear
Dynamics: Analytical, Computational, and Experimental
Methods. Wiley-VCH, 2007.
[15] The Network Simulator NS-2.
http://www.isi.edu/nsnam/ns/.
[16] K. Ramakrishnan, S. Floyd, and D. Black. RFC 3168: the
addition of explicit congestion notification (ECN) to IP.
[17] R. Shorten, D. Leith, J. Foy, and R. Kilduff. Analysis and
design of AIMD congestion control algorithms in
communication networks. Automatica, 41(4):725 – 730,
2005.
[18] R. Shorten, F. Wirth, and D. Leith. A positive systems
model of TCP-like congestion control: asymptotic results.
IEEE/ACM Trans. Netw., 14(3):616–629, 2006.
[19] R. Srikant. The Mathematics of Internet Congestion
Control (Systems and Control: Foundations and
Applications). SpringerVerlag, 2004.
[20] V. Vasudevan, A. Phanishayee, H. Shah, E. Krevat, D. G.
Andersen, G. R. Ganger, G. A. Gibson, and B. Mueller.
Safe and effective fine-grained TCP retransmissions for
datacenter communication. In Proceedings of SIGCOMM
’09, pages 303–314, New York, NY, USA, 2009. ACM.
[21] A. Vishwanath, V. Sivaraman, and M. Thottan.
Perspectives on router buffer sizing: recent results and open
problems. SIGCOMM Comput. Commun. Rev., 39:34–39,
March 2009.
[22] Q.-G. Wang, T. H. Lee, and C. Lin. Relay Feedback:
Analysis, Identification and Control. SpringerVerlag, 2003.
[23] L. Xu, K. Harfoush, and I. Rhee. Binary Increase
Congestion Control (BIC) for Fast Long-Distance
Networks. In INFOCOM, 2004.

APPENDIX
A. PROOF SKETCH OF THEOREM 1

we get:

The proof proceeds by computing the Jacobian of the
Poincaré map at its fixed point x∗α and requiring it to be
stable. Define Bǫ (x∗0 ) , {ξ ∈ R3 : ||ξ − x∗0 || ≤ ǫ}. We need
the following lemma to verify that starting from a neighborhood of x∗α , successive switching can occur and thereby the
Poincaré map is well-defined.

δhα = −

c exp

Lemma 3. Assume that F (x, u) is infinitely differentiable
with respect to x. For any given δ > 0, there exists ǫδ > 0
such that the trajectory of x(t) starting from any traversing
point in Bǫδ (x∗α ) ∩ S (resp. Bǫδ (x∗β ) ∩ S ) at time t will
traverse the plane S again and the traversing time t+1+ttrav
satisfies hα − δ < ttrav < hα + δ (resp. hβ − δ < ttrav <
hβ + δ).
Intuitively, this lemma is true because of continuity and
can be proved following a very similar argument as that
presented in the proof of lemma 3.3.3 of [22]. In the next
lemma, we characterize the trajectory of x(t) starting from
a region close to x∗α .
Lemma 4. There exists ǫ > 0 such that any trajectory of
the system described by (16), starting from xα = x∗α + δxα ∈
Bǫ (x∗α ) ∩ S will intersect and traverse S, and the traversing
point x(t1 ) satisfies
x(t1 ) − x∗β = Z2 δxα + O(δ 2 ).
Proof. From lemma 3, there exists some ǫ > 0 such that
the trajectory of x(t) starting from Bǫ (x∗α )∩S will traverse S
at some instant t1 = 1+hα +δhα . Define δx(t) = x(t)−x∗ (t).
Then,

(39)

∗

where we have used the series expansion of F (x + δx, u)
around (x∗ , u). Since δx(0) = δxα , from (39) we get:
x(1 + hα + δhα ) − x∗ (1 + hα + δhα )

Z 1+hα +δhα
2
JF (x∗ (s),u(s−1))ds δxα + O(δ )
= exp
= exp

0

= exp

Z 1+hα
0

∗



JF (x (s),u(s−1))ds



JF (x∗ (s),u(s−1))ds

δxα + O (δhα δxα ) + O(δ )
(40)

Furthermore, making a series expansion in δhα , we get:
x∗ (1 + hα + δhα ) − x∗β = F (x∗β , uα ) δhα + O(δ 2 ),

(41)

where we use the fact that x∗ (1 + hα ) = x∗β . Using (40)
and (41), we have:

Z 1+hα
JF (x∗ (s),u(s−1))ds δxα
x(1 + hα + δhα ) − x∗β = exp
0
+ F (x∗β , uα )δhα + O(δ 2 ).

δxα

+O(δ 2 ). (43)

Plugging (43) in (42) gives the desired result.
Similarly, if we define t2 to be the time taken for trajectory
of x(t) to traverse S again (at a traversing point close to x∗α ),
we have:
x(t2 ) = x∗α + Z1 δxβ + O(δ 2 )
with initial condition x∗β + δxβ = x∗β + Z2 δxα + O(δ 2 ). Replacing δxβ with Z2 δxα +O(δ 2 ) in the above equality yields:
x(t2 ) = x∗α + Z1 Z2 δxα + O(δ 2 ).
Note that x(t2 ) = P (xα ) and x∗α = P (x∗α ). Thus,
P (xα ) = P (x∗α ) + Z1 Z2 δxα + O(δ 2 ).
Consequently, the Jacobian of the Poincaré map at x∗α is
Z1 Z2 . Therefore, the Poincaré map is locally stable at x∗α
(respectively, the limit cycle x∗ is locally stable) if and only
if all the eigenvalues of Z1 Z2 are inside the unit circle; i.e.,
ρ(Z1 Z2 ) < 1.

B.

PROOF OF PROPOSITION 1

Recall that the second phase begins with Tk ≥ TP 1 . Since
the αi are all close their mean ᾱ after Phase I, it suffices to
study the evolution of ᾱ. This is very useful, as it reduces
an N -dimensional problem into a 1-dimensional one.
Define the function f : [0, ∞] −→ [0, ∞]:
∗

f (α) = e−g(1+W α/2) (eg − 1 + α).
ᾱ(Tk+1 ) = e−g∆Tk (eg − 1 + ᾱ(Tk ))
= f (ᾱ(Tk ))eg/2N

P

i Wi (Tk )(ᾱ(Tk )−αi (Tk ))

.

Invoking (29), we can bound the exponent term
g
g X
Wi (Tk )(ᾱ(Tk ) − αi (Tk )) ≤ e−g(Tk −TP 1 ) ,
2N i
4
ᾱ(Tk+1 ) = f (ᾱ(Tk ))(1 + δk ),

2

δxα + O(δ 2 )

c F (x∗β , uα )

to get:

0

Z 1+hα



1+hα
JF (x∗ (s),u(s−1))ds
0

Using (21) and (19) we have:

˙
δx(t)
= F (x(t), u(t − 1)) − F (x∗ (t), u(t − 1))
= F (x∗ (t) + δx(t), u(t − 1)) − F (x∗ (t), u(t − 1))
= JF (x∗ (t), u(t − 1)) δx(t) + O(δ 2 ).

R

(42)

Since x(1+hα +δhα ) and x∗β are on the switching plane S, we
have cx(1+hα +δhα ) = cx∗β = 0. After some manipulations,

(44)

where |δk | ≤ ǫk , ge−g(Tk −TP 1 ) /2. Since the δk vanish
exponentially fast, (44) implies that ᾱ essentially evolves
according to the iteration ᾱ(Tk+1 ) ≈ f (ᾱ(Tk )).
Before proceeding, we state a few useful properties of f .
Lemma 5. For parameters satisfying (22):
(i) f maps [0, 1] to [0, 1]; i.e., f ([0, 1]) ⊆ [0, 1].

(ii) f has a global maximum at αmax = 2/(gW ∗ ) − (eg − 1),
and is strictly increasing for α < αmax , and strictly
decreasing for α > αmax .
(iii) f (αmax ) < 4αmax /5.
(iv) f has a unique fixed point 0 < α∗ < min(αmax , 1).
(v) for any 0 ≤ α ≤ αmax ,
∗

|f (α) − α∗ | ≤ e−g(1+W α/2) |α − α∗ |.

Proof. (i), (ii), and (iii) follow after some simple algebraic manipulations.
(iv) Since f (0) > 0, f (1) < 1, and f (αmax ) < αmax ,
the continuity of f implies the existence of a fixed point in
(0, min(αmax , 1)). The derivative of f is given by:
f ′ (α) = −

C.

BOUNDS ON α∗

Theorem 2 shows that αi (Tn ) converge to the constant α∗
which solves (23). Here, we provide bounds on the value of
α∗ . Recall that W ∗ = (Cd + K)/N .
Theorem 3. If W ∗ ≥ 2, then α∗ satisfies:
r
r
2
2
1
∗
−g <α <
+ g.
2 W∗
W∗

∗
gW ∗
f (α) + e−g(1+W α/2) .
2

Because f (α) ≥ 0, this implies:

gW ∗
f (αmax ), e−g ) ≤ max(4/5, e−g ) < 1.
2
Thus, f is a contraction, and the uniqueness of the fixed
point follows by the contraction mapping principle.
(v) By the Mean-Value Theorem:
|f ′ (α)| ≤ max(

f (α) − α∗ = f ′ (c)(α − α∗ ),

for some c ∈ (0, αmax ). Note that f ′ (c) > 0 by part (ii).
Assume α > α∗ . Then f (α) > α∗ , and we have:
∗

α∗ = f (α∗ ) > e−g(1+W α/2) (eg − 1 + α∗ ),
∗

=⇒ f (α) − α∗ < e−g(1+W α/2) (α − α∗ ).

An identical argument for α < α∗ completes the proof.

√
∗
∗
Theorem 3 implies
√ very small g, α ≈ c/ W
√ that for
for a constant 1/ 2 < c < 2. As g increases, the αi (t)
fluctuate more widely resulting in weaker bounds on α∗ . To
stop the fluctuations
from becoming large compared to the
√
“ideal” value, c/ W ∗ , an upper limit is required for
√ g. This
provides another justification for choosing g / 1/ Cd + K,
suggested using the fluid model in Section 3.3.
Proof. Assume that system starts with initial condition
Wi (0) = W ∗ and αi (0) = α∗ . Its easy to see that starting
from this initial condition, the marking process p(t) is a
periodic square wave with period ∆T = 1 + W ∗ α∗ /2 and
duty cycle 1/∆T . Also, Wi (t) and αi (t) do not depend on
i, and so dropping the subscript, the common α(t) process
evolves according to:

Lemma 6. Let m , inf{k|Tk ≥ TP 1 }. Then for k ≥ m + 1:
|ᾱ(Tk+1 ) − α∗ | ≤ e−g∆Tk |ᾱ(Tk ) − α∗ | + 2ǫk .

(45)

Proof. Using (44) and Lemma 5 (iii), for k ≥ m + 1:
ᾱ(Tk ) < (4αmax /5)(1 + g/2) < αmax .
The last inequality uses g < 1/2, which follows from (22).
Hence, using (44) and Lemma 5 (i) and (v):
|ᾱ(Tk+1 ) − α∗ | ≤ |f (ᾱ(Tk )) − α∗ | + f (ᾱ(Tk ))δk
≤e

−g(1+W ∗ ᾱ(Tk )/2)

∗

|ᾱ(Tk ) − α | + ǫk .

The result follows by noting that:
∗

e−g(1+W ᾱ(Tk )/2) = e−g∆Tk eg/2N
≤e

−g∆Tk

P

i Wi (Tk )(αi (Tk )−ᾱ(Tk ))

(1 + ǫk ).

We are now ready to prove Proposition 1. Let m be defined as in Lemma 6. Iterating (45) backwards from n ≥
m + 1:
|ᾱ(Tn ) − α∗ |
≤ e−g(Tn −Tm+1 ) |ᾱ(Tm+1 ) − α∗ | + 2


≤ eg(Tm+1 −TP 1 ) + g

n−1
X

n−1
X

ǫk e−g(Tn −Tk+1 ) ,

eg(Tk+1 −Tk ) e−g(Tn −TP 1 ) .

k=m+1

Using ∆Tk ≤ 1 + W ∗ /2 and Lemma 1, we have


∗
∗
|αi (Tn )−α∗ | ≤ 1+e2g(1+W /2) +geg(1+W /2) n e−g(Tn −TP 1 ) ,
for all 1 ≤ i ≤ N . It is easy to show that for n ≥ 2:
∗

∗

dα
= g(p(t) − α(t)).
dt

∗

1 + e2g(1+W /2) + geg(1+W /2) n ≤ e2g(1+W /2) n,
and the result (equation (30)) follows for n ≥ m + 1. For
1 ≤ n ≤ m, the result is trivial because the right side of (30)
is larger than 1.

(47)

The low pass filter described by (47), has frequency response
H(s) = g/(s+g) and impulse response h(t) = ge−gt . Let αdc
denote the DC value of the α(t) process. Since the DC value
of p(t) is equal to its duty cycle, 1/∆T , αdc = H(0)/∆T =
1/∆T . Furthermore,
α(t) − αdc

1
= (p(t) −
) ∗ (ge−gt )
∆T
Z min{1,t}
Z t
1
1
=
)ge−g(t−τ ) dτ +
)ge−g(t−τ ) dτ,
(1 −
(−
∆T
∆T
0
min{1,t}

where ∗ is the convolution operator. Using this, we have the
following bounds:
Z 1
1
1
)dτ = g(1 −
),
α(t) − αdc < g
(1 −
∆T
∆T
0
Z ∆T
1
1
)dτ = −g(1 −
).
α(t) − αdc > g
(−
∆T
∆T
1
Substituting αdc = 1/∆T in the above bounds, and taking
t to be a congestion instant (so α(t) = α∗ ) gives:

k=m+1



(46)

−g +

1
1
≤ α∗ ≤ g +
.
∆T
∆T

Finally, substituting ∆T = 1 + W ∗ α∗ /2, and using W ∗ ≥ 2,
the result follows after some basic algebra.

