Bioethical Inquiry (2015) 12:179–182 
DOI 10.1007/s11673-015-9621-0 
CRITICAL PERSPECTIVES 
Facebook Study: A Little Bit Unethical But Worth It? John Kleinsman & Sue Buckley 
Received: 19 August 2014 /Accepted: 4 January 2015 /Published online: 5 March 2015 # Journal of Bioethical Inquiry Pty Ltd. 2015 
Abstract Human research involving the use social me dia raises many of the same issues as medical research. The publication of a paper in June 2014 investigating Bemotional contagion^ received extensive publicity re cently because of the methods used. The approach in volved manipulating the BNews Feeds^ of Facebook users, but the participants were not informed of their involvement in the research and had no opportunity to consent or opt out. Some commentators have argued that although it would have been preferable to obtain informed consent, it was not strictly required because the research was unlikely to cause significant harm and was important. This paper argues that the research was unethical because (i) it should have been over seen by an independent ethics committee or review board and (ii) informed consent could and should have been obtained. Regardless of the importance of any research and irrespective of its likelihood to cause harm, the ethical principles that have evolved since the 1940s should be followed in all instances when experimental research is being carried out on human participants. 
Keywords Social media . Human experimentation . Ethics research . Informed consent 
The history of Binformed consent^ in research goes back to the Nuremberg Code of 1947, developed after the Nuremberg trials at the end of the Second World War. 
J. Kleinsman (*) : S. Buckley 
The Nathaniel Centre, P.O. Box 12243, Thorndon, Wellington 6144, New Zealand 
e-mail: jkleinsman@nathaniel.org.nz
These trials exposed research by Nazi doctors on Jewish citizens, persons with a disability, and others, research conducted without consent and which included the tor ture, maiming, and murder of many subjects. Since that code was developed there have been numerous and serious instances of unethical research where consent was not obtained. The lesson learnt from Nuremberg and other well-known unethical research studies, such as Tuskegee and Willowbrook, is that justifying re search on the basis of its potential benefits alone, and without proper consideration of the rights of partici pants, all too easily leads to exploitation and harm. 
The recent publication of a research paper that inves tigated the Bemotional contagion^ of almost 700,000 randomly selected Facebook users received extensive publicity because of the methods used by the researchers (Kramer, Guillory, and Hancock 2014), specifically their decision not to inform the participants. 
For this research, two groups of Facebook users had the emotional content of their BNews Feeds^ manipulated in order to assess whether their emo tional states, as measured by their posting behav iours, were affected by the emotional expressions of others. In one group, exposure to friends’ posi tive emotional content in their News Feeds was reduced; in another group, exposure to friends’ negative emotional content was reduced. The effect on the participants was then measured by examin ing the emotionality of their status updates. 
In explaining their project, the researchers stated that they used word-counting software, which meant that original posts were not viewed by the researchers. As such, they considered that it was consistent with Facebook’s Data Use Policy to which all users agree. They further claimed that the Data Use Policy precluded 
180 Bioethical Inquiry (2015) 12:179–182
the need to seek additional consent from the study group. In addition, it was later claimed that as the experiment was conducted by Facebook for internal purposes, there was no obligation to Bconform to the provisions of the Common Rule^ that protect human research subjects (Verma 2014, 10779). 
Responding to criticisms that the researchers failed to obtain informed consent from the unknowing partici pants, one of the research authors, Adam Kramer, appealed to the need for the research to take place: BWe felt that it was important to investigate the common worry that seeing friends post positive content leads to people feeling negative or left out. At the same time, we were concerned that exposure to friends’ negativity might lead people to avoid visiting Facebook^ (Kramer 2014). He also stated that Bour goal was never to upset anyone. I can understand why some people have con cerns about it, and my co-authors and I are very sorry for the way the paper described the research and any anxiety it caused^ (Kramer 2014). But Kramer fails to address the issue of informed consent. 
In another counter-viewpoint to the criticism that the research was unethical, Michelle Meyer, writing with five co-authors and on behalf of 27 other ethicists, argued that the manipulation of feeds at the heart of this experiment mimics Facebook’s standard practice in which software automatically filters status updates for the commercially related purposes of optimising en gagement with particular advertisers, a practice, Bthat carries unknown emotional risks^ (Meyer 2014, 265). Thus, Meyer contends, Bif it is ethically permissible for Facebook to offer a service that carries unknown emo tional risks, and to alter that service to improve user experience, then it should be allowed—and encour aged—to try to quantify those risks and publish the results^ (Meyer 2014, 265). This argument is problem atic on a number of counts. 
Firstly, we are not denying that it is a good idea to want to quantify the unknown risks of Facebook’s fil tering practices. Indeed, it might even be argued that Facebook has an ethical responsibility to carry out such research in order to verify the veracity and seriousness of such risks. Rather, our key concern is about the fact that the experimentation on which the research relies has been done, in this instance, without the knowledge and consent of the participants. 
However, there is an ethical non sequitur in Meyer’s argument that the research on users’ moods is justified on the basis of Facebook’s current filtering practices. 
What is at stake here from an ethical perspective is the role of Bintention^ in human behaviour. If Facebook’s current (and generally accepted) filtering of status up dates for commercial reasons was, in fact, already based on the intentional manipulation of users’ moods, then there is a serious ethical problem with its current behav iour that needs to be urgently addressed. Were that really the case, then Meyer’s defence of the researchers’ be haviour is effectively grounded on the dubious idea that one wrong justifies another wrong! 
There is, however, no indication that this is the case. Rather, it seems that any emotional consequences Facebook’s standard current practices might have on Facebook users’ moods is both unproven and uninten tional. In which case, the intervention upon which the Facebook research is based belongs to an entirely dif ferent class of human action, because there is, ethically speaking, a world of difference between intending a particular outcome (the deliberate manipulation of Facebook users’ emotions) versus admitting the possi bility of such an outcome as an unintended side-effect of its current, commercially motivated, filtering practices.1 Here again, Meyer’s defence of the researchers is found to be lacking. 
The last paragraph in Meyer’s article is particularly worrying. It states: BThe Facebook experiment was controversial, but it was not an egregious breach of either ethics or law. Rigorous science helps to generate information that we need to understand our world, how it affects us and how our activities affect others^ (Meyer 2014, 265). If an experiment is in Bbreach of either ethics or law,^ then whether it is an Begregious^ breach or not is irrelevant. And why the use of Brigorous^ to describe the discipline of science that helps us to under stand the world? This would seem to imply that Brigorous science^ is sometimes distasteful to us and we should just Bharden up.^ Even more importantly, however, the blatant implication is that the outcome of research can justify overlooking breaches of ethics. To reiterate, Facebook is not wrong for wanting to find answers to real questions or for making its data avail able. The key ethical question revolves around the way it obtained that data—specifically its decision not to get 
1 Note that we do not address here the ethical issues associated with the commercially motivated and standard practice of manip ulating feeds by Facebook. This is a separate issue, worthy of further exploration but outside of our focus on the ethics of the Facebook research. Our point is that research on humans is subject to its own rigorous set of principles. 
Bioethical Inquiry (2015) 12:179–182 181
the informed consent of its users who thereby became unwitting participants in an experiment that involved their state of mind. 
If, as Kramer has stated, the intention of research is never to upset anyone, if there is little reason to expect that it might be harmful, and if there is a good reason for undertaking it, why is it important to gain informed consent? In answering this question it must be remem bered that the research in question involved the deliber ate manipulation of the emotions of the participants by an intentional intervention that concentrated on the feeds with either positive or negative content. As one commentator noted: BThe study harmed participants, because it changed their mood^ (James Grimmelmann in Arthur 2014, ¶3). That is to say, the research went beyond simply observing behaviour. Whether or not the researchers were themselves directly involved in the manipulation of the Facebook feeds, nevertheless their findings relied on the information generated by an Bexperiment^ initiated for the express purposes of their research project. 
As noted in our introductory comments, it is a well established principle within research ethics that any research involving an intervention requires fully in formed consent and should be overseen by an ethics committee independent from both the researchers and the organisation or company instigating the research. This means that participants should (1) know they are being experimented on; (2) be given clear information about the research; and (3) be informed of both the risks and benefits. The only exceptions to this are in circum stances where (i) the research is strictly observational or (ii) participants are, for various reasons, unable to give consent, in which case consent must be sought from someone legally entitled to provide consent for them. In exceptional cases, limited disclosure may be justified or consent might be obtained retrospectively, for example because of the need to avoid a biased response. It is also possible to seek a waiver of consent where the risk is low and where there are strong reasons why it would not be practical or possible to obtain consent. However, in these situations, the ethical rider is that such research must always be held up to close scrutiny by an appro priately accredited and independent review body. Such review bodies include already established ethics com mittees associated with universities, government agen cies, and independent social research bodies. 
Regarding the Facebook research, it would have been both practical and possible to obtain informed consent 
without introducing bias; for example, participants could have been told that the research would manipulate their posts over one week in an upcoming ten-week period without saying which week and without disclos ing whether participants were in the Bpositive,^ the Bnegative,^ or the control group. Participants could then have been given the option of opting out. In other words, the research fails to meet the minimum standard condi tions that are necessary for justifying either limited disclosure or the waiving of consent. Even if that were not the case, the decision by the researchers not to seek an independent review places their research outside of the long- and now well-established conventions that exist to promote ethical research as described in docu ments such as Australia’s National Statement on Ethical Conduct in Human Research (National Health and Med ical Research Council, Australian Research Council, and Australian Vice-Chancellors’ Committee 2014). While these conventions may have originated within a medical context, common sense and ethical consistency dictate they should apply to any research that involves participants where there is the potential for harm, in cluding emotional harm. 
Meyer herself acknowledges this shortcoming and goes at least some way to recognising that the treatment of Facebook users was ethically speaking deficient: BAlthough approval by an institutional review board was not legally required for this study, it would have been better for everyone involved had the researchers sought ethics review and debriefed participants afterwards^ (Meyer 2014, 265). Similarly, the publish ing journal, in an editorial expression of concern, has retrospectively admitted that there were ethical issues with the Facebook research: BIt is nevertheless a matter of concern that the collection of the data by Facebook may have involved practices that were not fully consis tent with the principles of obtaining informed consent and allowing participants to opt out^ (Verma 2014, 10779). Given the policy, now adopted by many journals, of not publishing human-related research that has not been adequately ethically reviewed, it is unfor tunate that the journal in question did not take a more pro-active stance; this policy has already proved to be effective in motivating robust ethical review in many other areas of human and animal research. 
To conclude: The actions of Facebook and the re searchers involved in the Facebook experiment de scribed above raise many other important questions about the way we all use social media as well as the 
182 Bioethical Inquiry (2015) 12:179–182
collection and use of personal data by private companies for commercial reasons. It is hoped that this discussion will stimulate further reflection and discussion about the way in which those responsible for social media are able to intrude into the lives of those using such platforms. We are focusing here on one aspect only, the use of social media to carry out research on unsuspecting participants. 
We believe that research can never be judged to be ethical on the basis of its outcome alone; a good out come does not justify an unethical research process— good research is always ethical from its inception. In terventional research should never be undertaken with out informed consent and/or independent scrutiny. The Facebook experiment clearly went beyond benign, anonymous, observational monitoring, which meant that in order to be ethical it required independent scru tiny and, in our view, informed consent. Even if it is true that the risks for the Facebook experiment were low and even if, in hindsight, the results are judged to be useful, there is an important principle at stake here that must be upheld. In the same way that stealing is stealing no matter what amounts are involved, so we all have a right not to be experimented on without our knowledge and consent, whatever the nature of the research. Proper respect for that right precludes researchers or companies making unilateral decisions not to seek consent. 
We neglect the principle of informed consent at our peril as the lessons of history have repeatedly shown. What many are treating as a relatively benign act by Facebook and its researchers represents, for us, a will ingness to embrace, once again, the follies of unchecked scientific paternalism—a willingness to leave research decisions about human well-being in the hands of re searchers without any independent scrutiny. The Facebook research relies on and fosters the very mindset 
that allowed the abuses of the past to occur—a mind-set where participants’ rights and well-being become sub servient to the outcomes of research, including research carried out by well-intentioned researchers. 
The actions of Facebook and the researchers represent a step Bback to the future.^ Small step or not, it is a step backwards from best accepted practice. For the research community to fail to acknowledge the unethical actions of the Facebook project would be to create a dangerous precedent for future research. History tells us we must never again trust researchers to the point of allowing them to act unilaterally. 
References 
Arthur, C. 2014. Facebook emotion study breached ethical guide lines, researchers say. The Guardian, June 30. http://www. theguardian.com/technology/2014/jun/30/facebook emotion-study-breached-ethical-guidelines-researchers-say. Accessed August 18, 2014. 
Kramer, A.D.I. 2014. [Untitled Facebook post, June 29, 2014.] https://www.facebook. com/akramer/posts/ 10152987150867796. Accessed August 18, 2014. 
Kramer, A.D.I., J.E. Guillory, and J.T. Hancock. 2014. Experimental evidence of massive-scale emotional contagion through social networks. Proceedings of the National Academy of Sciences 111(24): 8788–8790. 
Meyer, M.N. 2014. Misjudgements will drive social trials under ground. Nature 511(7509): 265. 
National Health and Medical Research Council, Australian Research Council, and Australian Vice-Chancellors’ Committee. 2014. National statement on ethical conduct in human research (2007)—updated March 2014. Canberra: Australian Government. https://www.nhmrc.gov.au/ guidelines/publications/e72. 
Verma, I.M. 2014. Editorial expression of concern and correction. Proceedings of the National Academy of Sciences 111(29): 10779.