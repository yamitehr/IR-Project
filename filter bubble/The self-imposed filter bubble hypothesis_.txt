Hypotesen om sjalvférvallade filterbubblor

The self-imposed filter bubble hypothesis

Axel Ekstr6m

handledare / supervisor(s)

Petter Johansson

Diederick Niehorster
KOGM20
2021-06-04
Masteruppsats i kognitionsvetenskap Master’s thesis (2 years) in Cognitive Science
Avdelningen fér kognitionsvetenskap Lund University Cognitive Science
Filosofiska institutionen Department of Philosophy

Lunds universitet Lund University
Abs. It is commonly assumed that algorithmic curation
of search results creates filter bubbles, where users’
beliefs are continually reinforced and opposing views
are suppressed. However, empirical evidence has
failed to support this hypothesis. Instead, we suggest
that filter bubbles may result from individuals acting
selectively on information made available by search
engines. When presented with search engine results
pages, links and sources that validate users’ beliefs
should be attended more than other links. This
prediction is testable using eye-tracking technology.
Here, we presented biased participants (n = 48) with
sets of simulated Google Search results, controlling for
the ideological leaning of each link. Results indicate
that, on average, politically Liberal participants spend
more time viewing own-side links than other links,
while political Conservatives do not. However, both
Liberals and Conservatives tend to select same-side
links. Further, there is a significant effect of trust, such
that links associated with less trusted sources are
attended less and selected less often. Implications,
study limitations, and directions for further study are

also discussed.

1 Introduction
The problem of filter bubbles

Every day, millions of people search for information
online using search engines such as Google Search,
Yahoo, and DuckDuckGo. The results we see on the
web influence our interpretations of world events and
our beliefs about the world. Google Search is
particularly ubiquitous, with billions of search queries
processed every day (Internetlivestats, 2021). However,
it has also been subject to extensive criticism. Search
engine result pages (SERPs) are typically based not
only on the search terms used but also on users’
previous searches. It has been alleged that this process,
known as_ personalization, leads to ideological
segregation and polarization. By reinforcing searchers’
beliefs and hiding or suppressing user-opposing views,
Google Search allegedly creates ideological filter
bubbles, potentially emphasizing real-life political
affective polarization and segregation (Pariser, 2011;
Sunstein, 1999) and fragmenting political discourse
(see Garrett & Resnick, 2011). Despite widespread
intuitive appeal, however, empirical evidence has
largely failed to support this hypothesis.

In one study of Google users, Hannak et al., (2017)
found small (~12%) differences in search results,
defined as links or the position of links. Counter to the
prediction of the filter bubble hypothesis, however, the
authors found no measurable history-driven effect of
personalization. Being logged into the Google system,
and searchers’ geographic location were the only
statistically significant factors. Similarly, Haim et al.,
(2017) found only minor differences in link position
between accounts when 1200 individuals searched for
information on suicide. Further, while Curtois et al.,
(2018) did find extensive variation in search results for

social and political search terms, most of that variation
was explained by the time of the search. Finally, in
studying the browsing histories of over 1.3 million
U.S-based users, Flaxman et al., (2016) found that
while news access was segregated, online search tools
such as search engines actually increased users’
chances of being exposed to opposing or disconfirming
views (see also Cardenal et al., 2019). Empirically,
then, the Google Search engine itself appears not to be
driving filter bubble-type ideological segregation (see
also Zuiderveen Borgesius et al., 2016). Thus, the
problem of the filter bubble phenomenon facing
academics is not necessarily the facilitation of political
segregation (though that may still be so), but that it is
apparently difficult to study in the first place. Notably,
however, one aspect of online information search that
remains largely unexplored is the role of the searcher
himself.

Typically, in studies on SERPs, top links receive
the most attention from users, with less attention
afforded to each subsequent link (Salmerén et al.,
2013; Granka et al., 2014). Hotchkiss et al., (2005)
introduced the term golden triangle to describe a
heatmap illustration of this phenomenon, where gaze is
concentrated in the rough form of a right triangle with
the right angle facing upwards to the left, such that gaze
on average drops off significantly beyond the
hypothenuse (see Figure 1). Further, while search
engines typically return hundreds of pages of results,
users commonly choose results from only the first page
(Joachims et al., 2007), and even in initial SERPs, more
than two-thirds of all clicks tend to go to the first five
link positions presented (Petrescu, 2014). Thus,
available research suggests that link position tends to
bias selection, which — all other things being equal —
should facilitate depolarization of political beliefs
(through homogeneity in selection), as opposed to
increased polarization. While a significant amount of
research has investigated the ways in which users
typically interact with search engines, few have sought
to investigate the way in which users’ beliefs interact
with such behaviors. These studies have also tended to
ignore political content in the links presented.

Yom-Tov et al. (2014) have suggested an
alternative proposition with important implications for
the filter bubble hypothesis. Biased persons, acting on
the large set of information made available via the
internet, may be selectively curating their own
newsfeeds and information sources — effectively
engaging in self-segregating behavior. This assertion,
henceforth referred to as the self-imposed filter bubble
hypothesis, does indeed find significant support in
relevant research literature from social psychology,
cognitive science, and communication (see below).
Further, while Yom-Tov and colleagues did not
themselves attempt to test this hypothesis empirically,
its core assertion presents researchers with clear
premises, open to investigation via experimental means.
In this thesis, I present the results of one such
investigation.
nttps://fs. blog

How Filter Bubbles Distort Reality: Everything You Need to ...
fitter t ,

https: //reutersinstitute.politics.ox.ac.uk
The truth behind filter bubbles: Bursting some myths | Reuters

https:/Avww.theverge.com

6 be so potarizi bel

 

  

https://edu.gc
Digital Media Literacy: How Filter Bubbles Isolate You

a filter b

global.org

nttps://medium.con

The Causes and Effects of “Filter Bubbles” and how to Break ..
Filter bubbles create ar ?
fF

nttps:/www.nordicom gu.se .
New study rejects the idea of filter bubbles | Nordicom

ea of filter bubbles

Figure I. In empirical studies on SERPs, users’ attention is
typically concentrated in a tniangle-like pattern, such that
lower-position links are attended less and read less
extensively on average, outside a “golden tnangle”.

Ingroups, outgroups, and dealing with sources

It is a well-replicated set of findings in social
psychology that group identity often becomes a cause
of differential treatment between groups (Eibl-
Eibesfeldt, 1979; Brewer, 1979; Tajfel & Turner, 1986;
for acomprehensive review, see Hewstone et al., 2002)
and is easily established, for example, based on real-
world groupings such as ethnicity and_ political
affiliation (Rand et al., 2008). These findings have
been repeatedly validated and replicated, with a review
by Mullen et al., (1992) finding that ingroup favoritism
did not once fail to replicate in any one culture where
it was investigated. Many factors are known to
influence ingroup bias, including the ease of
identification, salience, and status (see Hewstone et al.,
2002). Further, ingroup and outgroup cognitive biases
may extend even beyond conscious information
processing.

According to Cohen (2003, p. 1): “[G]roups define
the very meaning of objects in the social world.”
Indeed, dynamics of ingroup and outgroup appear to
affect even unconscious cognitive processing (for an
overview, see Chong, 2013), extending to seemingly
objective facts about the world (Bartels, 2008). As a
consequence, people often see the same thing but

 

1 Relatedly, Sperber et al., (2010) have suggested that

humans are equipped with mechanisms of “epistemic
vigilance”, designed to minimize the risk of unreliable

experience it differently. For example, in a classic work,
Hastorf and Cantril (1954) found that participants were
more likely to perceive errors in the playing of student
football players from teams of students from
competing schools, than they were to perceive them in
players representing their own school. This was later
revisited and further supported by Kahan et al., (2012),
who showed that participants viewing identical footage
disagreed about key aspects of the observed events (a
protest), depending on their own political ideology.

There is considerable consensus in the field that
partisanship biases information processing in the
context of politics as well (e.g., Chong, 2013; but see
also Gerber & Green, 1998). Such effects also tend to
be more readily found in people with greater political
knowledge and insight — 1.e., political sophisticates.
For instance, a survey study by Brader (2006) found
that sophisticates self-reported stronger discrete
emotions toward politicians. In the words of Lodge and
Taber (2005, p. 473): “[Political] sophisticates,
because of their interest in politics, have formed
crystallized attitudes to a fuller set of political issues.”
Interestingly, in this regard, a difference has been
found between political liberals (i.¢., left-wingers) and
political conservatives (i.e., right-wingers), such that
liberal persons are more likely to avoid exposure to
political disagreement, at least in online interactions
(e.g., Bode, 2016). ! Finally, ingroup favoritism
apparently also extends to levels of perception,
including visual attention, such that own-side social
stimuli are more thoroughly attended to and processed
(Xiao et al., 2016; Kawakami et al., 2014). For example,
Kawakami et al., (2014) found significant evidence of
preferential attention to the eyes and faces of ingroup
members, such that White participants tended to attend
more to the eyes of White target faces, compared to
Black target faces. This effect seemingly holds also for
novel ingroup and outgroup faces. This state of
research let us pose a set of main hypotheses.

Hia: Partisans select search results in line with their
group and ideology, and do not select search results
that fail to conform to their group and ideology.

Hb: The top-link heuristic — which posits that top-
presented search results are selected more often due to
their position as initial — holds when search results
align with searcher’s ideology, but not when it does not.

Another particularly meaningful marker for whether to
trust information is delineated by its source. The
question of how to treat others as sources is of
importance to several disciplines, such as
developmental psychology (Mills, 2013), decision
making (Birnbaum et al., 1976; Birnbaum & Stegner,
1979), and persuasion (Petty & Cacioppo, 1984; 1986).

information sampled from others. These mechanisms may
also include a check on new information, testing whether it is
consistent with one’s own beliefs (e.g., Mercier, 2020).
On average, people have trust in search engines’ ability
to rank and present users with the best results (Purcell
et al., 2012; Pan et al., 2007), though this may have
diminished in recent years (Schulthei® et al., 2018).
Even when presenting participants with manipulated
reverse-ordered search results, participants still placed
significant trust in Google’s own link positioning as
being relevant for assigned task purposes (Kammerer
& Gerjets, 2012). However, source position does not
seem to serve as an apparent clue to trustworthiness in
search results, such that links with higher position are
not necessarily trusted more as sources than are lower-
position ones (Kammerer & Gerjets, 2014). Thus,
judgements of trust in a search engine may be more
concerned with relevance to search enquiries, than with
explicit trust in a given source, suggesting that
conscious processing and evaluation of that source may
override the initial attentional bias towards top-
presented search results (e.g., Salmerén et al., 2013).
For delineating the role of trust in the reliability of
communicated information, it is useful to look to
models of message reliability.

Olsson and Angere’s Bayesian model of belief
updating (see Olsson, 2011; Olsson & Vallinder, 2013)
suggests that content and source reliability interact bi-
directionally, such that the reliability of a source
moderates evidential impact of message content — and
message content, in turn, provides evidence about the
reliability of the source (for another model
emphasizing this relationship, see Bovens & Hartmann,
2003). Just as statements from an unreliable source are
regarded as implausible, implausible statements
themselves make a source appear less reliable: it leads
to a reduction in subjective degree of belief of
reliability. In Olsson and Angere’s model, source
reliability is represented by a distribution over possible
reliability profiles, updated via Bayesian inference. In
such a model, at the bottomed-out value of P = 0, a
report would be taken as evidence of the opposite of
what was asserted. More recently, these predictions
have also been borne out empirically by empirically
Collins et al., (2018). One particularly important aspect
of (mis)trust in a source, with crucial ramifications for
political cognition, is individuals’ opinions and beliefs.
In the context of political information processing, then,
if a claim can be traced to an ideologically
disconfirming (opposing) source, political partisans
would — all other things being equal — be less inclined
to trust it, and therefore, to engage with it:

H2: People pay more attention to links associated with
trusted sources, compared to untrusted ones, and select
them more often.

Selective exposure and cognitive bias

Research from the 1940’s and onward has found that
people’s ideological convictions skew their willed
exposure to news that conform to those beliefs (e.g.,
Lazarsfeld et al., 1948), a finding that has more
recently been reaffirmed by modern research (Garrett

and Resnick, 2011; Yom-Tov et al., 2014; see also
Gentzkow & Shapiro, 2011). In the social sciences,
selective exposure theory describes this general
tendency of people to seek out information that
conforms to already held convictions and avoid or
disregard information that does not (see Klapper, 1960;
Sears & Freedman, 1967; Frey, 1986; see also Mutz &
Martin, 2011). To Festinger (1957), this tendency was
central to his concept of cognitive dissonance as a
means of reducing the mental discomfort that results
from holding incongruent beliefs. The construct also
aligns closely to Nickerson’s (1998) definition of the
confirmation bias, individuals’ tendency to evaluate
evidence and hypotheses in such a way as to support
prior conclusions — which is found across populations
and cultures. With impacts for political life, Dilliplane
(2011) also found that selective exposure to partisan
political information impacted voters’ levels of
participation over time.

The technological development of the late 20" and
early 21% centuries has led to widespread internet
access and internet use across the world, which
coincides with a greatly increased access to
information. Therefore, much recent literature on
selective exposure — the willful engagement with some
information or source over another — has focused
specifically on the way users engage with information
on novel social media platforms, such as Facebook
(e.g., Bakshy et al., 2015; Silflow et al., 2019; Cinelli
et al., 2020, Instagram (Parmelee et al., 2020) and
Twitter (Himelboim et al., 2013; Colleoni et al., 2014;
see also Garrett, 2013).

However, unlike search engines, social media are
already socially and selectively curated (e.g., Weeks et
al., 2017; Spohr, 2017; Messing & Westwood, 2014),
with Messing and Westwood (2014) arguing that social
endorsements play the role of heuristic cues in
individuals’ deciding to select a story that appears in
their newsfeed. There is thus an important distinction
to be made between engaging with presented socially
curated content, which is mediated by previous
interactions weighted by social relationships — and
information search using own-selected search terms,
which is dynamic, continuous, and driven by task goals.
It is of significant interest, then, to investigate attention
and engagement with political claims and news items
in an internet-based environment bereft of such social
cues — where all that remains is the individual and his
or her biases.

Jamieson and Cappella (2008) have argued that
selective exposure may facilitate ideological echo
chambers, which may have some bearing on the
creating of filter bubbles also. Crucial to this argument,
Stinchcombe (2010) found that when discussing topics
solely with like-minded individuals, their opinions tend
to polarize. Knobloch-Westerwick and Meng (2011)
found that participants preferred attitude-consistent
messaging, which also tended to strengthen political
self-concepts. However, results for the internet echo
chambers, as described by Jamieson and Cappella
(2008), have been mixed. Overall, it does not appear
that individuals actively avoid information that fails to
conform to their own worldview. In a large internet-
administrated study, Garrett (2009a) found that while
opinion-reinforcing information promoted exposure to
news stories compared with opinion-challenging
information, the difference was marginal. Importantly,
however, Garrett (2009b) has further argued that while
partisans tend to seek out opinion-reinforcing
information, they do not exhibit systematic bias against
challenges to those opinions (see also Valentino et al.,
2009).

However, before information can be processed, it
must be attended, and a small but growing body of
research now suggests that selective own-side-biased
filtering may take place at an even earlier stage of
processing (e.g., Kawakami et al., 2014). Accordingly,
I argue that participants’ ideological biases play a role
in attending to novel information also. For this purpose,
one tool of significance is eye tracking, which lets us
investigate the early stages of attention that operate
before any conscious reasoning has taken place.

Visual attention and depths of processing

Attention is by its nature selective, selecting for and
prioritizing some stimuli in the world — and not others.
One way of examining attentional processes is eye
tracking, which allows for in-depth capture of eye
movements in real time. Gaze behavior can often
reveal intricacies of information processing (see
Duchowski, 2002). For example, the eye-mind
hypothesis, as posited by Just and Carpenter (1980),
proposes a direct relationship between cognition and
eye movements, such that longer fixations (or pauses
in eye movements) indicate a greater cognitive load
implicit in the stimulus. In research on reading, Rayner
(1998) has found support for just such a relationship.

Further, saccadic eye movements are obligatorily
coupled with shifts in visual attention (see Deubel &
Schneider, 1996). Typically, more meaningful parts of
an image will draw more attention than less meaningful
ones (Henderson & Hayes, 2017). Eye movements are
also influenced by a variety of factors, including the
rarity or frequency (Kliegl et al., 2006; Just &
Carpenter, 1980), level of expectancy or consistency
(Henderson et al., 1999; Luke & Christianson, 2016;
Staub, 2015; V6 & Henderson, 2009) or
meaningfulness (Luke & Henderson, 2016; Henderson
& Hayes, 2017; Peacock et al., 2019) of stimuli (or
parts of stimuli), all of which typically elicit longer
viewing times by participant. Even in settings where
stimuli are identical, differences in instructions may
significantly influence eye movement patterns (Yarbus,
1967; Navalpakkam & Itti, 2005). Finally, previous
research on visual decision tasks has shown how
fixations may be used to derive preferences (Glaholt et
al., 2009; Glaholt & Reingold, 2009).

Eye tracking provides a measurement of
individuals’ attention, enabling capture even of
unconscious behavioral processes that mediate

conscious cognition and decision making (Holmqvist
et al., 2011; Parnamets et al., 2015). Accordingly,
Higgins et al., (2014) considered eye movements as
preference indicators at a very early stage of cognitive
processing. Similarly, Parnamets et al., (2015) have
argued that attention plays a mediating role in decision
making. Shimojo and colleagues have previously
presented the gaze cascade model of preference
decision making, wherein participants exhibit gaze bias
toward preferred items prior to selection (Shimojo et
al., 2003; Simion & Shimojo, 2006; 2007). While this
model has never been tested in the context of SERP
information search, it has proven a resilient finding in
a variety of decision-making tasks (e.g., Gidléf et al.,
2013; Armel et al., 2008; Krajbich et al., 2010).
Similarly, in preference decision-making tasks, before
selecting one face as the more attractive, people tend to
look more toward that face than other ones (Shimojo et
al., 2003; see also Maughan et al., 2006).

In online contexts, an eye tracking study by Silflow
et al., (2019) found that Facebook users tend to select
news posts where content reinforced their own
attitudes. This assertion finds further support in results
from eye tracking studies assessing selective exposure
in political advertising (Marquart et al., 2016; Schmuck,
et al., 2019), and Facebook news feeds (Vraga et al.,
2016; Siilflow et al., 2019). However, relatively little is
known about selective exposure at the early stages of
processing, such as visual attention (but see Marquart
et al., 2016; Zillich et al., 2019).

While eye tracking has been used extensively in
web-related research (e.g., Nielsen & Pernice, 2010),
to the author’s knowledge, this work represents the first
examination of its kind as it applies to everyday search
engine link selection — and, in particular, the attention
paid to links based on their perceived content. Relating
specifically to search behavior in interactions with
search engines, Granka et al., (2004) found that mean
time spent firxating on the first and second links in a set
of links were almost equal, after which there was a
steep drop-off in attention to subsequent links;
however, participants tended to select the first link in a
set (see also Salmerén et al., 2013). Thus, while earlier
eye tracking studies have investigated eye movements
in search such as the significance of link order, finding
strong preferences for top-presented links (Pan et al.,
2007), no previous research has examined the impact
of the perceived ideological content of available links
on the visual attention paid to those links.

In light of the above related research, we should
expect that users selectively attend and select link
alternatives that are distinguished by user-politically
dissident and source unreliability, such that disliked
sources are attended less and selected less often (see
Figure 2). Thus, attention is here operationalized as
aspects of gaze behavior: total time spent fixating on
and number on fixations on, any one link. Selection is
operationalized as the choice of clicking on one of
several links in presented SERPs.
H3a: People pay more attention to search results that
are in line with their ideology.

H3b: Liberal and left-wing partisans exhibit stronger
attention bias compared to right-wing partisans.

Finally, whereas there are — at the time of writing — no
studies known to this author investigating political
partisans’ reading behavior, reading as general
information processing has been extensively studied
(for an overview, see Rayner, 2009). Reading patterns,
such as thorough reading versus skimming, have been
found to lead to differentiating levels of
comprehension and retention (Strukelj & Niehorster,
2018). Significantly, Strukelj (2018) has investigated
how readers’ expectations — including having feelings
about the topic at hand, and knowing some text
originated from more or less respected news sources —
may impact even the process of reading itself. The state
of research thus presents researchers of political
information processing with the intriguing hypothesis
that partisans may engage differently with confirming
versus non-confirming political reading material, such
that disconfirming information would be less closely
scrutinized. Against this background, I define the final
hypothesis of the thesis:

H4: People inspect opposing-side information less
carefully, operationalized as differences in reading
depth.

Thus, I suggest that searchers’ personal beliefs lead
them to act selectively on the abundant set of available
information afforded by search engines, such that
personal ideological biases systematically skew their
attending to and selecting of information. In selecting
relevant information, searchers’ cognition may bias
attention to ideologically charged content, such that
ideologically confirming information is emphasized,
and disconfirming content is disregarded.

Continue search

2 Methods

Instruments

Ideology may be operationalized both as a
constellation of beliefs and as group identity, separate
constructs which may or may not have independent
effects on political information processing. Thus,
participants’ ideology was assessed through responses
to items from the SECS inventory (Everett, 2013) and
group identity via self-identification as left-wing,
centrist, or right-wing. Finally, participants were also
asked to rate, on seven-point Likert scales, (1) how
much they trusted each of a set of sources and (2) how
often they consumed news from those sources.

Apparatus

Eye movement data were recorded using Tobii Pro
Spectrum remote eye trackers. The tracker sample rate
was 600 Hz. The screen size of the monitors was 23.8”,
with a resolution of 1920 x 1080. For stimulus
presentation and data acquisition, the Tobii Pro Lab
software was used. Viewing distance from the monitor
was ~66cm. For all participants, both eyes were tracked,
and chin rests were used. Mouse clicks were also
recorded.

Pre-study

Links were sampled from Google Search results from
various online news sources, such as online magazines
and newspapers, to represent a diversity of viewpoints
across the political spectrum. For each topic, 10 links
were sampled, for a total of 80 links. To judge the
perceived ideology of each link, online participants (7
= 3) were recruited. Each link was presented once,
along with a seven-point Likert scale, and participants
were asked to rate how they perceived the ideological
skew of each link from left (liberal) to right
(conservative), where lower ratings signified more left-

se — __ No

No —> Attend briefly
Does information
conform to prior
beliefs?
Yes —> Consider for selection ——> Selected?
End search +——_ Yes

Figure 2. Selective attention in online information visual search (hypothesized).
wing content and higher ratings signified more right-
wing content. The ordering of the links was fully
randomized for each participant. The pre-study took ~5
minutes on average to complete. Participants were not
compensated. Cronbach’s alpha for the 80 items was
deemed sufficient (a = .79). In subsequent
categorization of the links, raters’ scores for each link
were averaged, and the average of the scores assigned
to each link. The purpose of this procedure was to
obtain a value of political leaning for each link, by
which to correlate the eye movement analyses.

Participants

Participants (V = 48, 22 women) took part in the
experiment. They were aged 18 — 53 (Af = 23.19, SD =
5.79) were recruited from local politically partisan
groups (e.g., left- and right-leaning political youth
groups) and from college courses that were deemed
likely to attract politically active students (e.g.,
political science). Six participants were excluded
because of significant data loss during recording. Out
of all participants, 25 self-identified as left-wing, 5 as
being in the center, and 18 as right-wing. All
participants were Swedish natives and spoke native
Swedish. In return for participation, participants
received a voucher for 100 SEK for use in a national
chain of bookstores.

Stimuli

Stimuli were created using the EBImage R package
(Pau et al., 2010). From the original 80 links, sets of six
links per topic were selected for the study proper, for a
total of 64. This number was selected because the
standard setting on most desktop monitors allows for at
least six links at any one time; it also aligns closely
with previous research showing selection as driven by
link position (e.g., Salméron et al., 2013). To control

Google bidrag 4

 

 

Tea

 
    

m Moderate!

   

 

 

x Transiate this pap
Debatt: Infor krav pa kunskaper i svenska for att fa bidrag
stones vt , '

Figure 3. Example SERP stimulus.

for ordering effects, in each set of search results, the
links were ordered according to a 6x6 Latin square,
resulting in a total of six stimuli for each topic, from
which one was sampled and presented to any given
participant (see Figure 3). This also required the
number of participants to be a factor of six. In all, 8
SERP stimuli were presented to each participant. For
the sake of environmental validity, stimuli should be as
visually similar as possible to real Google SERPs. All
links and all linked-to sites were in Swedish.

Safety precautions regarding Covid-19

As data collection took place during the Covid-19
global epidemic, a set of additional safety measures
were implemented to ensure the safety of both
experimenter and participants, and to limit the spread
of the virus. All participants were asked to use hand-
rub alcohol upon entering the lab and interactions with
the experimenter were kept at a minimum. After each
usage, keyboards, computer mice, and chin rests were
wiped off using wet wipes. Eye trackers were not
wiped. Initially, participants were limited to at most
five at a time in the lab; as recommendations changed,
this was further restricted to one participant at a time in
later sessions. All data collection was carried out in line
with the then-current guidelines issued by the Public
Health Agency of Sweden.

Procedure

Prior to the experiment, informed consent was obtained.
Participants were informed that their data would be
anonymized, that they would not be exposed to harm
of any kind, and that they had the right to opt out of
participation at any point during the experiment.
Participants were invited to sit down in front of a Tobii
Pro Spectrum eye tracker and asked to use the provided
chin rest. Each participant was instructed to keep their
head still for the duration of the experiment. The eye
tracker was then calibrated. Participants then received
on-screen instructions.

They were instructed that they were about to take
part in an experiment about searching for information
in Google Search. They were to examine the provided
sets of search results and select (by clicking) the link
they would be most likely to select in natural search
settings. In each set of search results, six links were
visible. For each trial, one mouse click was saved per
trial. After a participant had clicked on a link, the
experiment moved on to the next trial. Once all 8
stimuli screens had been presented, participants were
asked to fill in a Google Forms survey. There, they
provided on 7-point Likert scales their affects towards
a set of political topics and phrases (derived from the
SECS inventory). They were also asked to rate how
important each topic was to them personally. Finally,
they were asked to state their familiarity with a list of
sources, as well as the degree to which they trusted
each source. After the experiment, participants were
debriefed as to the true motivation of the study and
Table 1. Multiple linear regression analysis of relative total fixation durations on links.

 

(Intercept)

Link position

Nr. of characters in link

Participant ideology: Conservative
Participant ideology: Liberal

Participant self-identification: Right-wing
Participant self-identification: Left-wing
Link ideology: Left-wing

Link Ideology: Right-wing

Trust in Link source: Low

Trust in Link source: Mid

Participant ideology: Conservative
* Link ideology: Left-wing

 

Participant ideology: Liberal
* Link ideology: Left-wing

Participant ideology: Conservative
* Link ideology: Right-wing

Participant ideology: Liberal
* Link ideology: Right-wing

Estimate Std.error  tvalue P(z)
3.32 11 30.35 < 001
-.04 .004 -9.65 < 001
002 <.001 4.99 < 001
-.02 .07 -.27 82
-.09 .06 -1.50 .13
-.000 .03 -.007 995
11 .03 3.96 < 001
-.17 .06 -3.002 <01
-.1 .06 -1.79 .07
-.11 .02 -5.88 < 001
-.01 .03 -41 68
02 .08 25 81
16 .07 2.43 < 05
.08 7 48
.06 1.64 10

 

Adjusted R?: 0.11

offered compensation. Each experiment lasted roughly
~20 minutes.

3 Results

In initial qualitative observations, it was observed that
participants tended to investigate the presented search
result page from top to bottom, which was consistent
with Salmerén et al., (2013). In the present data set, no
participant apparently deviated from this pattern. In
addition, some participants did not attend to the last
few links at all, aligning with prior research (e.g.,
Granka et al., 2004). Further, link position apparently
affected how much attention was afforded to each link,
generally resulting in the “golden triangle”-style gaze
patterns as described by Hotchkiss et al., (2005; see
Figure 1).

For subsequent quantitative analyses, due to a
coding error, two links, one from each of two trial
screens had no corresponding ratings for trust in link
source. Therefore, these links were excluded from eye
movement analyses; however, other links in the stimuli
screen were still included. For analyses of link
selection, trials containing these links were excluded,
and only selected links were analyzed. In trials where

the wrongly coded link was not selected, data were
included in the analysis.

Fixation durations

Because fixation duration was highly variable between
participants (see Holmqvist et al., 2011), data
distribution was significantly skewed. Therefore, data
were log10 transformed prior to analysis. A multiple
linear regression, excluding zeroes, was then
calculated to predict total fixation duration based on
Link position, Participant ideology, coded as
Conservative, Liberal, or Center, Participant self-
identification, coded as Right-wing, Left-wing, or
Center; Perceived link ideology, coded as Left-wing,
Right-wing, or Center; Trust in the link source, coded
as High, Medium, or Low; and interactions between
Participant self-identification and Link ideology. The
model met homolinearity, homoscedasticity and
multicollinearity assumptions; however, residuals were
found not to be normally distributed. One data point
was identified via Cook’s distance as highly influential
and removed prior to subsequent analysis. A
significant regression equation was found (F(14, 2144)
= 19.02 , p< .001), with R?=.11. Link position was a
significant predictor of fixation duration (p < .001).
Mean fixation duration was found to be longer for left
wing-identifying compared to  center-identifying
participants (p < .001), but no difference was found

between center- and right wing-identifying participants.

Participants’ trust in the sources associated with links
was a significant predictor when trust was low (p
<.001) but not when it was medium-high or high, such
that links associated with less trusted sources were
attended significantly less, compared to more trusted
ones. Finally, a significant interaction effect was found
between participant ideology and link ideology, such
that the combination of ideological liberals and left-
wing links predicted greater fixation durations (p <.05).
There was no independent effect of participant
ideology (see Table 1). The number of characters in
each link was also included in the model as a covariate
and found to be highly significant (p < .001).

Number of fixations

In order to take account of zeroes (unattended areas of
interest) in the data, a second regression analysis was
performed including zeroes. When modelling the
number of fixations per text AOI — a count variable —

Table 2. Quasi-Poisson regression analysis of fixations per link.

the number of zeroes in the data were found to be
overdispersed. Thus, a quasi-Poisson regression was
calculated to predict the number of fixations per link
based on the same predictors of Link position,
Participant ideology, Participant self-identification,
Link ideology, Trust in the link source, and interactions
between Participant self-identification and Link
ideology. A statistically significant model (Efron’s R?
= .08) (Efron, 1978). Link position (p < .001) and the
number of characters in a link (p < .001) were both
significant predictors of fixation number per link.
Participant  self-identification was a significant
predictor (p < .001), such that participants who
identified as left-wing made more fixations than those
that identified as Center or right-wing. There was no
observed significant sex difference. The perceived
ideology of the link was a significant predictor, such
that apparently left-wing links were fixated more than
centrist or right-wing ones (p < .05). Trust in the
sources associated with the links was also a significant
predictor of the number of fixations (p < .001), such
that links associated with sources for which trust was
low were attended significantly less than were links
associated with sources for which trust was medium-
high or high. There were no significant interaction

 

 

(Intercept)

Link position

Nr. of characters in link

Participant ideology: Conservative
Participant ideology: Liberal

Participant self-identification: Right-wing
Participant self-identification: Left-wing
Link ideology: Left-wing

Link Ideology: Right-wing

Trust in Link source: Low

Trust in Link source: Mid

Participant ideology: Conservative
* Link ideology: Left

Participant ideology: Liberal
* Link ideology: Left

Participant ideology: Conservative
* Link ideology: Right-wing

Participant ideology: Liberal
* Link ideology: Right-wing

Estimate Std. error t-value P@)
2.23 27 8.34 < 001
-.09 01 -8.43 < 001

01 .001 4.19 < 001
14 14 1.01 31
-.12 12 -1.02 31
Jl .07 1.48 14
33 .07 5 <.001
-.27 .13 -2.14 <.05
-.14 12 -.15 25
-.18 .04 -4.11 <.001
.03 .06 A2 67
-.15 17 -.89 37
.26 15 1.8 .07
-.12 .16 -.71 48
15 14 1.06 29

 

Efron’s R?= .08
Table 3. Multiple regression analysis of reading depth.

 

 

Estimate Std.error  #value P(z)
(Intercept) -.93 ll -8.69 <.001
Link position -.04 .004 -9.74 < 001
Nr. of characters in link -.0001 .0004 -.26 8
Participant ideology: Conservative -.0007 .O7 -.01 Al
Participant ideology: Liberal -.07 .06 -1.2 23
Participant self-identification: Right-wing 02 .03 81 A2
Participant self-identification: Left-wing 13 .03 5.05 <.05
Link ideology: Left-wing -.17 .06 -3 <.01
Link Ideology: Right-wing -.09 05 -1.58 ll
Trust in Link source: Low -.11 .02 -5.66 <.001
Trust in Link source: Mid -.01 .26 -.26 .79
Participant ideology: Conservative .03 .08 34 73
* Link ideology: Left
Participant ideology: Liberal 15 .06 2.6 <.05
* Link ideology: Left
Participant ideology: Conservative .05 .O7 7 AD
* Link ideology: Right-wing
Participant ideology: Liberal 09 .06 1.43 15

* Link ideology: Right-wing

 

Adjusted R?: .099

effects between Participant ideology and Link ideology
(see Table 2).

Scrutiny in reading

To investigate the hypothesis that partisans read
disconfirming links less closely, a measure of reading
depth was computed using the number of fixations on
each text AOI, divided by the number of characters (not
including spaces) in that same AOI. One data point was
excluded based on Cook’s distance. A multiple linear
regression was then calculated to predict reading depth
based on the same variables as listed above (see Table
3). A significant regression equation was found (F(14,
2144) = 17.84, p < .001), with R? = .10. Link position
was shown to be a significant predictor of reading
depth (p < .001). Participant self-identification was
shown to be significant, such that left-wing participants
read the links more carefully than did those that
identified as right-wing (p < .05), which was consistent
with overall fixation time. Link ideology was shown to
be a significant predictor such that left-wing links were
read more closely by all participants compared to right-
wing ones (p < .01). The interaction between
Participant ideology and Link ideology was found to
be a significant predictor of reading depth, such that

political liberals read politically left-wing links more
carefully (p < .05). Participant ideology was not found
to be a significant predictor of reading depth. The
number of characters in each link, again included
covariate, was not found to be a significant predictor.

Selection

To investigate hypotheses Hla and H1b, a binomial
regression for binary outcomes (clicks agreed versus
did not agree with beliefs) was calculated based on
Link position, Perceived link ideology, Participant
self-identification, Participant ideology, and Trust in
link sources, resulting in a significant model (p < .001).
Link ideology was a statistically significant predictor
of selection-ideology agreement when the link was
left-wing (p < .05) and right-wing (p <.001), compared
to links representing the political center. Similarly,
participant political self-identification was a significant
predictor when participants identified as left-wing (p
<.001) or right-wing (p <.001), compared to
participants who identified as being in the political
center. Trust in the source of the link was a significant
Table 4. Results from logistic regression analysis of link selection

 

 

95 % CI
Estimate Std. Wald = sig. Exp(B) Lower Upper
error stat. bound bound

(Intercept) -4.47 86 27.24 <.001 01 -6.15 -2.79
Link position .001 08  .0003 99 1 -.16 17
Link ideology: Left-wing 2.09 92 5.18 <.05 8.11 29 3.89
Link ideology: Right-wing 3.13 78 16.06 <.001 22.94 1.6 4.67
Participant self-identification: 1.93 5 14.74 <001 6.87 94 2.91
Left-wing
Participant self-identification: 2.06 AQ 1741 <001 7.82 1.09 3.02
Right-wing
Participant ideology: Conservative 2 .89 .05 82 1.22 -1.54 1.94
Participant ideology: Liberal -.58 .96 35 55 56 -2.46 1.32
Trust in Link source: Mid 94 A2 483 <.05 2.5 Al 1.78
Trust in Link source: High AS 31 2.05 15 1.56 -.17 1.06
Participant ideology: Conservative -.16 1.29 02 9 85 -2.7 2.37
* Link ideology: Left
Participant ideology: Conservative 43 1.08 16 69 1.5 -1.69 2.55
* Link ideology: Right
Participant ideology: Liberal 2.46 1.2 422 <05 11.64 ll 48
* Link ideology: Left-wing
Participant ideology: Liberal -.17 1.1 02 88 84 -2.32 1.98

* Link ideology: Right-wing

 

McFadden R? = 34

predictor when Trust was medium-high (p < .05), but
not when it was low or high. Participant ideology was
not a significant predictor, however, a significant
interaction was observed between participant ideology
and link ideology, such that selection-agreement was
significantly greater for liberal participants selecting
left-wing links (p < .05). There were no other
statistically significant interaction effects. Link
position was not a significant predictor of selection-
ideology agreement, supporting hypothesis H1b (see
Table 4).

4 Discussion
Moving the conversation on filter bubbles

The filter bubble hypothesis posits that algorithmic
curation of search results facilitates ideological
segregation, with significant implications for society
(Pariser, 2011, Liljeblad, 2012) and the personal
beliefs of individuals (e.g., Miller & Record, 2013).
However, empirical research on this topic has largely

failed to support the hypothesis (e.g., Hannak et al.,
2017; Haim et al., 2017). An alternative explanation,
here referred to as the self-imposed filter bubble
hypothesis (see Yom-Tov et al., 2014), posits that filter
bubble-like effects may be imposed by users
themselves, acting preferentially on sets of search
results, attending to, and selecting from, confirming
(and trusted) sources of information, rather than
disconfirming (and distrusted) ones. In this thesis, I
have attempted an empirical test of this hypothesis.
Quantitative analysis of selection data provided
support for hypothesis Hla (Partisans select search
results in line with their group and ideology, and select
against search results that are not in line with their
group and ideology), such that both left-wing
identifying and right-wing identifying participants
tended to select own-side links; and strong support for
hypothesis Hlb (The top-link heuristic holds when
search results align with searcher’s ideology, but not
when it does not), such that link position appeared
irrelevant to partisans’ selection. Notably, some of the

10
strongest evidence found by this thesis supported
confirmation of hypothesis H2 (People pay more
attention to links associated with trusted sources,
compared to untrusted ones, and select them more
often), such that trust in the source associated with a
link predicted both the attention paid to, and
subsequent selection of, that link. Analysis of eye
movement data provided partial support for H3a
(People pay more attention to search results that are in
line with their ideology) and confirmation of
hypothesis H3b (Liberal and left-wing partisans
exhibit stronger attention bias compared to right-wing
partisans), such that Liberal partisans did exhibit a
stronger attention bias to own-side (left-wing) links,
while Conservatives did not. Consistent with the
results of the other analyses described above, there was
partial support for hypothesis H4 (People inspect
opposing-side information less carefully,
operationalized as differences in reading depth.), such
that Liberal participants read own-side links more
closely than other-side links.

The present study contributes to the current
literature in several ways. Firstly, it adds to an
understanding of how politically partisan users of
search engines engage with political content in SERPs.
It also provides some empirical evidence of partisans’
politically self-segregating online behavior, both in the
early stages of information processing and attention —
a novel contribution — and in subsequent selection of
content, which is consistent with prior literature on
selective exposure (Klapper, 1960; Sears & Freedman,
1967). Notably, however, a visual attention bias for
own-side content was only observed for liberal
participants. This bias in left-leaning participants is
consistent with some previous research. For instance,
there is evidence that left-wing and liberal partisans
would be more punishing of opposite-side material,
such as exhibiting a stronger tendency to “unfriend”
opposite-side endorsing friends on social networks
(e.g., Cox & Jones, 2016; but for a nuanced account,
see Mitchell et al., 2014). As of the time of writing, it
is unclear whether liberals and conservatives exhibit
some measurable differences in terms of information
processing that might otherwise explain these findings
(but see Jost & Amodio, 2011). Significantly, while
visual attention was biased in only a subset of the
sample, analysis of selection data was more broadly
consistent with earlier findings on selective exposure
in online environments and information search (e.g.,
Garrett, 2009a; Bakshy et al., 2015). Both right-wing
and left-wing partisans strongly curated their chosen
links, effectively engaging in a process of selective
exposure. Altogether, these results suggest that
partisans’ selection bias is stronger than that of their
visual attention.

This thesis also provides evidence that trust in a
source of information serves as an important predictor
of both visual attention and selection of a link. In
research on message reliability, people’s evaluations of
communicated information tend to be contingent on

both relevance and plausibility (see Sperber et al.,
2010; Mercier et al., 2017; Mercier, 2020). In this study,
I assumed that political alignment and agreement
signified relevance more broadly; we further argue that
participants’ ratings of trust in sources of the presented
links tapped into values of apparent plausibility, such
that a more trusted source should on average be
expected to provide more plausible and reliable news
coverage and opinion-making. To the author’s
knowledge, this represents the first time such results
have been demonstrated in an online information
search environment. Notably, however, they align with
previous research on what facilitates engagement with
opposite-side information or sources. For example,
Yom-Tov et al., (2014) found that people were more
likely to click on documents representing the opposing
view when the language model (computed based on
popular Democrat- and Republican-leaning news
outlets) of that document was consistent with their own
views. Moving forward, others have emphasized the
potential role of novel technology in facilitating
interactions across political boundaries, such as
software encouraging engagement with opposite-side
sources and views (e.g., Bozdag & van den Hoven,
2015). Thus, taking account of the cognitive
mechanisms that underlie selective exposure, allows
researchers to gain better understanding into the
supposed problem of filter bubbles.

Given the results presented in this thesis, it appears
necessary that the focus of the filter bubble debate (e.g.,
Pariser, 2011) be shifted to properly incorporate the
role of the individual user and how he or she engages
with the information made available by internet search
engines. If validated further, the findings presented in
this work may have significant implications for
government policy (and the choice of whether or not to
regulate internet search engines), and for internet tech
companies more broadly. After all, attempts at
counteracting possible filter bubble-type effects
through changes to the algorithms that generate search
results — e.g., by presenting users with ideologically
diverse information — has little consequence, if those
users do not attend to other-side information, and thus
never choose to interact with it. Itis therefore necessary
that researchers seek to move the discussion on filter
bubbles, from algorithmic curation of search results
(for which empirical results are few) to the mind of
users who see, attend, and select from them.

Limitations

The study suffered from several limitations that
need addressing. First, in our data, some ideological
concepts appeared almost universally appreciated. For
example, only 4 out of 48 participants claimed to have
negative feelings towards abortion. Thus, it appears
that the SECS inventory (Everett, 2013) (which was
invented for studying ideology in the US) may be less
useful in a Swedish context. Swedes are, on average,
high on secular values, and highly liberal by
international standards (World Values Survey, 2021).

11
They are also among the people in the world scoring
the highest on values of self-expression, signifying
general acceptance of societal outgroups such as
immigrants and sexual minorities (e.g., homosexuals),
and trust in government. Thus, the lack of hypothesized
interaction effect may stem from a failure to sample a
sufficiently high number of Swedish conservatives (as
defined by Everett, 2013). Relatedly, the present study
also did not attempt to control for participants’ actual
knowledge of political affairs and events (1.e., political
sophistication, see Lodge & Taber, 2005). It is likely
that possessing demonstrable knowledge on some
political topic may impact attention to presented
information on that same topic.

Further, it is possible that a simple three-level
coding of political material (left-Center-right;, Liberal-
Center-Conservative) is not sophisticated enough to
capture the mechanisms of political information
processing in a Swedish sample. Specifically, the lack
of statistically significant effect of visual attention to
own-side material in Conservative and right-wing
participants may be an artefact of link sampling.
Currently, Swedish right-wing politics is divided
between a socially liberal but fiscally conservative
faction, and another more socially conservative, anti-
establishment faction (for an overview, see Esaiasson
& Wangnerud, 2016). Meanwhile, no equivalent
discrepancy currently exists for left-wing politics. It is
possible, then, that supposedly right-wing content in
presented links played to one of these right-wing
factions and not the other, attracting some right-wing
identifying participants but repelling others. Were this
to be addressed in future research, it is possible that a
visual attention bias for own-side content would be
found for Conservative and right-wing participants.
However, as no research of this kind is known to the
author at the point of writing, this possibility remains
solely hypothetical.

A second point of contention concerns the
generalizability of the findings. Importantly, much
eye-tracking research has shown discrepancies in eye
movements for laboratory settings, as compared with
their real-life counterparts (e.g., Gidléf et al., 2013;
Mulckhuyse et al., 2008; Born et al., 2011; Foulsham
et al., 2011). In light of these findings, we cannot rule
out the possibility that our information search task is
not close enough to the real experience of online
information search. In real life, search terms are not
given but thought up dynamically by the user.
Typically, users tailor search terms to current needs,
using combinations of phrases they deem likely to
produce wanted results. For political partisans, this
may also involve searching for political information in
biased terms, more likely to return lists of results
appropriate to those same views. Thus, as links used in
the present study were controlled for political content,
this is unlikely to reflect the real-life situation of biased
attention in online information search.

The above limitation also dovetails with a more
general concern for the ecological validity of the

presented work. Specifically, when participants are
probed for responses to affectively charged stimuli —
such as political content — they may be prone to self-
censorship, shying away from particularly radical or
unusual responses (i.e., exhibit demand characteristics).
For this reason, future work on the topic may thus
strive for more naturalistic settings. For instance,
recent developments in eye tracking present the
possibility of conducting eye movement research using
participants’ own webcams in their home (e.g.,
Papoutsaki et al., 2017; see also Semmelmann &
Weigelt, 2018). However, it remains yet to be seen how
this development could be used in the scientific study
of visual attention in online information search outside
of formal lab environments.

Finally, we cannot rule out any effect of framing.
The sampled links included as stimuli were not
controlled for any attention-grabbing quality inherent
in their headlines. For instance, some authors have
suggested that “clickbait” — a style of headline
designed to generate engagement from its online
audience by inducing them to click to access its content
— may drive affective polarization between left-wing
and right-wing online audiences (e.g., Settle, 2018).
This possibility cannot as of yet be ruled out, although
recent work on clickbait headlines by Munger et al.,
(2020) found no effect of clickbait headlines on
affective polarization. There are also no studies known
to this author, showing differences in prevalence or
effectiveness of clickbait-style articles for left-wing or
right-wing content. Additionally, while clickbait-type
headlines were effective early to mid-2010’s, they have
recently seen a drastic reduction in use — and in
profitability in recent years (see Rayson, 2018).
Therefore, effects of framing of news items inherent in
the links may be negligible — though it not possible to
say for certain.

Summary and directions for future research

This work investigated potential filter bubble-type
effects resulting from partisans’ visual attention and
subsequent selection. It appears that link position
significantly affects which links are initially attended —
but evaluation and (especially) selection are mediated
by partisans’ perception of its apparent content and by
the trust placed in the sources associated with those
contents. The expected interaction effect for visual
attention between partisanship and link content was
only found a subset of participants, Liberal participants
attending left-wing content. As for now, however, this
picture remains incomplete. Whereas the literature on
selective attention in web search has integrated eye
movement research, there is much still in the fields of
cognitive science that might provide insights into any
potential polarizing behavior.

Firstly, prior research on eye movements during
reading have found that readers’ expectations (Strukelj,
2018), and working memory capacity (Daneman &
Carpenter, 1980; Dixon et al., 1988; Strukelj et al.,
2017) may affect their visual processing of reading

12
material. This thesis contributes to this body of
literature, suggesting that (some) partisans read own-
side affirming information more carefully than other-
side affirming, and that readers, in general, read trusted
information more carefully than they do mistrusted
information. For political information processing, this
raises the possibility of social group differences in
processing of reading material — something largely
unexplored in the relevant literature.

It is also possible that opposite-side information
constitutes a different working memory load compared
to own-side information, where the first prompts
avoidance and the second prompts engagement. The
results presented in this thesis thus presents intriguing
possible implications for future studies on the subject
of political information processing in real time. How
do partisans engage (or fail to engage) when reading
news items or opinion pieces written by writers they
distrust or presenting a disliked conclusion? Further
research on the topic may help further elucidate the
intricacies of biased information processing.

A second area for future investigation is that of so-
called knowledge resistance (see Wikforss, 2017;
Klintman, 2019; see also O'Connor & Weatherall,
2019; Mercier, 2020). In recent years, there has been
widespread concern that (some or all) individuals are
somehow resistant to information that might otherwise
change their minds. The work presented in this thesis,
attempting to integrate eye movements within a
framework of partisans’ information processing, helps
point the way toward a formal integration of cognitive
science with this novel and significant development
(but see Mercier, 2020).

Finally, the findings presented in this thesis help
provide clues into the cognitive mechanisms that
underlie political partisanship — a development that
should be seen against the backdrop of
neuropsychological studies of partisan information
processing (see Jost & Amodio, 2011; Jost et al., 2014).
For example, a functional magnetic resonance imaging
study by Westen et al., (2006) observed selective
activity in the brains of American political Liberals and
Conservatives while reasoning about information that
was threatening either to their own candidate in the
2004 American presidential election or to the opposing
candidate. Results suggested that motivated reasoning
implicated emotional processing and was not linked to
activity in brain regions associated with “cold” (or
objective) reasoning. The authors argued that
motivated reasoning was qualitatively distinct from
reasoning, when participants do not have a strong
emotional stake in the conclusions. Such and similar
work may provide clues as to how partisans’ treat
information, once attended. As communication
research has progressively sought to integrate tools of
cognitive science, an extension to neuroscientific tools
has become feasible. Moreover, the strong effect of
trust found in this thesis suggests a role in information
processing more broadly. Significantly, it also
supersedes any definition of ideology and extends to

settings outside of online political information
processing. Moving forward, neuropsychological
research should seek to investigate the relationship
between motivated reasoning, objective reasoning, and
trust, incorporating what is known about selective
exposure, so as to provide deeper knowledge of the
partisan brain and mind.

5 Conclusions

This thesis presented the self-imposed filter bubble
hypothesis, the proposition that political partisans
engage in self-segregating behavior in online
information search. It found partial empirical support
for its main hypothesis and strong support that such
behavior may be driven less by political persuasion per
se, and more by the trust individuals place in the
sources of link material, such that less trusted sources
are typically both attended less and selected against.

Acknowledgements

This Master’s thesis originated in discussions between
Axel Ekstrém — the author — and Erik J. Olsson,
Professor of Theoretical Philosophy at Lund
University, in the context of the research project Filter
Bubbles and Ideological Segregation Online: Do We
Need Regulation of Search Engines?, funded by The
Bank of Sweden Tercentenary Foundation (2019-2021,
Olsson PI). The original idea of studying filter bubbles
in search engines using eye-tracking technology was
the author’s. The experimental design was developed
by the author in collaboration with Olsson, who also
contributed to the hypothesis formation. The original
hypotheses were supplemented and refined by the
author, who also recruited and administered all
participating subjects, and carried out all experiments
(including the described pre-study) and subsequent
data analyses. Ekstrém’s administration of the
experiments was funded by the above research project,
in which he participated as a research assistant, as were
the vouchers that were given to the subjects as
compensation for their participation.

References

Armel, K. C., Beaumel, A., & Rangel, A. (2008).
Biasing simple choices by manipulating relative
visual attention. Judgment and — Decision
making, 3(5), 396-403.

Bakshy, E., Messing, S., & Adamic, L. A. (2015).
Exposure to ideologically diverse news and opinion
on Facebook. Science, 348(6239), 1130-1132.

Bartels, L. M. (2018). Unequal democracy: The
political economy of the new gilded age. Princeton
University Press.

Birnbaum, M. H., Wong, R., & Wong, L. K. (1976).
Combining information from sources that vary in
credibility. Memory & Cognition, 43), 330-336.

13
Birnbaum, M. H., & Stegner, S. E. (1979). Source
credibility in social judgment: Bias, expertise, and
the judge's point of view. Journal of Personality
and Social Psychology, 37(1), 48.

Bode, L. (2016). Pruning the news feed: Unfriending
and unfollowing political content on social
media. Research & Politics, 3(3), 2 053 168 016
661 873.

Born, S., Kerzel, D., & Theeuwes, J. (2011). Evidence
for a dissociation between the control of
oculomotor capture and
disengagement. Experimental Brain
Research, 208(4), 621-631.

Bozdag, E., & Van Den Hoven, J. (2015). Breaking the
filter bubble: democracy and design. Ethics and
information technology, 17(4), 249-265.

Bovens, L., & Hartmann, 8. (2003). Bayesian
epistemology. Oxford University Press on Demand.

Brader, T. (2006). Campaigning for hearts and minds:
How emotional appeals in political ads work.
University of Chicago Press.

Brewer, M. B. (1979). In-group bias in the minimal
intergroup situation: A  cognitive-motivational
analysis. Psychological bulletin, 86(2), 307.

Cardenal, A. S., Aguilar-Paredes, C., Galais, C., &
Pérez-Montoro, M. (2019). Digital technologies
and selective exposure: How choice and filter
bubbles shape news media exposure. The
international journal of press/politics, 24(4), 465-
486.

Chong, D. (2013). Degrees of rationality in politics.
In (L. Huddy, D. O. Sears, & L. S. Levery (Eds.),
The Oxford handbook of political psychology (pp.
96-129).

Cinelli, M., Brugnoli, E., Schmidt, A. L., Zollo, F.,
Quattrociocchi, W., & Scala, A. (2020). Selective
exposure shapes the Facebook news diet. PloS
one, 15(3), 0229129.

Cohen, G. L. (2003). Party over policy: The
dominating impact of group influence on political
beliefs. Journal of personality and _ social
psychology, 85(5), 808.

Colleoni, E., Rozza, A., & Arvidsson, A. (2014). Echo
chamber or public sphere? Predicting political
orientation and measuring political homophily in
Twitter using big data. Journal of
communication, 64(2), 317-332.

Collins, P. J., Hahn, U., von Gerber, Y., & Olsson, E.
J. (2018). The bi-directional relationship between
source characteristics and message
content. Frontiers in psychology, 9, 18.

Courtois, C., Slechten, L., & Coenen, L. (2018).
Challenging Google Search filter bubbles in social
and political information: Disconfirming evidence
from a digital methods case study. Telematics and
Informatics, 35(7), 2006-2015.

Cox, D., & Jones, R. (2016). Merry Christmas’
vs.Happy Holidays’: Republicans and Democrats
are polar opposites. Public Religion Research
Institute report.

Daneman, M., & Carpenter, P. A. (1980). Individual
differences in working memory and
reading. Journal of verbal learning and verbal
behavior, 194), 450-466.

Deubel, H., & Schneider, W. X. (1996). Saccade target
selection and object recognition: Evidence for a
common attentional mechanism. Vision
research, 36(12), 1827-1838.

Dilliplane, S. (2011). All the news you want to hear:
The impact of partisan news exposure on political
participation. Public Opinion Quarterly, 75, 287—
316.

Dixon, P., Lefevre, J. A., & Twilley, L. C. (1988).
Word knowledge and working memory as
predictors of reading skill. Journal of educational
psychology, 80(4), 465.

Duchowski, A. T. (2002). A breadth-first survey of
eye-tracking applications. Behavior Research
Methods, Instruments, & Computers, 34(4), 455—
470.

Eibl-Eibesfeldt, I. (1979). Human ethology: Concepts
and implications for the sciences of
man. Behavioral and Brain Sciences, 2(1), 1-26.

Efron, B. (1978). Regression and ANOVA with zero-
one data: Measures of residual variation. Journal of
the American Statistical Association, 73(361), 113-
121.

Esaiasson, P., & Wangnerud, L. (2016). Political
parties and political representation. In J. Pierre
(Ed.), The Oxford Handbook of Swedish
Politics (pp. 188-205). Oxford University Press.

Everett, J. A. (2013). The 12 item social and economic
conservatism scale (SECS). PloS — one, 8(12),
e82131.

Festinger, L. (1957).4 theory of cognitive
dissonance (Vol. 2). Stanford university press.

Flaxman, S., Goel, S., & Rao, J. M. (2016). Filter
bubbles, echo chambers, and online news
consumption. Public opinion quarterly, 80(S1),
298-320.

Foulsham, T., Walker, E., & Kingstone, A. (2011). The
where, what and when of gaze allocation in the lab
and the natural environment. Vision
research, 51(17), 1920-1931.

Frey, D. (1986). Recent research on selective exposure.
In L. Berkowitz (Ed.), Advances in experimental
social psychology (Vol. 19, pp. 41- 80). New York:
Academic Press.

Garrett, R. K. (2009a). Echo chambers online?:
Politically motivated selective exposure among
Internet news users. Journal of Computer-
Mediated Communication, 14(2), 265-2835.

Garrett, R. K. (2009b). Politically motivated
reinforcement seeking: Reframing the selective
exposure debate. Journal of communication, 594),
676-699.

Garrett, R. K., & Resnick, P. (2011). Resisting political
fragmentation on the Internet. Daedalus, 140(4),
108-120.

14
Garrett, R. K. (2013). Selective exposure: New
methods and new directions. Communication
Methods and Measures, 7(3-4), 247-256.

Gerber, A., & Green, D. P. (1998). Rational learning
and partisan attitudes. American journal of political
science, 794-818.

Gentzkow, M., & Shapiro, J. M. (2011). Ideological
segregation online and offline. The Quarterly
Journal of Economics, 126(4), 1799-1839.

Gidléf, K., Wallin, A., Dewhurst, R., & Holmqvist, K.
(2013). Using eye tracking to trace a cognitive
process: Gaze behaviour during decision making in
a natural environment.

Glaholt, M. G., & Reingold, E. M. (2009). Stimulus
exposure and gaze bias: A further test of the gaze
cascade model. Attention, — Perception, &
Psychophysics, 71(3), 445-450.

Glaholt, M. G., Wu, M. C., & Reingold, E. M. (2009).
Predicting preference from fixations. PsychNology
Journal, 7(2), 141-158.

Granka, L. A., Joachims, T., & Gay, G. (2004, July).
Eye-tracking analysis of user behavior in WWW
search. In Proceedings of the 27th annual
international ACM SIGIR conference on Research
and development in information retrieval (pp. 478-
479).

Haim, M., Arendt, F., & Scherr, S. (2017). Abyss or
shelter? On the relevance of web search engines’
search results when people google for
suicide. Health communication, 32(2), 253-258.

Hannak, A., Sapiezynski, P., Molavi Kakhki, A.,
Krishnamurty, B., Lazer, D., Mislove, A., &
Wilson, C. (2013, May). Measuring personalization
of web search. In Proceedings of the 22"4
international conference on World Wide Web (pp.
527-538).

Hastorf, A. H., & Cantril, H. (1954). They saw a game;
a case study. The Journal of Abnormal and Social
Psychology, 491), 129.

Henderson, J. M., Weeks Jr, P. A., & Hollingworth, A.
(1999). The effects of semantic consistency on eye
movements during complex scene
viewing. Journal of experimental psychology:
Human perception and performance, 25(1), 210.

Henderson, J. M., & Hayes, T. R. (2017). Meaning-
based guidance of attention in scenes as revealed by
meaning maps. Nature Human Behaviour, 1(10),
743-747.

Hewstone, M., Rubin, M., & Willis, H. (2002).
Intergroup bias. Anmual review of
psychology, 53(1), 575-604.

Higgins, E., Leinenger, M., & Rayner, K. (2014). Eye
movements when viewing
advertisements. Frontiers in psychology, 5, 210.

Himelboim, I., Smith, M., & Shneiderman, B. (2013).
Tweeting apart: Applying network analysis to
detect selective exposure clusters ~— in
Twitter. Communication methods and
measures, 7(3-4), 195-223.

Holmgqvist, K., Nystrém, M., Andersson, R., Dewhurst,
R., Jarodzka, H., & Van de Weijer, J. (2011). Eye
tracking: A comprehensive guide to methods and
measures. OUP Oxford.

Hotchkiss G., Alston S., & Edwards G. (2005). Google
Eye Tracking Report: How Searchers See and Click
on Google Search Results (Enquiro Search
Solutions). Accessed January 24, 2021,
https://searchengineland .com/figz/wp-
content/seloads/2007/09/hotchkiss-eye-tracking  -
2005.pdf.

Google Search Statistics. (2021, May 12). Internet
Live Stats.
hitps://www.internetlivestats.com/google-search-
statistics/

Jamieson, K. H., & Cappella, J. N. (2008). Echo
chamber: Rush Limbaugh and the conservative
media establishment. Oxford University Press.

Joachims, T., Granka, L., Pan, B., Hembrooke, H..,
Radlinski, F., & Gay, G. (2007). Evaluating the
accuracy of implicit feedback from clicks and
query reformulations in web search. ACM
Transactions on Information Systems (TOIS), 25(2),
7-€s.

Jost, J. T., & Amodio, D. M. (2012). Political ideology
as motivated social cognition: Behavioral and
neuroscientific evidence. Motivation and
Emotion, 36(1), 55-64.

Jost, J. T., Nam, H. H., Amodio, D. M., & Van Bavel,
J. J. (2014). Political neuroscience: The beginning
of a beautiful friendship. Political Psychology, 35,
3-42.

Just, M. A., & Carpenter, P. A. (1980). A theory of
reading: From eye fixations to
comprehension. Psychological review, 87(4), 329.

Kahan, D. M., Hoffman, D. A., Braman, D., Evans, D.,
& Rachlinski, J. J. (2012). They saw a protest:
Cognitive illiberalism and the speech-conduct
distinction. Stan. L. Rev., 64, 851.

Kammerer, Y., & Gerjets, P. (2012). How search
engine users evaluate and select Web search
results: The impact of the search engine interface
on credibility assessments. In Web search engine
research. Emerald Group Publishing Limited.

Kammerer, Y., & Gerjets, P. (2014). The role of search
result position and source trustworthiness in the
selection of web search results when using a list or
a grid interface. International Journal of Human-
Computer Interaction, 30(3), 177-191.

Kawakami, K., Williams, A., Sidhu, D., Choma, B. L.,
Rodriguez-Bailon, R., Cafiadas, E., 2. &
Hugenberg, K. (2014). An eye for the I: Preferential
attention to the eyes of ingroup members. Journal
of Personality and Social Psychology, 107(1), 1.

Klapper, J. T. (1960). The effects of mass
communications. Glencoe, IL: Free Press.

Kliegl, R., Nuthmann, A., & Engbert, R. (2006).
Tracking the mind during reading: The influence of
past, present, and future words on_ fixation

15
durations. Journal of experimental psychology:
General, 135(1), 12.

Klintman, M. (2019). Knowledge resistance: How we
avoid insight from others. Manchester University
Press.

Knobloch-Westerwick, S. & Meng, J. (2011).
Reinforcement of the political self through
selective exposure to political messages. Journal of
Communication, 61(2), 349-368.

Krajbich, I., Armel, C., & Rangel, A. (2010). Visual
fixations and the computation and comparison of
value in simple choice. Nature
neuroscience, 13(10), 1292-1298.

Lazarsfeld, P. F., Berelson, B., & Gaudet, H. (1948).
The people’s choice: How the voter makes up his
mind in a presidential campaign. New York:
Columbia University Press.

Liljeblad, J. (2012). The Implications of Personal
Internet Search for Theories of Global Civil
Society. International Journal of Technology,
Knowledge & Society, 8(1).

Lodge, M., & Taber, C. S. (2005). The automaticity of
affect for political leaders, groups, and issues: An
experimental test of the hot cognition
hypothesis. Political Psychology, 26(3), 455-482.

Luke, S. G., & Henderson, J. M. (2016). The influence
of content meaningfulness on eye movements
across tasks: evidence from scene viewing and
reading. Frontiers in psychology, 7,257.

Maughan, L., Gutnikov, S., & Stevens, R. (2007). Like
more, look more. Look more, like more: The
evidence from eye-tracking. Journal of Brand
management, 14(A4), 335-342.

Marquart, F., Matthes, J., & Rapp, E. (2016). Selective
exposure in the context of political advertising: A
behavioral approach using — eye-tracking
methodology. International Journal of
Communication, 10, 20.

Mercier, H., Dezecache, G., & Scott-Phillips, T. (2017).
Strategically Communicating Minds. Current
Directions in Psychological Science, 26(5), 411-
416.

Mercier, H. (2020). Not born yesterday: The science of
who we trust and what we believe. Princeton
University Press.

Messing, S., & Westwood, S. J. (2014). Selective
exposure in the age of social media: Endorsements
trump partisan source affiliation when selecting
news online. Communication — research, 41(8),
1042-1063.

Miller, B., & Record, I. (2013). Justified belief in a
digital age: On the epistemic implications of secret
Internet technologies.

Mills, C. M. (2013). Knowing when to doubt:
Developing a critical stance when learning from
others. Developmental psychology, 49(3), 404.

Mitchell, A., Gottfried, J., Kiley, J., & Matsa, K. E.
(2014). Political Polarization & Media Habits:
From Fox News to Facebook. How Liberals and

Conservatives Keep Up with Politics, Washington,
DC: Pew Research Center.

Mulckhuyse, M., van Zoest, W., & Theeuwes, J. (2008).
Capture of the eyes by relevant and irrelevant
onsets. Experimental Brain Research, 186(2), 225-
235.

Mullen, B., Brown, R., & Smith, C. (1992). Ingroup
bias as a function of salience, relevance, and status:
An integration. European journal of social
psychology, 22(2), 103-122.

Munger, K., Luca, M., Nagler, J., & Tucker, J. (2020).
The (null) effects of clickbait headlines on
polarization, trust, and learning. Public opinion
quarterly.

Mutz, D. C., & Martin, P. S. (2001). Facilitating
communication across lines of political difference:
The role of mass media. American political science
review, 97-114.

Navalpakkam, V., & Itti, L. (2005). Modeling the
influence of task on attention. Vision
research, 45(2), 205-231.

Nickerson, R. S. (1998). Confirmation bias: A
ubiquitous phenomenon in many guises. Review of
general psychology, 2(2), 175-220.

Nielsen, J., & Pernice, K. (2010). Eyetracking web
usability. New Riders.

O'Connor, C., & Weatherall, J. O. (2019). The
misinformation age: How false beliefs spread. Yale
University Press.

Olsson, E. J. (2011). A simulation approach to
veritistic social epistemology. Episteme-
Edinburgh, 8(2), 127.

Olsson, E. J., & Vallinder, A. (2013). Norms of
assertion and communication in _ social
networks. Synthese, 190(13), 2557-2571.

Pan, B., Hembrooke, H., Joachims, T., Lorigo, L., Gay,
G., & Granka, L. (2007). In Google we trust: Users’
decisions on rank, position, and relevance. Journal
of computer-mediated communication, 12(3), 801-
823.

Papoutsaki, A., Laskey, J., & Huang, J. (2017, March).
Searchgazer: Webcam eye tracking for remote
studies of web search. In Proceedings of the 2017
Conference on Conference Human Information
Interaction and Retrieval (pp. 17-26).

Pariser, E. (2011). The Filter Bubble: What the Internet
1s Hiding from You. Penguin Press.

Parmelee, J. H., & Roman, N. (2020). Insta-echoes:
Selective exposure and selective avoidance on
Instagram. Telematics and Informatics, 52, 101432.

Pamamets, P., Johansson, P., Hall, L., Balkenius, C.,
Spivey, M. J., & Richardson, D. C. (2015). Biasing
moral decisions by exploiting the dynamics of eye
gaze. Proceedings of the National Academy of
Sciences, 112(13), 4170-4175.

Pau, G., Fuchs, F., Sklyar, O., Boutros, M., & Huber,
W. (2010). EBImage—an R package for image
processing with applications to cellular
phenotypes. Bioinformatics, 26(7), 979-981.

16
Peacock, C. E., Hayes, T. R., & Henderson, J. M.
(2019). Meaning guides attention during scene
viewing, even when it is irrelevant. Affention,
Perception, & Psychophysics, 81(1), 20-34.

Petrescu, P. (2014, October 1). Google Organic Click-
Through Rates in 2014. MOZ Blog.
https://moz.com/blog/google-organic-click-
through-rates-in-2014.

Petty, R. E., & Cacioppo, J. T. (1984). Source factors
and the elaboration likelihood model of
persuasion. ACR North American Advances.

Petty, R. E., & Cacioppo, J. T. (1986). The elaboration
likelihood model of persuasion. In Communication
and persuasion (pp. 1-24). Springer, New York,
NY.

Purcell, K., Rainie, L., & Brenner, J. (2012, March 9).
Search engine use, 2012. Pew Internet and
American Life Project, 9. Retrieved from
http://pewinternet.org/Reports/2012/Search-
Engine-Use-2012.aspx

Rand, D. G., Pfeiffer, T., Dreber, A., Sheketoff, R. W.,
Wernerfelt, N. C. & Benkler, Y. Dynamic
remodeling of in-group bias during the 2008
presidential election. Proc. Natl. Acad. Sci. USA
106, 6187-6191 (2009).

Rayner, K. (1998). Eye movements in reading and
information _ processing: 20 ~years”=s of
research. Psychological bulletin, 124(3), 372.

Rayson, S. (2018). Content, shares, and links: Insights
from analyzing 1| million articles. moz. com, 8.

Salmerén, L., Kammerer, Y., & Garcia-Carrién, P.
(2013). Searching the Web for conflicting topics:
Page and user factors. Computers in Human
Behavior, 29(6), 2161-2171.

Schmuck, D., Tribastone, M., Matthes, J., Marquart, F.,
& Bergel, E. M. (2019). Avoiding the other side?
An eye-tracking study of selective exposure and
selective avoidance effects in response to political
advertising. Journal of Media Psychology:
Theories, Methods, and Applications.

Schultheif, S., Siinkler, S., & Lewandowski, D. (2018).
We still trust in Google, but less than 10 years ago:
an eye-tracking study. Information Research: An
International Electronic Journal, 23(3), n3.

Sears, D. O., & Freedman, J. L. (1967). Selective
exposure to information: A critical review. Public
Opinion Quarterly, 31(2), 194-213.

Semmelmann, K., & Weigelt, S. (2018). Online
webcam-based eye tracking in cognitive science: A
first look. Behavior Research Methods, 50(2), 451-
465.

Settle, J. E. (2018). Frenemies: How social media
polarizes America. Cambridge University Press.
Shimojo, S., Simion, C., Shimojo, E., & Scheier, C.
(2003). Gaze bias both reflects and influences
preference. Nature neuroscience, 6(12), 1317-

1322

Simion, C., & Shimojo, S. (2006). Early interactions

between orienting, visual sampling and decision

making in facial preference. Vision
research, 46(20), 3331-3335.

Simion, C., & Shimojo, S. (2007). Interrupting the
cascade: Orienting contributes to decision making
even in the absence of visual
stimulation. Perception & psychophysics, 694),
591-595.

Spohr, D. (2017). Fake news and _ ideological
polarization: Filter bubbles and selective exposure
on social media. Business Information
Review, 34(3), 150-160.

Staub, A. (2015). The effect of lexical predictability on
eye movements in reading: Critical review and
theoretical interpretation. Language and
Linguistics Compass, 98), 311-327.

Stinchcombe, A. L. (2010). Going to extremes: How
like minds unite and divide. Contemporary
Sociology: A Journal of Reviews, 39, 205-206.

Strukelj, A. (2018). Reading expectations: How
expectations influence our reading, eye movements,
opinions, and judgments. Lund University.

Strukelj, A., & Niehorster, D. C. (2018). One page of
text: Eye movements during regular and thorough
reading, skimming, and spell checking. Journal of
Eye Movement Research, 11(1).

Strukelj, A., Nystrém, M., & Holmqvist, K. (2017).
The effects of conceptual and perceptual difficulty
on processing and engagement in text during
reading and learning. In /9¢h European Conference
on Eye Movements.

Silflow, M., Schafer, S., & Winter, S. (2019).
Selective attention in the news feed: An eye-
tracking study on the perception and selection of
political news posts on Facebook. new media &
society, 21(1), 168-190.

Sunstein, C. R. (1999). The law of group
polarization. University of Chicago Law School,
John M. Olin Law & Economics Working Paper,
(91).

Tajfel, H., & Turner, J. C. (1986). The social identity
theory of intergroup behavior. In S. Worchel & W.
G. Austin (Eds.), Psychology of intergroup
relations (2nd ed., pp. 7-24). Nelson-Hall.

Valentino, N. A., Banks, A. J., Hutchings, V. L., &
Davis, A. K. (2009). Selective exposure in the
Internet age: The interaction between anxiety and
information utility. Political Psychology, 30(4),
591-613.

V6, M. L. H., & Henderson, J. M. (2009). Does gravity
matter? Effects of semantic and syntactic
inconsistencies on the allocation of attention during
scene perception. Journal of Vision, 9(3), 24-24.

Vraga, E., Bode, L., & Troller-Renfree, S. (2016).
Beyond self-reports: Using eye tracking to measure
topic and style differences in attention to social
media content. Communication Methods and
Measures, 10(2-3), 149-164.

Weeks, B. E., Lane, D. S., Kim, D. H., Lee, S. S., &
Kwak, N. (2017). Incidental exposure, selective
exposure, and political information sharing:

17
Integrating online exposure patterns and expression
on social media. Journal of Computer-Mediated
Communication, 22(6), 363-379.

Westen, D., Blagov, P. S., Harenski, K., Kilts, C., &
Hamann, S. (2006). Neural bases of motivated
reasoning: An fMRI study of emotional constraints
on partisan political judgment in the 2004 US
presidential election. Journal of cognitive
neuroscience, 18(11), 1947-1958.

Xiao, Y. J., Coppin, G., & Van Bavel, J. J. (2016).
Perceiving the world through group-colored
glasses: A perceptual model of intergroup
relations. Psychological Inquiry, 27(4), 255-274.

Wikforss, A. (2017). Alternativa fakta: Om kunskapen
och dess fiender. Falun: Fri Tanke Forlag.

World Values Survey. (2021, April 24). Findings and
Insights

https://www.worldvaluessurvey.org/W VSContents
Jjsp?CMSID=findings&CMSID=findings

Yom-Tov, E., Dumais, S., & Guo, Q. (2014).
Promoting civil discourse through search engine
diversity. Social Science Computer Review, 32(2),
145-154.

Zillich, A. F., Kessler, S. H., Peter, C., Naab, T., &
Kine, R. (2019). Measuring selective exposure
to online information: combining eye-tracking and
content analysis of users’ actual search
behavior. Methoden und Forschungslogik der
Kommunikationswissenschaft, (14), 196-220

Zuiderveen Borgesius, F., Trilling, D., Moller, J.,
Bodo, B., De Vreese, C. H., & Helberger, N.
(2016). Should we worry about filter
bubbles?. Jnternet Policy Review. Journal on
Internet Regulation, 5.

18
