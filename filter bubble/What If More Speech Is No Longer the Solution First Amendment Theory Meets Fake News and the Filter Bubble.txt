What If More Speech Is No Longer the
Solution? First Amendment Theory
Meets Fake News and the Filter Bubble

Philip M. Napoli *

II.

II.

IV.

TABLE OF CONTENTS

INTRODUCTION .0...ecececcecceeceeceeeeeeeeececeeceeceeeseeeeeeseseresneeteeesireseesnreenees 57
COUNTERSPEECH AND THE FIRST AMENDMENT: ASSUMPTIONS,

APPLICATIONS, AND CRITIQUES ......cccceccecseeeeeeeeeeceeeeeeecneeereeneeenteees 60
A. THE COUNTERSPEECH DOCTRINE IN PRACTICE ......:::ceeceeeees 62
B. CRITIQUES OF COUNTERSPEECH .......:ccccccceeseeceeeeeseeeteeseeeeeeentens 66

How TECHNOLOGICAL CHANGES UNDERMINE THE COUNTERSPEECH
DOCTRINE 0... cececcceececeececeeeeeeceeeeeeeeceeeecrecaeseeecaeeseeseresneseeseeatesseseresnaes 68

A. THE RELATIVE PROMINENCE OF TRUE VERSUS FALSE NEWS...68
B. DIMINISHED GATEKEEPING AND DISTRIBUTION BARRIERS....... 71
C. INCREASED ABILITY TO TARGET THE MOST IMPRESSIONABLE .74
D

THE DIMINISHED LIKELIHOOD OF BEING EXPOSED TO FACTUAL
COUNTERSPEECH..0...cccccccececseeeeeeeseceeceeeceeeceesereceeseceesseenieeeeesntee 77

E. THE DIMINISHED ABILITY TO DISTINGUISH BETWEEN
LEGITIMATE AND FALSE NEWS.......:::ccceccceceeceeeeeeeeeeeeeteeeeeentens 79

F. THE ENHANCED SPEED AT WHICH FALSE NEWS CAN TRAVEL.85

IMPLICATIONS ......ceccceccecceececeeceeeeeececeeceeceeeseeeeeseeeereseeeeeseeneeseeeeneenees 87

 

James R. Shepley Professor of Public Policy, Sanford School of Public Policy, Duke

University; Andrew Carnegie Fellow. An earlier version of this paper was presented at the 45th
Research Conference on Communications, Information, and Internet Policy. The author
gratefully acknowledges the research assistance of Petra Ronald and Anne Napoli. This
publication was made possible by a grant from the Carnegie Corporation of New York. The
statements made and views expressed are solely the responsibility of the author.

-55-
A. THE FIRST AMENDMENT AND FALSITY ....0ccceccecceeseeeeeeeeteenees 87
B. MARKET FAILURE IN THE MARKETPLACE OF IDEAS........:.0006 88
C. THE 2016 PRESIDENTIAL ELECTION AS MARKET FAILURE CASE
STUDY ooeececccccecceeececneceeeeeceeeseecaeceeeeesceesereeeseeeeeesnesereeneseeets 93
D. THE FUTURE OF COUNTERSPEECH AND THE MARKETPLACE OF
IDEAS 0c cecececccecceceeceeceeeeeeeeeeeeeeeeeceeeeeeeceeseeesesseesursnieeseestiesieeentees 97
CONCLUSION... .ececccecceececeeceeeeeeeceeeceeceaeeceeceeeeaeeceeseeectesieesieesieeneents 103

- 56 -
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 57

I. INTRODUCTION

The results and aftermath of the 2016 U.S. presidential election have
brought increased attention to the dynamics of the contemporary news and
information ecosystem and how these dynamics affect citizen knowledge and
political decision-making. Specific points of focus have included the extent
to which algorithmically-driven search and social media platforms are
facilitating the construction of “filter bubbles” or “echo chambers”,! the
presence of political bias in content curation platforms,’ the extent to which
such platforms facilitate the widespread dissemination of false news stories,
and inflammatory political advertisements placed by foreign governments.*
These phenomena interact in ways that have raised significant concerns about
the nature of the relationship between contemporary news and information
channels, as well as the effective functioning of the democratic process.°

 

1. See generally, Mostafa M. El-Bermawy, Your Filter Bubble Is Destroying
Democracy, WIRED (Nov. 18, 2016, 5:45 AM), [https://perma.cc/K87X-NJ59], see also
Matthew Ingram, Facebook and the News: Trends, Filter Bubbles and Algorithmic Bias,
FORTUNE (May 12, 2016), _ http://fortune.com/2016/05/12/facebook-and-the-news/
[https://perma.cc/2KLF-EP6P].

2. See, e.g, Olivia Solon & Sam Levin, How Google's search algorithm spreads false
information with a rightwing bias, THE GUARDIAN (Dec. 16, 2016, 06:00 EST),
https: //www.theguardian.com/technology/2016/dec/16/google-autocomplete-nghtwing-bias-
algorithm-political-propaganda [https://perma.cc/COBT-2WP8]; see also Daniel Trielli et al.,
Googling Politics: How the Google Issue Guide on Candidates is Biased, SLATE (June 7, 2016),
http://www.slate.com/articles/technology/future_tense/2016/06/how_the google issue guide
_on_candidates is biased.html [https://perma.cc/N8DU-Y4HR], Nelson Granados, How
Facebook Biases Your News Feed, ForBES (June 30, 2016, 7:26 PM),
https: //www. forbes.com/sites/nelsongranados/2016/06/30/how-facebook-biases-your-news-
feed/#799f10621d51 [https://perma.cc/73LB-CYT4]; Issie Lapowsky, Of Course Facebook Is
Biased That's How Tech Works Today, WIRED (May I1, 2016, 7:00 AM)
https://www. wired.com/2016/05/course-facebook-biased-thats-tech-works-today/
[https://perma.cc/5AKR-63KV].

3. See generally, Jen Weedon et. al, FACEBOOK, INFORMATION OPERATIONS AND
FACEBOOK 8 (Version 1.0, Apr. 27, 2017),
https://fonewsroomus. files. wordpress.com/2017/04/facebook-and-information-operations-
vl.pdf [https://perma.cc/63QM-SH65],; ALICE MARWICK & REBECCA LEWIS, DATA & Soc’y,
MEDIA MANIPULATION AND DISINFORMATION ONLINE 44,
https: //datasociety.net/pubs/oh/DataAndSocietyMediaManipulationAndDisinformationOnline
.pdf [https://perma.cc/6M9 Y-FLCN].

4. See, e.g, Mark Isaac & Scott Shane, Facebook’s Russia-Linked Ads Came in Many
Disguises, NY. TIMES (Oct. 2, 2017),
https://www.nytimes.com/2017/10/02/technology/facebook-russia-ads-.html
[https://perma.cc/ZH2B-BY6E].

5. See, e.g., Clive Thompson, Social Networks Must Face Up to Their Political Impact,
WIRED (Jan, 5, 2017, 6:01 PM), https://www.wired.com/2017/01/social-networks-must-face-
political-impact/ [https://perma.cc/2WZ7-4GEJ], Alex Kantrowitz, How The 2016 Election
Blew Up in’ Facebook’s Face, BuzzFEED (Nov. 21, 2016, 11:15 AM),
https: //www.buzzfeed.com/alexkantrowitz/2016-election-blew-up-in-facebooks-face
[https://perma.cc/9JKJ-5DCAJ, El-Bermawy, supra note 1; Nathaniel Persily, Can Democracy
Survive the Internet, 28 J. DEMOCRACY 63.
58 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

In 2013, the World Economic Forum presciently highlighted “massive
digital misinformation” as a leading global risk in its annual global risk
assessment. © In 2016, renowned fact-checking organization PolitiFact
declared “fake news” its Lie of the Year.’ Nonetheless, at least in the U.S.,
issues of misinformation in the digital sphere have only very recently found
their way onto the communications policy agenda.*

This somewhat sluggish response can be explained, at least in part, by
a First Amendment tradition that has valorized the notion of “counterspeech.”
A central tenet of the First Amendment is that more speech is an effective
remedy against the dissemination and consumption of false speech.*? The
counterspeech doctrine is a perspective that was first explicitly articulated by
Justice Louis Brandeis in Whitney v. California. '° Since then, the
effectiveness of counterspeech has become an integral component of most
conceptualizations of an effectively functioning “marketplace of ideas,” in
which direct government regulation of speech is minimized in favor of an
open and competitive speech environment."!

This Article seeks to unpack the set of assumptions about the dynamics
of the production, dissemination, and consumption of news that are embedded
in the counterspeech doctrine. This Article then questions whether these

 

6. See WORLD ECONOMIC FORUM, GLOBAL RISKS 2013: EIGHTH EDITION 23 (2013),
http://www3.weforum.org/docs/WEF GlobalRisks Report_2013.pdf
[https://perma.cc/9GKG-UCW3].

7. See generally Angie Drobnic Holan, 2016 Lie of the Year: Fake News, POLITIFACT
(Dec. 13, 2016), http:/*www.politifact.com/truth-o-meter/article/2016/dec/13/2016-lie-year-
fake-news/ [https://perma.cc/8X2N-SHJ9].

8. See, e.g., Extremist Content and Russian Disinformation Online: Working with Tech
to Find Solutions, Hearing Before the S. Comm. on the Judiciary, Subcomm. on Crime and
Terrorism, 115" Cong. (Oct. 31, 2017), https://www judiciary.senate.gov/meetings/extremist-
content-and-russian-disinformation-online-working-with-tech-to-find-solutions
[https://perma.cc/42VE-5HSD]; Social Media Influence in the 2016 United States Elections,
Hearing Before the 8S. Select Comm on Intelligence (Nov. 1, 2017),
https: //www intelligence.senate.gov/hearings/open-hearing-social-media-influence-2016-us-
elections [https://perma.cc/K65 Y-KAQ4], Russia Investigative Task Force Open Hearing with
Social Media Companies, Hearing before the H. Permanent Select Comm. on Intelligence
(Nov. 1, 2017), _ https://intelligence house .gov/calendar/eventsingle.aspx?EventI D=814
[https://perma.cc/8DYT-QRJU].

9. See Robert D. Richards & Clay Calvert, Counterspeech 2000: A New Look at the Old
Remedy for "Bad" Speech, 2000 B.Y.U.L. Rev. 553, 553-554 (2000) (“Rather than censor
allegedly harmful speech and thereby risk violating the First Amendment’s protection of
expression, or file a lawsuit that threatens to punish speech perceived as harmful, the preferred
remedy is to add more speech to the metaphorical marketplace of ideas’).

10. Whitney v. California, 274 U.S. 357, 377 (1927) (Brandeis, J., concurring).

11. See Abrams v. United States, 250 U.S. 616, 630 (1919) (Holmes, J., dissenting).
(“[T]he ultimate good desired is better reached by free trade in ideas — that the best test of truth
is the power of the thought to get itself accepted in the competition of the market, and that truth
is the only ground upon which their wishes safely can be carried out. That, at any rate, is the
theory of our Constitution.”); see also Alvin I. Goldman & James C. Cox, Speech, Truth, and
the Free Market for Ideas, 2 LEGAL THEORY 1, 3 (1996); Ronald Coase, The Market for Goods
and the Market for Ideas, 63 AM. ECON. REV. 384, 384 (1974) (“[I]n the market for goods,
government regulation is desirable whereas, in the market for ideas, government regulation is
undesirable and should be strictly limited.”).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 59

assumptions remain viable in the face of the evolving structure and operation
of the contemporary media ecosystem: and if not, what this means for
contemporary media law and policy. Specifically, this Article argues that
conditions, such as the structural and economic changes that have affected the
news media, increased fragmentation and personalization, and increasingly
algorithmically-dictated content dissemination and consumption, affect the
production and flow of news in ways that may make it more difficult than it
has been in the past to assume that legitimate news will systematically win
out over false news. Thus, just as it has been asked whether the assumptions
underlying the Second Amendment right to bear arms (written in the era of
muskets and flintlocks) are transferrable to today’s technological
environment of high-powered, automatic assault weapons,'? it may be time to
ask whether this fundamental aspect of First Amendment theory, crafted in an
era when news circulated primarily via interpersonal contact and print media,
and in which electronic media were just beginning to develop, is effectively
transferrable to today’s radically different media environment.

In addressing this issue, Part I will review the counterspeech doctrine,
its underlying assumptions, the ways that it has been put into practice in legal
and policy decision-making, and the critiques that have been leveled against
it. As Part 1 will illustrate, the focal points of these critiques have been the
psychological and behavioral barriers to counterspeech, as well as the
resistance of certain types of speech to the effectiveness of counterspeech.
Missing from the counterspeech dialogue, however, has been a substantive
consideration of whether the evolution of the media ecosystem has progressed
in ways that might affect the validity of the doctrine.

Part II then will provide an overview of the profound technological
changes that have affected the media ecosystem and media users over the past
two decades. While most of these changes are widely recognized, this section
will argue that each of these developments bears directly on the integrity of
the counterspeech doctrine. Specifically, this part will illustrate that
technological changes have: 1) affected the relative prominence of the
production of true versus false news; 2) diminished the gatekeeping barriers
that have traditionally curtailed the production and dissemination of false
news; 3) increased the ability of those producing false news to target those
most likely to be receptive to/affected by the false news; 4) diminished news
consumers’ likelihood of being exposed to accurate news that counteracts
false news; 5) diminished news consumers’ ability to distinguish between true
and false news; and 6) enhanced the speed at which false news can travel.

 

12. See, e.g., Christopher Ingraham, What ‘Arms’ Looked Like When the 2nd Amendment
Was Written, WASH. Post (June 13, 2016),
https://www. washingtonpost.com/news/wonk/wp/2016/06/13/the-men-who-wrote-the-2nd-
amendment-would-never-recognize-an-ar-15/?utm_term=.86da76908f41
[https://perma.cc/KA8E-WV53] (“Of course, semiautomatic firearms technology didn't exist
in any meaningful sense in the era of the founding fathers. They had something much different
in mind when they drafted the Second Amendment. The typical firearms of the day were
muskets and flintlock pistols. They could hold a single round at a time, and a skilled shooter
could hope to get off three or possibly four rounds in a minute of firing. By all accounts they
were not particularly accurate either.”).
60 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

Each of these six conditions contributes to undermining the extent to which
counterspeech can effectively operate as a fundamental assumption of First
Amendment theory.

Finally, Part II will consider the broader political, legal, and policy
implications of this argument. In particular, this part will consider what the
diminished efficacy of counterspeech might mean for the understanding of
the marketplace of ideas metaphor and the potential for failure in the
marketplace of ideas. The results of the 2016 presidential election will be used
to examine possible causes and indicators of such market failure. This part
will conclude with a consideration of the legal and policy implications of a
media ecosystem in which the counterspeech doctrine has been undermined
due to technological change.

II. COUNTERSPEECH AND THE FIRST AMENDMENT:
ASSUMPTIONS, APPLICATIONS, AND CRITIQUES

The counterspeech doctrine was first formally articulated by Justice
Louis Brandeis in Whitney v. California.? According to Brandeis, “[i]f there
be time to expose through discussion the falsehood and fallacies, to avert the
evil by the processes of education, the remedy to be applied is more speech,
not enforced silence.””"4 This perspective is in many ways a natural outgrowth
of the well-known “marketplace of ideas metaphor”,!> which has served as a
fundamental principle in communications law and policy,'® but has been
subject to substantial critique in its own right.'7 As Justice Holmes’ famous
articulation of the marketplace of ideas metaphor asserts, “the ultimate good
desired is better reached by free trade in ideas — that the best test of truth is
the power of the thought to get itself accepted in the competition of the
market.”!®§ Under this formulation, the ideas marketplace is inherently capable
of distinguishing between truth and falsity and can be counted on to accept
and act upon true information and reject false information. This process is, in
turn, fundamental to the well-functioning democracy that, according to many
interpretations, the First Amendment is intended to protect.!? Today, Holmes’

 

13. See 274 U.S. 357, 377 (1927) (Brandeis, J., concurring).

14. Id

15. See Daniel E. Ho & Frederick Schauer, Testing the Marketplace of Ideas, 90 N.Y.U.
L. REV. 1160, 1167 (2015) (observing that Brandeis’ opinion in Whitney v. California
represents a “‘canonical formulation’ of the marketplace of ideas metaphor’).

16. See generally PHILIP M. NAPOLI, FOUNDATIONS OF COMMUNICATIONS Po.Licy (2001).

17. See, e.g, Darren Bush, “The Marketplace of Ideas.” Is Judge Posner Chasing Don
Quixote’s Windmills’, 32 Ariz. ST. L.J. 1107, 1146 (2000) (arguing that, in realms such as
speech, “the market metaphor becomes increasingly less applicable or useful”), Ho & Schauer,
supra note 15; Stanley Ingber, The Marketplace of Ideas: A Legitimizing Myth, 1984 DUKE L.J.
1 (1984).

18. Abrams v. United States, 250 U.S. 616, 630 (1919) (Holmes, J., dissenting).

19. See generally ALEXANDER MEIKLEJOHN, POLITICAL FREEDOM: THE CONSTITUTIONAL
POWERS OF THE PEOPLE (1960), See also CASS SUNSTEIN, DEMOCRACY AND THE PROBLEM OF
FREE SPEECH (1995).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 61

statement is echoed within more contemporary notions of the “wisdom of
crowds”? or “the wealth of networks.””!

Counterspeech is an outgrowth of this marketplace of ideas framework.
Given the metaphor’s assumption that the marketplace is capable of
effectively distinguishing between truth and falsity, ** then a speech
environment that facilitates as much speech as possible is a potentially
effective way of assuring that truth prevails over falsity, and that the good
ideas prevail over the bad ones. “More speech” (1.e., counterspeech) thus
becomes an effective and First Amendment-compliant approach to assuring
that individuals have the information they need to be informed and effective
participants in the democratic process.

There are a number of fundamental assumptions that underlie this
perspective. First, there is the assumption that individuals are capable of
discerning between true and false information.”* The logic here is that, just as
participants in the traditional product market are capable of distinguishing
between high and low value products, participants in the idea market are
similarly capable of distinguishing between true and false news and
information. A second, related, assumption is that participants in the idea
marketplace place greater value on true news and information than they do on
false information.”* This assumption strikes at the core of what it is the
marketplace actually values. A third assumption 1s that, as late U.S. Supreme
Court Justice Antonin Scalia has stated, “[g]iven the premises of democracy,
there is no such thing as too much speech.”** A fourth assumption that
underlies the counterspeech doctrine is that a sufficient number of those
exposed to false information also will be exposed to the countervailing true
information.*° Of course, if the previous assumptions hold true, then this
exposure to true and accurate information will have its desired effect in terms

 

20. See generally JAMES SUROWIECKI, THE WISDOM OF CROWDS XII (2004) (arguing that
“under the nght circumstances, groups are remarkably intelligent, and are often smarter than
the smartest people in them’).

21. YocHAl BENKLER, THE WEALTH OF NETWORKS: How SocIAL PRODUCTION
TRANSFORMS MARKETS AND FREEDOM 4 (2006) (illustrating “the nse of effective, large-scale
cooperative efforts — peer production of information, knowledge, and culture”).

22. See Abrams v. United States, 250 U.S. 616, 630 (1919) (Holmes, J., dissenting)
(“[T]he best test of truth is the power of the thought to get itself accepted in the competition of
the market”).

23. See, eg., Lyrissa Barnett Lidsky, Nobody's Fools: The Rational Audience as First
Amendment Ideal, 2010 U. ILL. L. REv. 799, 801 (discussing the “rational audience”
assumption in First Amendment jurisprudence: “The first of these assumptions is that
audiences are capable of rationally assessing the truth, quality, and credibility of core speech’).

24. See Goldman & Cox, supra note 11, at 18 “Thus, if consumers have no very strong
preference for truth as compared with other goods or dimensions of goods, then there is no
reason to expect that the bundle of intellectual goods provided and "traded" in a competitive
market will have maximum truth content. If people valued falsehood, then perfect competition
would provide falsehood in a Pareto-optimal way.”).

25. See McConnell v. FEC, 540 US. 93, 258-59 (2003) (Scalia, J., concurring in part
and dissenting in part).

26. See, e.g., Vincent Blasi, Reading Holmes through the Lens of Schauer: The Abrams
Dissent, 72 NOTRE DAME L. REV. 1343, 1357 (1997), see also Richards and Calvert, supra note
9, at 554-55.
62 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

of contributing to an informed citizenry. Each of these are contentious
assumptions in their own right.*? However, as will be discussed below,
economic and technological changes in the media ecosystem have led to
conditions that further challenge many of these assumptions.

A. The Counterspeech Doctrine in Practice

Applications of the counterspeech doctrine have been wide ranging in
media law and policy, as well as in industry practice.** Below, are a few
applications that have particular relevance to the focus on the structure and
operation of the contemporary media ecosystem and its relationship to a well-
functioning democracy.

The well-known (some might say notorious) Fairness Doctrine is a
useful case study of a rare instance in which the counterspeech doctrine has
been utilized to justify government regulation.*? The Fairness Doctrine
required broadcast licensees to devote news coverage to controversial issues
of public importance.* In providing such coverage, broadcasters were further
required to devote time to competing perspectives on an issue.*! So, for
instance, if a news broadcast ran a story on new research asserting a link
between cigarette smoking and cancer, the tobacco industry was entitled to
demand that time be devoted to the perspective that the causal link between
cigarette smoking and cancer had yet to be determined. And, importantly, this
competing perspective needed to be broadcast during a day/time when a
comparable number of viewers who viewed the initial broadcast could be
reached.

To the extent that the Fairness Doctrine essentially compelled
additional, most likely contradictory, speech, it embodies the counterspeech
doctrine and its commitment to “more speech.” The irony is that the Fairness
Doctrine was eliminated in the late 1980s under the logic that the requirement
to provide counterspeech “chilled” broadcaster coverage of controversial
issues overall,” essentially resulting in less speech rather than more speech.

 

27. See generally DARREN BUSH, supra note 17; Ho & SCHAUER, supra note 15, STANLEY
INGBER, supra note 17.

28. See RICHARDS AND CALVERT, supra note 9, at 553-585.

29. For a more detailed discussion of the Faimess Doctrine and its relationship to
counterspeech, see Adam Welle , Campaign Counterspeech: A New Strategy to Control Sham
Issue Advocacy in the Wake of FEC v. Wisconsin Right to Life, 2008 Wis. L. REV. 795, 823-
825. (2008).

30. KATHLEEN ANNE RUANE, FAIRNESS DOCTRINE: HISTORY AND CONSTITUTIONAL
IssUES 2 (2011) (noting that the Fairness Doctrine “affirmatively established the duty of
broadcast licensees to cover controversial issues of public importance in a fair and balanced
manner”); See generally Report on Editorializing by Broadcast Licensees, 13 F.C.C. 1246
(1949).

31. RUANE, supra note 30, at 2 (“Broadcasters .. . had the affirmative duty to determine
what the appropriate opposing viewpoints were on these controversial issues, and who was best
suited to present them.”).

32. See RUANE, supra note 31 at 6 (“The Commission examined the effect of its
enforcement of the Fairness Doctrine upon broadcasters and came to the conclusion that the
doctrine chilled speech substantially’).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 63

In the case of the Fairness Doctrine, counterspeech was used to justify
speech regulation. More often, it has been used to reject speech regulation.
For instance, in the realm of political campaign advertising there has been a
history of efforts to impose restrictions on the dissemination of false
information.** A useful example involves efforts in the state of Washington
to impose a regulation that allowed a state agency to determine the veracity
of campaign statements, and to fine campaigns found to disseminate false
statements.*4 These regulations were overturned by the Washington State
Supreme Court for a host of reasons,*° including a rejection of the State’s
contention that protecting the integrity of elections represented a sufficiently
compelling government interest. 3° According to the court, prohibiting
“arguably false, but nondefamatory, statements about political candidates to
save our elections conflicts with fundamental principles of the First
Amendment.”?’ Moreover, the court explicitly argued that counterspeech
represented the more appropriate mechanism for coping with falsity in
political campaign communications. ** According to the court, “[oJur
constitutional election system already contains the solution to the problem
that RCW 42.17.530(1)(a) is meant to address.”*? Quoting Brown v. Hartlage,
the court noted that ““[iJn a political campaign, a candidate's factual blunder
is unlikely to escape the notice of, and correction by, the erring candidate's
political opponent. *° The preferred First Amendment remedy of ‘more
speech, not enforced silence,’ thus has special force.’”*! Thus, the court
concluded, “[i]n other words, the best remedy for false or unpleasant speech
is more speech, not less speech.”

What is particularly important about both of these examples is the
extent to which they reflect how the First Amendment will facilitate the
dissemination of false news and information. However, the importance of the
circulation of diverse ideas and viewpoints is so important that such falsity
must be tolerated. This tolerance is accompanied by the confidence that a
robust speech environment will allow truthful and accurate news and
information to triumph over falsity. This position is well-reflected in the
Supreme Court’s statement in Gertz v. Robert Welch, Inc., that the First

 

33. See Rickert v. State Pub. Disclosure Comm’n, 168 P.3d 826, 827 n. 2-3 (Wash.
2007).

34. Id

35. Reasons included the court’s rejection of the notion that “the State possesses an
independent nght to determine truth and falsity in political debate,” id at 827, as well as the
fact that the statute did not require proof of the defamatory nature of the speech, id at 828-829.

36. Jd. at 830-831.

37. Id at 831.
38. Jd. at 832.
39. Id

40. Brown v. Hartlage, 456 U.S. 45, 61 (1982) (quoting Whitney v. California, 274 U.S.
357, 377 (1927) (Brandeis, J., concurring).

41. See Rickert 168 P.3d at 855.

42. Id at 855-56.
64 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

Amendment requires protecting “some falsehood in order to protect speech
that matters.”

Compared to less-protected categories of speech, such as commercial
speech, the First Amendment protections for political false speech — and thus
the reliance upon counterspeech — are at their most pronounced.** News
organizations represent the most explicitly protected category of speakers (as
reflected in the “of the press” clause).** For news organizations, since New
York Times Co. v. Sullivan,” legal liability for falsity has been largely limited
to intentional and malicious falsities directed at individuals or organizations
that are damaging to the individual’s or organization’s reputation.*’ This
focus is a reflection of the Supreme Court’s position that “false statements of
fact [can] cause damage to an individual’s reputation that cannot easily be
repaired by counterspeech, however persuasive or effective.”*® No such
liabilities exist for the production and dissemination of journalistic falsities
for the remaining political issues and concerns around which falsities could
be generated, whether it be older examples, such as AIDS conspiracy theories
or Holocaust denial,” or more recent examples, such as the nature of the
scientific evidence surrounding climate change, given the broad protections
given to the press and its role in maintaining “uninhibited, robust, and wide
open” political discussion.

Sunilarly, the journalistic presentation of falsities about individuals or
organizations that are beneficial rather than harmful are fully protected. So
while a news outlet accusing a political figure of running a child sex ring out
of a Washington, DC, pizza parlor could be vulnerable to a libel lawsuit, a
news outlet that knowingly reports inflated figures for a candidate’s net worth
or charitable donations (thereby enhancing the candidate’s status with voters)
is in the clear, even if it is subsequently proven that this information was
published with knowledge of its falsity, since in no way was the candidate’s
stature or reputation damaged by the false information.

The bottom line is that “any test of truth” when applying the First
Amendment to the work of journalists has been rejected.*! According to the
Supreme Court in New York Times Co. v. Sullivan, “[ijnjury to official
reputation error affords no more warrant for repressing speech that would

 

43. See 418 US. 323, 340-41 (1973).

44, See Frederick Schauer, Facts and the First Amendment, 57 UCLA L. REV. 897, 912-
914 (2009-2010).

45. See Potter Stewart, “Or of the Press”, 26 HASTINGS L.J. 631 (1974-1975).

46. See 376 US. 254 (1964).

47. See generally ANTHONY LEWIS, MAKE No LAw: THE SULLIVAN CASE AND THE FIRST
AMENDMENT (1991).

48. See Hustler Magazine, Inc. v. Falwell, 485 U.S. 46, 52 (1988).

49. See Schauer, supra note 46 at 897. For a discussion of the First Amendment
protections for Holocaust deniers, see generally Jonathan D. Varatt, Deception and the First
Amendment: A Central, Complex, and Somewhat Curious Relationship, 33 UCLA L. REv.
1107, n. 27-29 and accompanying text.

50. SeeN.Y. Times Co. v. Sullivan, 376 US. 254, 270 (1964).

51. Jd at271.
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 65

otherwise be free than does factual error..”°? From this standpoint, we can
assume that the prevailing First Amendment position on fake news is the
production, dissemination, and consumption of more news.

Finally, it is important to note that counterspeech has become tightly
integrated into the operation of the social media platforms and content
aggregators that have become the eye of the storm for escalating concerns
about the impact of false news on democratic decision-making. Facebook, for
example, has commissioned a series of studies that highlights the prominence
of counterspeech within the context of a variety of controversial issues across
different countries.*’ In addition, in 2016, the company launched the Online
Civil Courage Initiative, which states its mission as to “[t]o promote the civil
courage displayed by organizations and grassroots activists carrying out
valuable counterspeech work online.” “4 Facebook’s commitment to
counterspeech is reflected in its description of the Online Civil Courage
Initiative: “We believe that engagement is more powerful than censorship in
reforming prejudiced and bigoted opinions and voices, and are committed to
amplifying campaigns which encourage positive dialogue and debate.” In
this statement, Facebook seems to suggest that the platform will work to
enhance (i.e. “amplifying”) counterspeech to address prejudiced and bigoted
opinions and voices.

Along similar lies, Twitter has organized online convenings to
facilitate discussions about strategies for producing and disseminating
counterspeech through social media.*° Google, in its 2017 testimony before
the Senate Subcommittee on Crime and Terrorism about its initiatives to
combat extremist content and disinformation on its platforms, highlighted that

 

52. Id at 272.

53. See JAMIE BARTLETT & ALEX KRASODOMSKI-JONES, DEMOS, COUNTER-SPEECH ON
FACEBOOK (2016), https:/(www.demos.co.uk/wp-content/uploads/2016/09/Counter-speech-
on-facebook-report.pdf  [https://perma.cc/YPW5-WPHN], JAMIE BARTLETT & ALEX
KRASODOMSKI-JONES, DEMOS, COUNTER-SPEECH EXAMINING CONTENT THAT CHALLENGES
EXTREMISM ONLINE (2015), https://www.demos.co.uk/wp-content/uploads/2015/10/Counter-
speech. pdf [https://perma.cc/B YM6-MVW/7]. It is worth noting that while these studies seek
to document the prevalence of counterspeech on Facebook, they do not seek to determine its
effectiveness.

54. See ONLINE CIVIL COURAGE INITIATIVE, FACEBOOK,
https: //www.facebook.com/pg/OnlineCivilCourage/about/  [https://perma.cc/SW32-SF6X  ]
(ast visited June 9, 2017).

55. Id.

56. See, e.g., @TweeSurfing, Counter Speech On Social Media: The New Age Activism,
TWITTER, (Dec. 2, 2016), https://perma.ce/TYE7-XK9L. See also Colin Crowell, Our Approach
to Bots and Misinformation, TWITTER BLoG (June 14, 2017), https://perma.cc/68UA-DSES
(“Twitter’s open and real-time nature is a powerful antidote to the spreading of all types of
false information. This is important because we cannot distinguish whether every single Tweet
from every person is truthful or not. We, as a company, should not be the arbiter of truth.
Journalists, experts and engaged citizens Tweet side-by-side correcting and challenging public
discourse in seconds. These vital interactions happen on Twitter every day... .” [emphasis in
original]).
66 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

it is “creating new programs to promote counterspeech on [its] platforms.’*”
These programs include efforts to redirect consumers of extremist propaganda
toward content that counters those narratives, as well as efforts to encourage
YouTube content creators to speak out against hate speech, xenophobia, and
extremism.”®

B. Critiques of Counterspeech

To some extent, critiques that have been directed at counterspeech
overlap with those directed at the overarching marketplace of ideas metaphor
within which the counterspeech doctrine is embedded. This is particularly the
case for those critiques that emphasize fundamental human characteristics and
tendencies that could lead to the embracing of false news and information
over true news and information. In light of the concerns that have arisen in
the wake of the 2016 U.S. presidential election about the potential influence
of fake news,’ there appears to be a renewed interest in the vast literatures
across fields, such as communication, cognitive psychology, and behavioral
economics, that highlight fundamental human tendencies that can lead to the
acceptance of false information over accurate information.” This literature
illustrates how established behavioral patterns, such as selective exposure,
confirmation bias, heuristics for coping with information overload, and
directionally motivated reasoning explain how false news can be favored over
legitimate news.*!

 

57. See Extremist Content and Russian Disinformation Online: Working with Tech to
Find Solutions: Hearing Before the Subcomm. on Crime and Terrorism of the S. Comm. the
Judiciary, 115" Cong. (2017) (Statement of Richard Salgado, Director, Law Enforcement and
Information Security, Google).

58. Id.

59. See Weedon et al., supra note 3.

60. See, e.g., CASS SUNSTEIN, #REPUBLIC 71-97 (2017), Elizabeth Kolbert, Why Facts
Don’t Change Our Minds, THE NEW YORKER (FEB. 27, 2017), https://perma.cc/M354-3U YN,
Parmy Olson, Why Your Brain May Be Wired to Believe Fake News, FORBES (FEB. 1, 2017,
5:35PM), https://perma.cc/UN3J-DFAC. It is beyond the scope of this paper to review these
bodies of literature. For helpful reviews, see Derek E. Bambauer, Shopping Badly: Cognitive
Biases, Communications, and the Fallacy of the Marketplace of Ideas, 77 U. COL. L. REV. 649
(2006), Goldman & Cox, supra note 11; Ho & Schauer, supra note 15.

61. See, eg. R. Kelly Garrett & Natalie Jomini Stroud, Partisan Paths to Exposure
Diversity. Differences in Pro- and Counterattitudinal News Consumption, 64 J. COMM. 680,
693-94 (2014), Michael A. Beam, Automating the News: How Personalized News
Recommender System Design Choices Impact News Reception, 41 COMM. RES. 1019, 1020-36
(2014), D.J. Flynn, Brendan Nyhan & Jason Reifler, The Nature and Origins of
Misperceptions: Understanding False and Unsupported Beliefs About Politics, 38 ADVANCES
POL. PSYCHOL. 127,128-32 (2017). For a more detailed discussion of the range of cognitive
biases that can come into play see Bambauer, supra note 60 at 673-96. See also Alessandro
Bessi et. al., Homophily and Polarization in the Age of Misinformation, 225 Eur. PHys. J.
SPECIAL Topics 2047 (2016) (discussing research showing a correlation between polarized
social networks and participation in the consumption and spread of false news and
information).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 67

These are long-standing behavioral and psychological patterns.” As
Frederick Schauer has noted, “[t]hat people believe things that are false comes
as no surprise. That a large number of people believe things that are false
despite being told the truth is also hardly a revelation.”* The bottom line is
that the notion of the “rational audience,” capable of processing speech from
diverse sources, and capable of effectively and rationally assessing the truth,
quality, and credibility, is much more an ideal-type in First Amendment
theory than an empirical reality.** What may be different today, however is
the extent to which the U.S. media system is capable of counteracting these
fundamental human tendencies. Instead, it may be exacerbating them.”

Other critiques have explored specific speech contexts, where it has
been argued that the counterspeech doctrine is particularly ineffective. It has
frequently been noted that the efficacy of counterspeech can depend upon a
wide range of circumstances related to the character of the speech at issue.
Hate speech, for mstance, has been singled out as being particularly resistant
to the effects of counterspeech.® Hate speech may have a silencing effect on
would-be speakers, inhibiting their ability to engage in counterspeech or it
may impose unfair or dangerous burdens on those who engage in
counterspeech.® Further, marginalized groups that often are the targets of
hate speech may lack the access and resources to effectively reach all of those
exposed to the initial speech.

The counterspeech doctrine is a pillar of First Amendment theory that
rests on an intellectual foundation that 1s somewhat shaky, at best. The
critiques of counterspeech have focused on either the aspects of human
psychology that work against counterspeech being consumed and/or having
its intended effects, or on those types of speech that the mechanisms of
counterspeech are less likely to affect.”

Largely absent from these critiques of the counterspeech doctrine are
detailed considerations of how technological and structural changes in the
media and information environment may impact the extent to which we can

 

62. See, e.g., Schauer, supra note 44, at 899.

63. See Schauer, supra note 44, at 898.

64. See generally Lidsky, supra note 23.

65. See infra notes 76-180 and accompanying text.

66. See, e.g., Blasi, supra note 26, at 1357, see also Richards and Calvert, supra note 9,

67. See Richard Delgado & David Yun, “The Speech We Hate”: First Amendment
Totalism, the ACLU, and the Principle of Dialogic Politics, 27 ARIZ. ST.L.J. 1281, 1292 (1995).

68. See, e.g., OWEN M. FIss, THE IRONY OF FREE SPEECH 25-6 (1996).

69. See Mari J. Matsuda, Public Response to Racist Speech: Considering the Victim’s
Story, in MARIJ. MATSUDA ET AL, WORDS THAT WOUND: CRITICAL RACE THEORY, ASSAULTIVE
SPEECH, AND THE FIRST AMENDMENT 17, 48 (1993) (arguing that minority groups have
“diminished access to private remedies such as effective counterspeech’”).

70. See Schauer, supra note 46, at 912-914, see generally Man J. Matsuda, Public
Response to Racist Speech: Considering the Victim’s Story, in WORDS THAT WOUND: CRITICAL
RACE THEORY, ASSAULTIVE SPEECH, AND THE FIRST AMENDMENT 17, 48 (1993).
68 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

expect factual speech to overcome false speech.7! How might these
technological changes affect the integrity of the counterspeech doctrine? This
question is the focus of the next section, which argues that the media
ecosystem has evolved in ways that undermine the likelihood (however slim
it already may have been)” that true and high-quality news and information
will overcome false and low-quality news information. In this regard, the
arguments presented here can be layered upon the established critiques
discussed above, thereby further calling into question the validity of the
notion of more speech serving as an effective antidote to false speech.

II. How TECHNOLOGICAL CHANGES UNDERMINE THE
COUNTERSPEECH DOCTRINE

The goal of this section is to consider the range of changes affecting the
contemporary media ecosystem through the lens of counterspeech, with a
particular focus on contemporary concerns about the prominence of fake news
and the operation of filter bubbles. That is, how do these changes potentially
affect the production, distribution, and consumption of legitimate versus false
news and information?

A. The Relative Prominence of True Versus False News”

In considering the changes that have affected the media ecosystem over
the past two decades, it makes sense to begin with the changing dynamics of
news production. The technological and economic changes that have
transformed the media ecosystems have had a number of intersecting effects
that have, on the one hand, undermined the production of legitimate news,
while at the same time enhanced the production of false news.

 

71. For instance, see Schauer ’s supra note 46 at 899, wherein Schauer recognizes t the
apparent “increasing and unfortunate acceptance of factual falsity in public communication”,
but doesn’t explore how the evolution of the media sector might be contributing to this increase.

72. See supra, notes 62-72 and accompanying text.

73. It should be noted that this analysis starts from the premise that it 1s possible to make
valid distinctions between “legitimate” and “fake” news. Certainly, as with all dimensions of
speech classification (e.g., commercial vs. non-commercial speech, libelous vs. non-libelous
speech), there will be areas of ambiguity and disagreement, but such ambiguity and
disagreement does not invalidate the viability, legitimacy or importance of maintaining the
distinction. See James Weinstein, Speech Characterization and the Limits of First Amendment
Formalism: Lessons from Nike v. Kasky, 54 CASE WESTERN RESERVE L. REV. 1091, 1093
(2004) (“In a typical free speech case, ... use of verbal formulae or case matching to determine
the category in which to place the speech in question works well enough. There is often
precedent so factually similar that it really is controlling; or even in the absence of such truly
controlling precedent, categorizing the speech in question one way rather than the other so
clearly promotes the values underlying free speech doctrine that a judge can intuitively make
the nght choice”). Not surprisingly, efforts to clarify the concept of fake news or to develop
more precise terminology, are ongoing; see, e.g., Claire Wardle & Hossein Derakhshan,
INFORMATION DISORDER 4 (2017) (developing the concept of “information pollution” as an
alternative to “fake news’).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 69

In terms of the production of legitimate news, the ongoing economic
crisis in journalism has been well documented.” Key consequences of this
crisis include: declines in the number of newspapers across the country, in the
size of television newsrooms, and in the number of professional journalism
positions.”* The rise of various online news outlets, and the new opportunities
technological change fostered for “citizen journalism,” have been interpreted
by some as adequate countervailing forces in the wake of declines in
traditional journalism; however, the reality is that these developments have
not been able to fully replace the declines in news workers or news reporting
that have resulted from the declines affecting traditional media.’ The
troubling paradox here is that increases in the number of media outlets and
channels have led to decreases in the production of genuime journalism.

While it is difficult to reconcile this position with the apparent
abundance of online news, it is more understandable if we consider a seldom
discussed, and insufficiently researched, phenomenon in the realm of digital
journalism: what is perhaps best described as parasitic journalism.”’ Parasitic
journalism refers to news stories that have as their origins and foundation
reporting produced by another media outlet.” If one examines news stories
produced by digital media outlets through this analytic lens, the proportion of
the online news reporting that merits classification as original journalism
declines dramatically. Indeed, this kind of parasitic journalism (or “vampire
web pages,” as they are sometimes called) has emerged as a thriving business
model, due in large part to the extent to which social media platforms facilitate

 

74. See, eg. Leonard Downie, Jr., & Michael Schudson, The Reconstruction of
American Journalism, COLUM. J. REV. 1 (Nov/Dec. 2009),
http://archives.cjr.org/reconstruction/the_reconstruction_of_american.php
[https://perma.cc/83MQJ-GQB8] (“As almost everyone knows, the economic foundation of the
nation’s newspapers, long supported by advertising, is collapsing, and newspapers themselves,
which have been the country’s chief source of independent reporting, are shrinking—literally.
Fewer journalists are reporting less news in fewer pages, and the hegemony that near-monopoly
metropolitan newspapers enjoyed during the last third of the twentieth century, even as their
primary audience eroded, is ending. Commercial television news, which was long the chief
rival of printed newspapers, has also been losing its audience, its advertising revenue, and its
reporting resources”),, C.W. Anderson et al., Post-Industrial Journalism: Adapting to the
Present 2 (Colum. J. School / Tow Ctr. for Digital Journalism Rep.) http://towcenter.org/wp-
content/uploads/2012/11/TOWCenter-Post_Industrial_ Journalism.pdf
[https://perma.cc/U V9D-HPS8]. (“The effect of the current changes in the news ecosystem has
already been a reduction in the quality of news in the United States”).

75. See BUR. LAB. STAT., NEWSPAPER PUBLISHERS LOSE OVER HALF THEIR EMPLOYMENT
FROM JANUARY 2001 TO SEPTEMBER 2016 (Apr. 3, 2017),
https://www.bls.gov/opub/ted/2017/mobile/newspaper-publishers-lose-over-hal f-their-
employment-from-january-200 | -to-september-2016.htm, https://perma.cce/A4VT-22NH.

76. See PEw RES. CTR, STATE OF THE NEWS MEDIA 2016 (June, 2016),
http://www.journalism.org/2016/06/15/state-of-the-news-media-2016/,,
[https://perma.cc/2_LAM-E72U].

77. See generally The Future of Newspapers, THE INDEP. (Nov. 13, 2006),
http://www.independent.co.uk/news/media/the-future-of-newspapers-5331270.html
[https://perma.cc/8C WU-LK WM].

78. Id. (“Although there's an enormous amount of online news-related material, if you
analyse it, very, very little is actually new fact, new information - it's almost all parasitic
journalism carried out either by broadcasters or newspapers.”).
70 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

the ability to identify popular news stories, and then recycle and recirculate
nearly identical versions of those stories that demonstrably drain the audience
(and thus, revenue) away from the outlets that produced the original story.”

Ultimately, the apparent multitude of online news outlets masks a
journalistic ecosystem in which original reporting is recycled and circulated
by scores of under-resourced news outlets incapable in engaging in original
reporting.*° In many ways, this may be the true online echo chamber — the
process by which the same reporting reverberates through outlet after outlet,
often reconfigured and re-summarized in ways that sometimes seek to
disguise the story’s true origins and that provide opportunities for original
commentary — but not original reporting. The end result is that the bulk of the
news produced continues to originate from a relatively small number of media
outlets, each of whose economic capacity to produce news is in a continued
state of decline.*!

The bottom line is that original reporting is costly to produce and, given
the degrading economics of journalism, this production is in decline. Fake
news, on the other hand, is far less costly to produce.** Fabricated news stories
do not require the same rigorous research, verification processes, or tramed
professionals to produce. This is why fake news has a fairly extensive history
— one that certainly predates the Internet and social media*’ — with changes in
communications technologies consistently affecting the dynamics of how
fake news is produced, disseminated, and consumed.** Today, fake news can
be easily and effectively produced (and monetized) by a “Macedonian”
teenager in his bedroom.* From this standpoint, the evolution of the media
ecosystem has done nothing to make the production of false news and

 

79. See Steven Rosenfeld & Ivy Olesen, Vampire Webpages Suck Content from
Legitimate Progressive News Sites, ALTERNET (Mar. 6, 2017),
http://www.alternet.org/media/vampire-webpages-suck-content-legitimate-progressive-news-
sites [https://perma.cc/Y6BX-WF3N].

80. Even producers of fake news engage in rampant cannibalization of other fake news
producers. See Craig Silverman & Lawrence Alexander, How Teens in The Balkans Are
Duping Trump Supporters with Fake News, BUZZFEED.COM (Nov. 3, 2016),
https://www.buzzfeed.com/craigsilverman/how-macedonia-became-a-global-hub-for-pro-
trump-misinfo?utm_term=.jgOP8e208# mcSdvo9bv [https://perma.cc/YCH9-8NN4] (“Most
of the posts on these sites are aggregated, or completely plagiarized, from fringe and right-wing
sites in the US”).

81. See supra notes 76-82 and accompanying text.

82. See generally, Jamie Condliffe, Fake News is Unbelievably Cheap to Produce, MIT
TEcH. R. (June 14, 2017),  https://www.technologyreview.com/s/608105/fake-news-is-
unbelievably-cheap/.

83. See, e.g., David Uberti, The Real History of Fake News, COLUM. J. REV. (Dec., 15,
2016), http:/www.cjr.org/special_report/fake_news_history.php _ [https://perma.cc/K5FH-
Z9C8].

84. See Jacob Soll, The Long and Brutal History of Fake News, POLITICO (Dec. 18, 2016),
http://www. politico.com/magazine/story/2016/12/fake-news-history-long-violent-2 14535
[https://perma.cc/ZRR6-ZY35 | (discussing impact of the printing press on production,
dissemination, and consumption of fake news).

85. See Samantha Subramanian, /nside the Macedonian Fake-News Complex, WIRED
(Feb. 15, 2017), https://www.wired.com/2017/02/veles-macedonia-fake-news/
[https://perma.cc/AG3C-7D6Z]; Silverman & Alexander, supra note 80.
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 71

information more economically challenging in the way that it has for
legitimate news. On the contrary, the economics of false news have been
enhanced as a result of the changes in systems of news distribution.*° Thus,
from the standpoint of the counterspeech doctrine, the relative production of
legitimate news and information compared to false news and information is
in the midst of perhaps an unprecedented decline.

B. Diminished Gatekeeping and Distribution Barriers

The shift in the relative prominence of legitimate versus false news is a
function of the fact that the gatekeeping barriers that have traditionally
curtailed the dissemination of false news relative to legitimate news have been
dramatically reduced. The notion of gatekeeping barriers refers to the
decision-making mechanisms controlling the type of news to which
consumers have access..°’ The mass media era was defined by gatekeeping
bottlenecks, in which freedom of the press was “guaranteed only to those that
own one.”*® Effective distribution was confined to outlets, such as broadcast
stations, cable networks/systems, newspapers, and magazines, all of which
were relatively scarce for technological and economic reasons, and thus
operated as news and information bottlenecks that wielded substantial
gatekeeping power.*?

The Internet has provided the opportunity to circumvent these
bottlenecks. As a consequence, the economic incentives for producing
legitimate journalism have been undermined, even as, the opportunities to
distribute news have increased, and the costs of distribution have decreased.”
Conversely, given the low costs associated with producing fake news, the
diminished gatekeeping barriers and minimal distribution costs have
enhanced the economic incentives for producing fake news.*! The size of the
potential market is, simply, larger.??

Even the gatekeeping to advertising dollars has been transformed in
ways that enhance the opportunities for fake news outlets. Today, the
allocation of online advertising dollars is increasingly handled by
algorithmically-driven ad placement networks, given the overwhelming

 

86. See infra notes 92-102 and accompanying text.

87. See generally Pamela Shoemaker and Timothy Vos, GATEKEEPING THEORY (2009).

88. See AJ. Liebling, The Wayward Press: Do You Belong in Journalism? NEw
YORKER, (May 14, 1960), at 109.

89. See Jonathan Taplin, The IP TV Revolution, in THE NETWORK SOCIETY 241 (2005)
(describing the “critical transition from a media world of analog scarcity to... digital
abundance where any maker of content (films, music, video games) could have access to the
world’s audience through a server based on demand media environment”).

90. See supra notes 78-83 and accompanying text.

91. See Abby Ohlheiser, This is How Internet's Fake News Writers Make Money, WASH.
POST (Nov. 18, 2016), https: //www.washingtonpost.com/news/the-
intersect/wp/2016/11/18/this-is-how-the-internets-fake-news-writers-make-
money/?utm_term=.7c4ee4d7e8d6 [https://perma.cc/V5S9-LBJS].

92. Id
72 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

number of ad placement options.” Often, online advertisers do not even know
exactly where their advertisements are being placed.” This is in stark contrast
to the mass media era, when information about when and where
advertisements were being placed was common knowledge.” The end result
is that, on the basis of the criteria embedded in the ad-placement algorithms,
fake news sites have been on more or less equal footing with other online
content providers. Even recent, initial efforts to ban known fake news outlets
from major ad networks (a response to the post-2106 fake news revelations)
appear to have — at least initially — proven not entirely effective.*
Previously, the distribution and monetization of fake news would be
prevented to some extent via the limited number of gatekeepers.*’ Given their
limited number, these gatekeepers had both the incentive and the opportunity
to curb the dissemination of fake news. The incentive came from the fact that,
in a far less fragmented media environment, neutral and objective (and thus
less likely to be false) reporting represented an effective approach to attracting
and retaining the largest possible audience.** The opportunity came in the
form of the substantial economic resources these outlets had to research and
verify stories — resources that were a function of the economic health of these

 

93. See Robert Thomson, News Corp. CEO on Fake News, ‘Digital Duopoly’ and What
Role Advertising Plays in All of Jt, MEDIASHIFT (Apr. 3, 2017),
http://mediashift.org/2017/04/news-corp-ceo-fake-news-digital-duopoly-role-advertising-
plays/ [https://perma.cc/P382-B8VV].

94. David laconangelo, Why Didn’t These Companies Know They Were Advertising on
Breitbart? CHRISTIAN SCIENCE MoNITOR (2016, Nov. 30),
https://www.csmonitor.com/Business/2016/1130/Why-didn-t-these-companies-know-they-
were-advertising-on-Breitbart (“The fact that many of the companies apparently didn’t
know that their ads were appearing [on Breitbart] seems to highlight how new ad
technologies have loosened companies’ grip over their brand’s associations’).

95. Jd (noting that it has become “a lot easier for buyers to lose a degree of control
over where their ads run”).

96. See Craig Silverman et al., In Spite of the Crackdown, Fake News Publishers Are
Sall Earning Money from Major Ad Networks, BUuZzFEED (Apr. 4, 2017),
https://www.buzzfeed.com/craigsilverman/fake-news-real-ads [https://perma.cc/62GN-
L72N].

97. See AJ. Liebling, The Wayward Press) Do You Belong in Journalism? NEW
YORKER, May 14, 1960, at 105.

98. See, e.g., JAMES T. HAMILTON, ALL THE NEWS THAT’S FIT To SELL: How THE MARKET
TRANSFORMS INFORMATION INTO NEWS 38 (2004) (“The evidence in this chapter demonstrates
that independent news coverage grew as scale economies became more important”), see also
GERALD J. BALDASTY, THE COMMERCIALIZATION OF NEWS IN THE NINETEENTH CENTURY 28
(1992). It should be noted that some researchers have questioned whether the development of
the norm of objectivity is tied to the commercialization of the press. See, e.g., Michael
Schudson, The Objectivity Norm in American Journalism, 2 JOURNALISM 149, 160 (2001)
(‘The notion that the move from partisanship to objectivity was economically motivated is
widely believed but nowhere justified.”).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 73

outlets prior to the damaging effects of an increasingly fragmented media
environment.”

This scenario of diminished bottlenecks and gatekeepers represents a
tremendous opportunity for the production and dissemination of fake news.
As has been well-illustrated in the months since the 2016 U.S. presidential
election, many of those engaged in the production and distribution of fake
news did so purely because of the tremendous economic opportunity it
presented, not out of any ideological motivations.'°° Economic incentives to
provide false news have always existed, given the appealing economics of
false news production discussed above.!°! The key point here is that the
diminished barriers to entry (and thus diminished institutional gatekeeping)
afforded by the Internet enhanced these incentives.

These economic incentives have been further enhanced over the past
few years by social media distribution.’ Social media provides a means to
more effectively capitalize on the diminished gatekeeping barriers facilitated
by the Internet by providing previously unprecedented paths to low-cost
distribution and large aggregations of audiences. Research indicates that
social media referrals are a more crucial component of story distribution for
hyper-partisan and fake news sites than they are for legitimate news sites.‘
Another recent study found that, in the days before the 2016 election, many
Twitter users received a higher volume of misinformation and conspiratorial
content than professionally produced news.!™

 

99. See, eg., Leonard Downie, Jr., & Michael Schudson, The Reconstruction of
American Journalism, COLUM. J. REV. 1 (Nov/Dec. 2009),
http://archives.cjr.org/reconstruction/the_reconstruction_of_american.php
[https://perma.cc/KD6D-DBLM] (“Commercial television news, which was long the chief
rival of printed newspapers, has also been losing its audience, its advertising revenue, and its
reporting resources.”).

100. See, e.g., Subramanian, supra note 85 (“These Macedonians on Facebook didn’t care
if Trump won or lost the White House. They only wanted pocket money to pay for things—a
car, watches, better cell phones, more drinks at the bar.”). As Adam Mosseri, Facebook’s Vice
President of News, has stated, “We’ve found that a lot of fake news is financially motivated.”
Adam Mossen, News Feed FYI: Addressing Hoaxes and Fake News, FACEBOOK (Dec. 15,
2016), _ https://newsroom.fb.com/news/2016/12/news-feed-fyi-addressing-hoaxes-and-fake-
news/ [https://perma.cc/GT4S-X4QH]; Silverman & Alexander, supra note 82 (“Their reasons
for launching these sites are purely financial, according to the Macedonians with whom
BuzzFeed News spoke”).

101. See supra notes 84-88 and accompanying text.

102. See generally Timothy B. Lee, Facebook's Fake News Problem, Explained, Vox
(Nov. 16, 2016),  http://www.vox.com/new-money/2016/11/16/13637310/facebook-fake-
news-explained [https://perma.cc/JV55-2MZP]

103. See Alexios Mantzarlis, Facebook Referrals are Crucial for Traffic to Hyperpartisan
and Fake News Sites, POYNTER (Nov. 28, 2016), https://www.poynter.org/2016/facebook-
referral s-are-crucial-for-traffic-to-hyperpartisan-and-fake-news-sites/440132/
[https://perma.cc/KT3K-YBAP].

104. See Philip N. Howard et al., Social Media, News and Political Information During
the U.S. Election: Was Polarizing Content Concentrated in Swing States? COMPROP DaTa
MEMO (Sept. 27, 2017), http://comprop.oii.ox.ac.uk/wp-
content/uploads/sites/89/2017/09/Polanizing-Content-and-Swing-S tates. pdf
[https://perma.cc/53VP-PBY2], at 1 (finding that “nationally, Twitter users got more
misinformation, polarizing and conspiratorial content than professionally produced news”).
74 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

It is important to emphasize that these social media platforms, like their
mass media predecessors, also represent bottlenecks with substantial
gatekeeping capacity.!°> The reality however, has been that, likely due to a
combination of factors (scale, technological limitations, economic incentives,
organizational philosophy, ignorance), this gatekeeping authority has not
been rigorously deployed to combat the dissemination of fake news.

It is important to recognize that underlying this argument is the
assumption that, regardless of the motivation, sources of news and
information with more partisan orientations produce more false news than
journalistic sources that adhere to more traditional notions of neutrality and
objectivity. While perhaps controversial, this assumption is grounded in
compelling empirical evidence.!

In sum, within the counterspeech doctrine’s valorization of “more
speech,” the point here is that, in today’s news ecosystem, more of this “more
speech” is likely to be false speech.

C. Increased Ability to Target the Most Impressionable

Within the context of the distribution of news, it is also important to
take into consideration the ways in which the distribution of false news can
now be more effectively targeted at those individuals most likely to be
affected by the misinformation.

Nicholas Negroponte’s famous speculation about the inevitability (and
desirability) of The Daily Me provides a useful starting point for the rise of
personalization in digital media. '’ Personalization is a data driven
phenomenon, facilitated by the information backchannels that are inherent in
interactive media. '°* As Negroponte predicted, interactive media have
allowed people to craft their own individual news diets. Negroponte’s
somewhat utopian perspective has since been tempered by concerns about the

 

105. See Emily Bell, Facebook is Eating the World, Cou. J. REV. (Mar. 7, 2016) (“The
largest of the platform and social media companies, Google, Apple, Facebook, Amazon, and
even second order companies such as Twitter, Snapchat and emerging messaging app
companies, have become extremely powerful in terms of controlling who publishes what to
whom.... There isa far greater concentration of power in this respect than there ever has been
in the past”).

106. See, e.g., Kate Starbird, Examining the Alternative Media Ecosystem Through the
Production of Alternative Narratives of Mass Shooting Events on Twitter (2017) (unpublished
manuscript), http://faculty. washington.edu/kstarbi/Alt_Narratives ICWSM17-
CameraReady.pdf [https://perma.cc/HS9M-8VF7]. The author notes that, “[n]ot surprisingly,
we found the conversation around alternative narratives of mass shooting events to be largely
fueled by content on alternative (as opposed to mainstream) media.” Jd at 9.

107. See NICHOLAS NEGROPONTE, BEING DIGITAL 153 (1996).

108. See generally, Mary Collins, Personalized Media: It’s All About the Data,
TVNEWSCHECK (2017, Sept. 8), http://(www.tvnewscheck.com/article/107097/personalized-
media-its-all-about-the-data.
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 75

political and cultural detriments of residing in such filter bubbles. !
Nonetheless, personalization continues to work its way through the news
ecosystem, with even the New York Times recently launching an initiative to
bring more data-driven personalization to the process of presenting stories to
online news consumers.!!° The key point here is that interactivity provides a
stream of audience data that facilitates audience targeting and personalization
to an unprecedented extent.

Within the context of counterspeech, this means that those with an
economic and/or political mterest in the dissemination of false news are now
far better equipped than in the past to deliver their content to those they most
desire to reach. Targeting exclusively right- or left-leaning news consumers
(or other, more specific political traits) with false news or information has
never been easier, as observable social media activity provides a host of
reliable indicators of an individual’s political orientation.'!! In these ways, the
magnitude of the “evil” (to use Brandeis’ term)!” that false speech can
achieve is amplified.

In the wake of the 2016 election, it was reported that Donald Trump’s
campaign employed a consulting firm, Cambridge Analytica, which drew
upon massive amounts of social media data to construct detailed
psychological, demographic, and geographic profiles of individual voters.
These data were then utilized by the Trump campaign to deliver micro-
targeted political messages through social media platforms such as

 

109. See, e.g., Eli Pariser, THE FILTER BUBBLE: WHAT THE INTERNET IS HIDING FROM You
(2011); SUNSTEIN, supra note 62 at 2 (“In the 1990s, the idea of a Daily Me seemed more than
a little absurd. But it’s looking astoundingly good. If anything, Negroponte understated what
was coming, what has now arrived, and what is on the horizon. Is that a promise or a threat? I
think it’s both — and that the threatening part is what needs to be emphasized, not least because
so many people see it as pure promise”); Jon Keegan, Blue Feed Red Feed: See Liberal
Facebook and Conservative Facebook, Side by Side, WALL ST. J. (May 18, 2016),
http://graphics.ws].com/blue-feed-red-feed/ [https://perma.cc/8SPX-SBGA]. For empirical
evidence of filter bubbles, see Tien T. Nguyen et. al., Exploring the Filter Bubble: The Effect
of Using Recommender Systems on Content Diversity, in WWW ='14 IN PROCEEDINGS OF THE
23RD INTERNATIONAL CONFERENCE ON WoRLD WIDE WEB 677 (Apr. 2014),
http://dl.acm.org/citation.cfm?doid=2566486.2568012 [https://perma.cc/TH9X-KW9F],
Alessandro Bessi et al., Users Polarization on Facebook and YouTube, PLOS ONE (Aug. 23,
2016), https://doi.org/10.1371/journal.pone.0159641 [https://perma.cc/NASD-SG4P], Walter
Quattrociocchi et al., Echo Chambers on Facebook (2016, June 13) (unpublished manuscript),
https://papers.ssrn.com/sol3/papers.cfm?abstract_1d=2795110 [https://perma.cc/PA95-
WDGD].

110. See Ricardo Bilton, All the News That’s Fit for You: The New York Times is
Experimenting with Personalization to Find New Ways to Expose Readers to Stories, NIEMAN
LAB (Sept.28, 2017), http:/*www.niemanlab.org/2017/09/all-the-news-thats-fit-for-you-the-
new-york-times-is-experimenting-with-personalization-to-find-new-ways-to-expose-readers-
to-stories/[https://perma.cc/QJ8T-XZ8P].

111. See Elanor Colleoni et al., Echo Chamber or Public Sphere? Predicting Political
Orientation and Measuring Political Homophily in Twitter Using Big Data, 64 J. oF
COMMUNICATION 317, 321 (2014) (“By classifying all the content posted according to its
political orientation we are able to identify the general political onentation of the users and
measure levels of political homophily in their network”).

112. See Whitney v. California, 274 U.S. 357, 377 (1927) (Brandeis, J., concurring).
76 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

Facebook.!' Hundreds of Russian-operated Facebook accounts also have
been found to have been engaging in such election-related micro-targeted
advertising. ''4 Congressional investigators are currently evaluating the
content of these ads, so there is no clear sense yet of the extent to which false
news or claims were delivered in these messages.!!° However, the point here
is that the technological capacity to target citizens with tailored messages or
false news stories based on their characteristics appears to have taken yet
another substantial leap forward, beyond what was possible through previous
communications channels.!!®

From a false news perspective, according to a U.S. Senate investigation,
the Russians working to spread fake news stories specifically targeted voters
in swing states such as Wisconsin, Michigan, and Pennsylvania,'!” with this
geographic targeting facilitated by social media data. Further, according to
the testimony of cybersecurity expert Clint Watts, some of these fake news
outlets explicitly targeted Donald Trump, tweeting fake news stories directly
to his Twitter account during time periods when he was known to be online,
under the presumption that he has shown himself to be particularly susceptible

 

113. See Issie Lapowsky, What Did Cambridge Analytica Really do for the Trump
Campaign? WIRED (Oct. 26, 2017), https:/Awww.wired.com/story/what-did-cambridge-
analytica-really-do-for-trumps-campaign/ [https://perma.cc/72E7-8WLL]. For methodological
details, see generally Joshua Green & Sasha Issenberg, /nside the Trump Bunker, with Days to
Go, BLOOMBERG BUSINESSWEEK, _ https://www.bloomberg.com/news/articles/2016-10-
27/inside-the-trump-bunker-with- 12-days-to-go [https://perma.cc/79L3-MVJV].

114. See Alex Stamos, An Update on Information Operations on Facebook, FACEBOOK
(Sept/ 6, 2017), _ https://newsroom.fb.com/news/2017/09/information-operations-update/
[https://perma.cc/ASRY-Z7F 5].

115. See Craig Timberg et al., Facebook to Turn Over Thousands of Russian Ads to
Congress, Reversing Decision, WASH. POST (Sept. 21, 2017),
https: //www. washingtonpost.com/business/technology/facebook-to-turn-over-thousands-of-
russian-ads-to-congress-reversing-decision/2017/09/21/9790b242-9f00-1 1e7-9083-
fbfddf6804c2_story.html?utm_term=.0d6c72e30048 [https://perma.cc/RJSA-TM6H].

116. See Zeynep Tufekci, Engineering the Public: Big Data, Surveillance, and
Computational Politics, 19 FIRST MONDAY, http://firstmonday.org/article/view/490 1/4097
[https://perma.ce/3_LWW-AWMC] (“While computational politics in its current form includes
novel applications, the historical trends discussed in this paper predate the spread of the
Internet. In fact, there was already a significant effort underway to use big data for purposes of
marketing, and the progression of using marketing techniques for politics — and “selling of
the President” — clearly reflects longer-term trends. However, computational politics
introduces significant qualitative differences to that long march of historical trends. Unlike
previous data collection efforts (for example, collating magazine subscriptions or car type
purchases) which required complicated, roundabout inferences about their meaning (does a
magazine subscription truly signal a voter preference?) and allowed only broad profiling in the
aggregate, this data provides significantly more individualized profiling and modeling, much
greater data depth, and can be collected in an invisible, latent manner and delivered
individually[.]’”).

117. See Rachel Roberts, Russia Hired 1,000 People to Create Anti-Clinton Fake News in
Key U.S. States During Election, Trump-Russia Hearings Leader Reveals, THE INDEP. (Mar.
30, 2017) (According to Senator Mark Warner, “[i]t’s been reported to me, and we’ve got to
find this out, whether they were able to affect specific areas in Wisconsin, Michigan,
Pennsylvania [.]”). For further evidence of the targeting of fake news to swing state social
media users, see Howard et al., supra note 104.
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 77

to fake news.!!8 This is an extreme example of today’s highly personalized
media environment enhancing the opportunities for purveyors of fake news
to reach those both most likely and most important to be affected by the
misinformation.

One could certainly argue that these dynamics provide comparable
opportunities for true and accurate news to target those news consumers most
in need of being reached, or most vulnerable to fake news. The problem with
this logic becomes clearer when factoring in the ways in which this process
of personalization undermines the likelihood of exposure to counterspeech
that directly addresses the false speech that has been consumed.!!°

D. The Diminished Likelihood of Being Exposed to Factual
Counterspeech

As Vincent Blasi has emphasized, one of the key conditions impacting
the effectiveness of counterspeech is the extent to which “the counter-
message comes to the attention of all the persons who were swayed by the
original idea.”'?° The dynamics of the contemporary media environment to
some extent serve to explicitly prevent this type of exposure to counterspeech
from taking place. This is the essence of the filter bubble phenomenon, in
which the intertwining of individual and algorithmic content
personalization’?! on social media and other news aggregation platforms
works to deflect news sources and content that do not correspond to the user’s
established content preferences and political orientation.’ Certainly, this

 

118. See MEDIA MATTERS FOR AMERICA, CNN. Fake News Trolls Pushing Conspiracy
Theories “Tweet Right at President Trump” Hoping that “He Cites it Publicly (Mar. 30, 2017)
https://www. mediamatters.org/video/2017/03/30/cnn-fake-news-trolls-pushing-conspiracy-
theories-tweet-right-president-trump-hoping-he-cites-it/2 15878 [https://perma.cc/35GH-
43VN |(“WOLF BLITZER (HOST): Do these fake news trolls sometimes actually target
President Trump himself? BRIAN TODD: According to the cybersecurity expert Clint
Watts who you had on earlier, Wolf, they do, in fact, do that. Watts testified today that
some outlets pushing fake or misleading stories will tweet nght at President Trump during high
volume periods when they know he's online. They're pushing conspiracy theories hoping that
he clicks on one and cites one publicly.”).

119. See infra notes 122-136 and accompanying text.

120. See Blasi, supra note 26, at 1357.

121. See Eytan Bakshy et al., Exposure to Ideologically Diverse News and Opinion on
Facebook, 348 SCIENCE 1130, 1130 (June 5, 2015) (“The media that individuals consume on
Facebook depends not only on what their friends share but also on how the News Feed ranking
algorithm sorts these articles and what individuals choose to read.”), Philip M. Napoli, Social
Media and the Public Interest: Governance of News Platforms in the Realm of Individual and
Algorithmic Gatekeepers, 39 TELECOM. PoL’y 751 (Oct. 2015).

122. See Sunstein, supra note 60, Seth R. Flaxman et al., Ideological Segregation and the
Effects of Social Media on News Consumption, at 1 (May 2014) (unpublished manuscript),
https://bfi uchicago.edw/sites/default/files/research/flaxman_goel_rao_onlinenews.pdf
(finding that “recent technological changes do increase ideological segregation’). For critiques
of the filter bubble logic and some contrary empirical findings, see Mark S. Nadel, Customized
News Service and Extremist Enclaves in Republic.com, 54 STANFORD L. REV. 831 (2002),
Jacob L. Nelson, Js Fake News a Fake Problem? COLUMBIA J. REV. (January 31, 2017),
https://www.cjr.org/analysis/fake-news-facebook-audience-drudge-breitbart-study.php.
78 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

process of deflection works both ways. That is, one’s filter bubble might
deflect fake news that contradicts previously-consumed legitimate news. Or,
it might deflect legitimate news that contradicts previously-consumed false
news.

But here again is where the extent to which the filter bubbles have a
partisan orientation comes into play. Given the empirical connection between
partisanship and falsity,'? to the extent one’s filter bubble has a partisan
orientation, the likelihood of fake news making it through the filter bubble
increases. 4 At the same time, the likelihood of legitimate news that
counteracts that fake news decreases.!** The current state of play is perhaps
best termed the “Spiral of Partisanship.”!° In this scenario, the increased
media fragmentation and personalization that began in the 1980s with the
development of cable television; then accelerated through the 90s and 2000s
with the rise of the Internet and social media, simultaneously facilitates the
mutually dependent phenomena of the rise of more partisan news outlets and
the selective exposure to more partisan news. These are mutually dependent
phenomena in that partisan news outlets require an audience to justify their
existence and more partisan news consumption requires the availability of
more partisan news outlets.

And so, as the media environment grows more fragmented, its ability
to both sow and satisfy increasing partisanship is amplified.!”’ It is likely no
coincidence that the upswing in self-reported partisanship begins in the 1980s,
at the same time that media fragmentation begins in earnest, primarily through

 

123. See Starbird, supra note 106.

124. See, e.g, Delia Mocanu et al., Collective Attention in the Age of (Mis)information,
51 Comp. IN Hum. BEHAV. 1198, 1202 (2015) (finding that “users with strong preferences for
alternative information sources .. . are more susceptible to false information”), Alessandro
Bessi et al., Science vs Conspiracy. Collective Narratives in the Age of Misinformation, PLOS
ONE at | (finding that “polarized communities emerge around distinct types of contents and
usual consumers of conspiracy news result to be more focused and self-contained on their
specific contents”).

125. See Quattrociocchi et al., supra note 109.

126. This term is used in reference to the well-known Spiral of Silence, which has posited
that individuals who perceive their opinion to be in the minority will choose not to express that
opinion, thus feeding into a downward spiral that systematically silences more and more of
those holding that minority opinion, thereby creating a false impression of a widely-shared
majority opinion. See ELIZABETH NOELLE NEUMAN, THE SPIRAL OF SILENCE: PUBLIC OPINION
— OUR SOCIAL SKIN (1994).

127. See JONATHAN M. LADD, WHY AMERICANS HATE THE MEDIA AND How IT MATTERS
(2011) Gllustrating how increased media fragmentation has interacted with demand for more
partisan news to amplify partisanship and distrust of institutional news media).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 79

the rise of cable television.!** And, as data tell us, consumers of partisan news
are both more likely to consume false news!’ and possibly are inherently
more resistant to counterspeech that corrects that false news.!*° Therefore, the
net effect is one in which the dynamics of the contemporary media ecosystem
tilt the balance toward the consumption/impact of fake news to an extent that
was not the case in the pre-filter bubble era.

This dynamic is particularly damaging to traditional articulations and
applications of the counterspeech doctrine. Traditional approaches to
counterspeech have essentially operated under a broadcast-era model of
media distribution. Consider the Fairness Doctrine, which operated under the
assumption that counterspeech presented on the same platform and at the
same time of day as the original speech would be effective."! Such an
assumption seems at best quaint, and at worst utterly anachronistic, when
applied to today’s media environment of intertwined individual and
algorithmic content filtering,!** in which filter bubbles have been constructed
in ways that often are fundamentally oriented toward deflecting
counterspeech. From this standpoint, it seems reasonable to suggest that the
ability of counterspeech to reach exactly those it needs to reach has been
diminished as a result of the technological changes that have affected the
media ecosystem.

E. The Diminished Ability to Distinguish Between Legitimate and
False News

Technological changes are undermining news consumers’ abilities to
distinguish between legitimate and false news. In illustrating this point, it is
important to begin with the unique challenges associated with evaluating
news. To do so, it is useful to begin with how consumers evaluate the quality
of the products that they consume. Economists generally recognize three

 

128. See Amanda Taub, The Real Story About Fake News is Partisanship, N.Y .TIMES
(Jan. 11, 2017), https:/Awww.nytimes.com/2017/01/11/upshot/the-real-story-about-fake-news-
is-partisanship.html [https://perma.cc/DQ34-XERP ] (“[S]tarting in the 1980s, Americans
began to report increasingly negative opinions of their opposing party.”). For a more detailed
discussion of the relationship between fragmentation and political polarization, see RICARDO
GANDOUR, A NEW INFORMATION ENVIRONMENT: How DIGITAL FRAGMENTATION IS CHANGING
THE WAy WE PRODUCE AND CONSUME NEws (2016),
https://knightcenter.utexas.edu/books/NewInfoEnvironmentEnglishLink. pdf
[https://perma.cce/8KZA-WG7A].

129. See Delia Mocanu et al., supra note 124.

130. See R. Kelly Garrett et al. Driving a Wedge Between Evidence and Beliefs: How
Online Ideological News Exposure Promotes Political Misperceptions, 21 J. OF COMPUTER-
MEDIATED Com. 331, 344 (2016) (“In the month leading up to the election, a quarter of
Americans said they used biased news sites several times or more. Reliance on these websites
appears to produce a distorted understanding of evidence, potentially promoting inaccurate
beliefs even when evidence is understood correctly. It is sobering to recognize that online news
may contribute to misperceptions even when consumers encounter a range of outlets and have
been exposed to more accurate political information”).

131. See Ruane, supra note 30.

132. See Napoli, supra note 121.
80 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

categories of goods: 1) search/inspection goods, for which quality can be
readily determined through examination; 2) experience goods, for which
quality can be determined only after usage for a period of time; and 3)
credence goods, which must be consumed on faith, as quality is difficult to
ascertain.!

News can sometimes fall into the second category (say, for example,
when the local newscast reports rain for tomorrow, but it ends up snowing
instead).'*4 But more often, news is likely to fall into the third category, with
news being consumed, and potentially being put to use in decision-making,
in ways that do not always result in the kind of observable feedback that
allows for a subsequent evaluation of the veracity or quality of that
reporting. '°5

When it comes to the evaluation of any kind of product, the notion of
“bounded rationality” comes into play.!°° And news consumers typically are
extremely rational, lacking the necessary information to make fully informed
determinations as to the quality of the product they are consuming. This 1s a
reflection of the fact that “by definition, news is what the public does not
know.”!*’ For these reasons, the consumption of false news is to some extent
a function of receiving inadequate information (interacting with the various
cognitive biases discussed above),!** and the resulting inability of consumers
to distinguish between true and false information, and thus consuming fake
news under the misperception that it is truthful. The challenge of accurately
distinguishing between true and false news is further exacerbated by the
dramatic increase in available news and information sources online, which
places a greater cognitive burden on news consumers in terms of
distinguishing between legitimate and false news sources and stories.!?

 

133. See John H. McManus, What Kind of Commodity is News? 19 COMMC’N RESEARCH
787, 794 (1992).

134. In this situation, news is not unlike a “lemon” purchased from an automobile seller.
The poor quality of the information (or car) is not revealed until well after the purchase is
finalized. See George A. Akerlof, The Market for “Lemons”: Quality Uncertainty and the
Market Mechanism, 84 Q.J. oF Econ. 488, 490-91 (1970) (discussing “asymmetrical
information”).

135. Seeld

136. For an overview and advocacy of the concept of bounded rationality, see generally
John Conlisk, Why Bounded Rationality?, 34 J. oF ECon. LIT. 669 (1996). For a discussion of
the concept’s relationship to the marketplace of ideas metaphor, see generally Joseph Blocher,
Institutions in the Marketplace of Ideas, 57 DUKE L.J. 821 (2008).

137. See McManus, supra note 133, at 793.

138. See Garrett & Stroud, supra note 61.

139. See, e.g., Olivia Solon, Only 20% of US. Adults Have Information Overload. but
Those Who do Feel the Burden, THE GUARDIAN (Dec. 7, 2016),
https: //www.theguardian.com/technology/2016/dec/07/information-overload-pew-study-
digital-divide. [https://perma.cc/647C-C5QP], Xiaoyan Qiu et al., Lack of Quality
Discrimination in Online Information Markets (January 2017) (unpublished manuscript) (on
file with ResearchGate),
https: //www.researchgate net/publication/312194354 Lack of quality discrimination in on
line_information_markets [https://perma.cc/E3R6-UFWV].
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 81

Of particular importance is the extent to which the traditional
mechanisms for combating this sort of uninformed consumption have been
undermined by technological change. For instance, the reputations of news
outlets long have served as a way for consumers to distinguish between truth
and falsity.“° Reputations have often been identified as an important factor to
facilitate efficient markets for experience and credence goods. ! The
reputation of the New York Times for being truthful and accurate has generally
been better than that of the National Enquirer.

This important heuristic, however, is being undermined as news
consumption migrates to news aggregators and social media platforms. This
is most compellingly demonstrated by research showing how seldom news
consumers know the actual source of the news they are consuming. For
example, recent research by the Pew Research Center indicates that
individuals who consume news via social media are capable of identifying the
originating source of the story consumed only about half the time.'*?

Further, this traditional outlet reputation-based mechanism for
evaluating the likely truthfulness of a news story is being replaced by a new
heuristic — the trustworthiness of the individual who shared the story on social
media.'“? Thus, an article shared by a trusted member of an individual’s social
network, but written by a source unknown to that individual, will be evaluated
as more trustworthy — and thus be more likely to be consumed and shared —
than an article produced by a reputable news source but shared by someone
viewed as less trustworthy.’ This halo effect extends to news brands as a
whole, with individuals more likely to follow and recommend news outlets
that were referred to them by trusted members of their social network. !4
Given that the filter bubble dynamic discussed above is a function of the
ideological homogeneity that characterizes many individuals’ social

 

140. See Miriam J. Metzger et al., Social and Heuristic Approaches to Credibility
Evaluation Online, 60 J. COMM. 413, 426 (2010) (“One of the most prevalent heuristics used
for evaluating credibility that was mentioned by focus group participants was relying on site
or source reputation.”).

141. See Steffen Huck et al., Pricing and Trust 1 (Feb. 2008) (unpublished manuscript)
(on file with Paris School of Economics) (noting that “[w]henever contracts for the exchange
of a good are incomplete and sellers have leeway to shade its quality about which the consumer
finds out only if it is too late... A key role in markets for such goods is assumed by trust”),
https://www.parisschoolofeconomics.eu/IMG/pdf/Huck2. pdf [https://perma.cc/RS7B-
EWVX].

142. See Amy Mitchell et al.. How Americans Encounter, Recall and Act Upon Digital
News, PEw RES. CTR. (Feb. 9, 2017), http:/www.journalism.org/2017/02/09/how-americans-
encounter-recall-and-act-upon-digital-news/. [https://perma.cc/L6JG-VQQA].

143. See generally, THE MEDIA INSIGHT PROJECT, “WHO SHARED IT?”: How AMERICANS
DECIDE WHAT NEWS To TRUST ON SOCIAL MEDIA (2017),
http://mediainsight.org/PDFs/Trust®20Social%20Media%20Experiments%202017/Medialns
ight Social%20Media%20Final.pdf [https://perma.cc/ED2R-YHEK].

144. Id at4-9.

145. Jd at 10 (“Those who trusted the sharer but saw the unknown outlet were more likely
than those who did not trust the sharer and saw the reputable outlet to share the article, follow
the sharer, sign up for news alerts from the source, and recommend the source to friends.”).
82 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

networks,'*° the situation once again presents itself in which the likelihood of
exposure to counterspeech is being undermined by the social media context
in which news consumption is increasingly taking place.

These dynamics help to explain recent findings indicating that trust in
mainstream news outlets is much lower than the levels of trust that news
consumers place in the news outlets catering to their ideological
orientation.” The distribution of trust in news organizations is essentially
being reallocated in ways that favor the consumption and acceptance of fake
news over legitimate news, which works against the effectiveness of
counterspeech. Ultimately, if news consumers are increasingly unable to
accurately gauge whether a news source’s reporting is likely to be true or
false, then more speech (1.e.., counterspeech) does nothing to assure that truth
prevails and that democratic decision-making is well-informed.!“*

Moreover, news consumers need to consider the issue of intentional
misrepresentation of news sources. Political propaganda has always been a
part of political campaigns. ‘4? Under the logic of counterspeech, false
propaganda should be effectively counteracted by true and accurate news and
information. However, a key means of enhancing the effectiveness of false
propaganda involves disguising the source. °° Propaganda disguised as

 

146. See Itai Himelboim et al., Birds of a Feather Tweet Together: Integrating Network
and Content Analyses to Examine Cross-Ideology Exposure on Twitter, 18 J. COMPUTER-
MEDIATED Como. 40, 40 (Jan. 2013) (finding that “Twitter users are unlikely to be exposed to
cross-ideological content from the cluster of users they followed as these were usually
politically homogeneous”), Andrei Boutyline & Robb Willer, The Social Structure of Political
Echo Chambers: Variation in Ideological Homophily in Online Networks, 38 POL. PSYCHOL.
551, 566-567 (2017) (finding that more ideologically extreme individuals have more
homophilous social networks, which should “result in networks that embed their members in
denser webs of like-minded associations, which could then insulate individuals from the
demotivating effects of dissenting views, and may enable political behaviors to spread faster
than they would through sparser networks”).

147. See Amy Mitchel et. al., Political Polarization & Media Habits, PEw RES. CTR. (Oct.
21, 2014) (showing “little overlap in the news sources [liberals and conservatives] turn to and
trust”), http://www jourmalism.org/2014/10/21/political-polarization-media-habits/.
[https://perma.cc/MR4D-DUHL]; “My” Media Versus “The” Media: Trust In News Media
Depends on Which News Media You Mean 1, MEDIA INSIGHT PROJECT (May 2017),
http://www. mediainsight.org/PDFs/Meaning%200f%20Media/APNORC_ Trust_The Media_
Topline final.pdf. https://perma.cc/N6FQ-5M5E. (finding that “on many fronts, Americans are
skeptical of ‘the news media’ in the abstract but generally trust the news they themselves rely
on”).

148. See Goldman & Cox, supra note 11, at 23.

149. For a comprehensive overview of the history of propaganda and its use in political
campaigns, see generally Garth S. Jowett & Victoria J. O’Donnell, Propaganda & Persuasion
(6" ed.) (2014).

150. See Jessie Daniels, Cloaked Websites: Propaganda, Cyber-Racism and Epistemology
in the Digital Era. 11 NEW MEDIA & SOCIETY 658, 660 (2009) (“The emergence of websites
such as Weltner’s Katrina Families and American Civil Rights Review illustrates a central
feature of propaganda and cyber-racism in the digital era: the use of difficult-to-detect
authorship and hidden agendas intended to accomplish political goals.”).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 83

legitimate news has proven to be particularly effective.!*! What is different
now is the extent to which propaganda can be effectively disguised as
legitimate news.!** This is a function of the diminished barriers to entry and
institutional gatekeeping, which operate in concert with the enhanced
distribution capacity of social media.

The degree to which propaganda operations can masquerade as news
outlets is much greater in an environment in which legitimate and illegitimate
news outlets can all exist side-by-side on social media platforms.'? This is
well-illustrated by the report that as many as 1,000 Russians were actively
engaged in the production and distribution of fake news through social media
during the 2016 election. An analysis of Russia’s online propaganda efforts
emphasized Russia’s utilization of a multiplicity of online sources that are
often disguised as news outlets.!*

In a 2012 television interview on the influence of money on political
campaigning, the late, conservative Supreme Court Justice (and established
counterspeech enthusiast) Antonin Scalia was asked how Thomas Jefferson
would likely have viewed the contemporary political communication
environment.!*° Scalia’s reply was, “I think Thomas Jefferson would have
said ‘the more speech the better.” That’s what the First Amendment 1s all
about.”!*’ He followed that statement, however, with this important caveat:
“so long as the people know where the speech is coming from.”** Thus, even
from a traditionalist First Amendment perspective, the counterspeech doctrine
is not absolute, and 1s especially vulnerable when the true source of news or
information is disguised.

 

151. Ja at 662 (“Organizations and individuals who deploy the strategies of ‘black’ and
‘grey’ propaganda online via cloaked websites can be more effective precisely because they
conceal their intention and authorship.”).

152. Research indicates that social media users find it particularly difficult to accurately
distinguish news posts from other types of social media posts. See Emily K. Vraga et al.,
Blurred Lines: Defining Social, News, and Political Posts on Facebook, 13 LINFo. &
TECH.POL. 272, 272 (2016) (“[U]sers and researchers often agree on defining social and
political content, but are more likely to disagree on categorizing news content.”).

153. Technological changes are likely to further enhance the ability to disguise fake news
as legitimate news. See Nick Bilton, Fake News is About to Get Even Scarier than You Ever
Dreamed, VANITY FAIR (Jan. 26, 2017), http:/Awww.vanityfair.com/news/2017/01/fake-news-
technology. [https://perma.cc/93U3-4MY9] (“At corporations and universities across the
country, incipient technologies appear likely to soon obliterate the line between real and fake.
Or, in the simplest of terms, advancements in audio and video technology are becoming so
sophisticated that they will be able to replicate real news—real TV broadcasts, for instance, or
radio interviews—in unprecedented, and truly indecipherable, ways”).

154. See Roberts, supra note 117.

155. See Christopher Paul & Miriam Matthews, The Russian “Firehouse of Falsehood”
Propaganda Model. RAND COoRP.: PERSP. (2016),
http://www.rand.org/content/dam/rand/pubs/perspectives/PE100/PE198/RAND PE198.pdf,
https://perma.cc/U3N8-5LXV (“[T]here are dozens of proxy news sites presenting Russian
propaganda, but with their affiliation with Russia disguised or downplayed.”).

156. See Piers Morgan Tonight (air date: Jul. 18, 2012 at 21:00 ET), CNN,
http://www.cnn.com/TRANSCRIPTS/1602/13/cenr.12.html, [https://perma.ce/5C42-7MUX].

157. Id.

158. Jd (emphasis added).
84 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

It is important to note that even mainstream news outlets have, on many
occasions, shown themselves to be unable to distinguish between legitimate
news and fake news, and thus have contributed to the dissemination of fake
news.!°? Parasitic journalism is an increasingly prominent dimension of the
news ecosystem, with news outlets facing diminished resources to produce
their own reporting or to rigorously verify the reporting of other news
outlets.’ These patterns increase the likelihood that legitimate news outlets
will facilitate the dissemination of fake news and thereby legitimize it for
some news consumers.

Thus, it is not surprising that recent research has illustrated that the false
news stories emanating from “hyper-partisan” nght-wing news sites were
able to influence the agenda of the mainstream news media.'*! From a
counterspeech perspective, this means that even the key providers of the
legitimate news that is intended (according to the counterspeech doctrine) to
overcome false news are not only operating at a diminished capacity to
counteract false news, but are sometimes even complicit in its perpetuation.

And then, of course, there is the question of how well new distributors
of news (1.e., social media platforms) are capable of distinguishing between
true and false news, and whether they take action on the basis of such
distinctions. Certainly, in the wake of the election these platforms have
ratcheted up their efforts to identify and curtail the spread of fake news

 

159. For a discussion of the challenges to the journalistic process of verifying news and
information disseminated online, see Alfred Hermida, Tweets and Truth: Journalism as a
Discipline of Collaborative Verification, 6 JOURNALISM PRAC. 659 (2012).

160. See The Future of Newspapers, supra note 79.

161. See Yochai Benkler etal., Study. Breitbart-Led Right-Wing Media Ecosystem Altered
Broader Media Agenda, CoLUM. JOURNALISM. REV. (Mar. 3, 2017),
http://www.cjr.org/analysis/breitbart-media-trump-harvard-study.php, _ttps://perma.cc/B4K8-
ULQA (“Our own study of over 1.25 million stories published online between April 1, 2015
and Election Day shows that a right-wing media network anchored around Breitbart developed
as a distinct and insulated media system, using social media as a backbone to transmit a hyper-
partisan perspective to the world. This pro-Trump media sphere appears to have not only
successfully set the agenda for the conservative media sphere, but also strongly influenced the
broader media agenda, in particular coverage of Hillary Clinton.”).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 85

stories.!© Whether these efforts have thus far been successful has been called
into question.!® The bottom line, however, is that when previous iterations of
content distributors (cable systems, broadcast networks, book distributors,
etc.) are compared to today’s social media platforms, social media platforms
know far less about the sources and content they are distributing (given the
massive scale at which they operate) than any previous generation of content
distributor.‘ In this regard, their relatively limited ability to distinguish
between fake and legitimate news stories/sources — their bounded rationality
— has been transferred to the news consumer.

F. The Enhanced Speed at Which False News Can Travel

Finally, it is important to consider how changes in media technology
have altered the speed at which fake news can travel. The issue of speed is
particularly important given that Brandeis’ original articulation of the
counterspeech doctrine notes that counterspeech represents the appropriate
remedy to false speech only “If there be time . . .”!°> This is a very important
qualification to take into consideration within the context of today’s media
ecosystem, in which news can “go viral.”!

It has been well documented how advances in media technologies have
compressed the “news cycle” and facilitated ever greater immediacy in the

 

162. See Josh Constine, Facebook Shows Related Articles and Fact-Checkers Before You
Open Links, TECHCRUNCH (Apr. 25, 2017), https://techcrunch.com/2017/04/25/facebook-
shows-related-articles-and-fact-checkers-before-you-open-links/. https://perma.ce/P243-
XPQE; Fergus Bell, Here’s a List of Initiatives that Hope to Fix Trust in Journalism and Tackle
Fake News, MEDIUM (Apr. 25, 2017), https://medium.com/@ferg/heres-a-list-of-initiatives-
that-hope-to-fix-trust-in-journalism-and-tackle-fake-news-30689feb402.
https://perma.cc/W72T-KQG6E; See also Testimony of Sean J. Edgett, Acting General Counsel,
Twitter, Inc., S. Comm. on the Judiciary, Subcomm. on Cnme and Terrorism (October 31,
2017), https://www._judiciary.senate.gov/imo/media/doc/10-31-
17%20Edgett™20Testimony.pdf. [https://perma.cc/YN59-VF5Z]; Testimony of Richard
Salgado, Senior Counsel, Law Enforcement and Information Security, Google, S. Comm. on
the Judiciary, Subcomm. on Cnme and Terrorism (October 31, 2017),
https://www judiciary .senate.gov/imo/media/doc/10-31-17%20Salgado%20Testimony. pdf.
[https://perma.cc/SGAS-T6FJ]; Testimony of Colin Stretch, General Counsel, Facebook, S.
Comm. on the Judiciary, Subcomm. on Cnme and Terrorism (October 31, 2017),
https://www _judiciary.senate.gov/imo/media/doc/10-31-17%20Stretch*s20Testimony. pdf.
[https://perma.cc/472D-H32W].

163. See, e.g, Sam Levin, Facebook Promised to Tackle Fake News. But the Evidence
Shows it’s not Working, THE GUARDIAN (May 16, 2017, 5:00 EDT),
https: //www.theguardian.com/technology/2017/may/16/facebook-fake-news-tools-not-
working [https://perma.cc/TQP6-R7KD].

164. Indeed, one could convincingly argue that the goal of these platforms is to host as
many speakers, and as much speech, as possible, with relatively little consideration given to
the nature of the speakers/speech — particularly in comparison to previous generations of
content distributors.

165. 274US. 357, 377 (1927) (Brandeis, J., concurring).

166. For a useful case study of viral news, see Sapna Maheshwan, How Fake News Goes
Viral: A Case Study, N. Y. TIMES (Nov. 20, 2016),
https://www.nytimes.com/2016/11/20/business/media/how-fake-news-spreads.html? r=1.
[https://perma.cc/G53 Y-DZ9X].
86 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70
delivery of news.'°’ The latest development in this process is the role that
social media can play in accelerating the distribution of a news story.’ An
emerging literature on “digital wildfires” documents the speed at which false
news can travel and seeks to explain the factors that can affect its diffusion.’
The speed of diffusion can be enhanced by technological advances such as
bots (certainly something Brandeis didn’t have to consider) that can operate
on a scale and pace that human false news disseminators cannot!” distribute
fake news in their efforts to influence the 2016 election. !7!

Presumably, legitimate news has the same capacity to travel at equal
speeds to false news today, just as it did in Brandeis” time. However, while
the underlying technological capacity is the same, the troubling reality is that
the rapid dissemination capacity of social media appears more likely to be
brought to bear for false news stories than for true news stories. Recent data
indicate that false news stories are more likely to be shared — and are thus

 

167. See generally HOWARD ROSENBERG & CHARLES S. FELDMAN, No TIME TO THINK:
THE MENACE OF MEDIA SPEED AND THE 24-HOUR NEWS CYCLE (2008).

168. This process dates back to the development of radio, and progresses through the rise
of 24-hour news networks and the dissemination of news online. Jd.

169. For a review, see Helena Webb et al., Digital Wildfires: Propagation, Verification,
Regulation, and Responsible Innovation. 34 ACM TRANSACTIONS ON INFo. Sys. | (Apr. 2016).

170. See Alessandro Bessi & Emilio Ferrara, Social Bots Distort the 2016 US.
Presidential Election Online Discussion, FIRST MONDAY (Nov. 7, 2016),
http://journals.uic.edu/ojs/index. php/fm/article/view/7090, [https://perma.cc/258N-D44N]
(‘Our findings suggest that the presence of social media bots can indeed negatively affect
democratic political discussion rather than improving it, which in turn can potentially alter
public opinion and endanger the integrity of the Presidential election.”), Samuel C. Woolley &
Douglas R. Guilbeault, Computational Propaganda in the United States of America:
Manufacturing Consensus Online, Computational Propaganda Research Project Working
Paper No. 2017.5, Oxford Internet Institute 3 (2017), http://comprop.oil.ox.ac.uk/wp-
content/uploads/sites/89/2017/06/Comprop-USA pdf, [https://perma.cc/K2WM-
RXYC](finding that bots are used to create “the illusion of significant online popularity in
order to build real political support,” and “democratiz[e] propaganda through enabling nearly
anyone to amplify online interactions for partisan ends’).

171. See Gabe O’ Connor & Avie Schneider, How Russian Twitter Bots Pumped Out Fake
News During The 2016 Election, NPR (Apr. 3, 2017),
http://www. npr.org/sections/alltechconsidered/2017/04/03/522503844/how-russian-twitter-
bots-pumped-out-fake-news-during-the-2016-election [https://perma.cc/BR5U-KA4G]
(“When he testified before the Senate Intelligence Committee last week, former FBI agent Clint
Watts described how Russians used armies of Twitter bots to spread fake news using accounts
that seem to be Midwestern swing-voter Republicans”).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 87

likely to spread faster (and farther) — than legitimate news stories.'”? The
explanation for this disparity once again takes us back to the role of
partisanship — in this case the role that partisanship plays in increasing the
likelihood of sharing a partisan news story,'” in combination with the
increased likelihood that a partisan news story is a false news story.!“ The
key implication here, once again, 1s that social media disproportionately favor
fake news over legitimate news.

In the end, given that news has never been able to travel faster and
farther than it can today, it seems reasonable to conclude that the likelihood
of there “be[ing] time” to rely upon counterspeech to counteract false news is
less today than in Brandeis’ era, and perhaps less today than has ever been the
case before, particularly given the other technologically-imposed challenges
that truthful counterspeech faces in counteracting false speech. The end result,
then, is a compounding set of conditions that contributes to a digital media
ecosystem that encourages and facilitates the production, dissemination, and
consumption of false news in ways that the traditional media ecosystem did
not.

IV. IMPLICATIONS

This section considers the broader legal, policy, and political
implications of the arguments developed above, all of which point to a media
environment in which the efficacy of counterspeech is being systematically
undermined.

A. The First Amendment and Falsity

As a starting point, it is worth considering how the arguments
developed here connect with other analyses of if and how First Amendment
jurisprudence has addressed the issue of false news and information. As
Schauer points out, the troubling irony is that First Amendment theory has

 

172. Craig Silverman, This Analysis Shows How Viral Fake Election News Stories
Outperformed Real News On Facebook, BuzzFEED (Nov. 16, 2016),
https: //www.buzzfeed.com/craigsilverman/viral-fake-election-news-outperformed-real-news-
on-facebook?utm_term=.cq7v VRjOK# .tgekXRJOE (“During these critical months of the
campaign, 20 top-performing false election stones from hoax sites and hyperpartisan blogs
generated 8,711,000 shares, reactions, and comments on Facebook. Within the same time
period, the 20 best-performing election stories from 19 major news websites generated a total
of 7,367,000 shares, reactions, and comments on Facebook”), Craig Silverman, Lies, Damn
Lies, and Viral Content 45 (Tow Ctr. for Digital Journalism Tow/Knight Rep.)
http://towcenter.org/wp-content/uploads/2015/02/LiesDamnLies_Silverman_TowCenter.pdf
(observing that “Misinformation is often more viral and spreads with greater frequency than
corrective information”).

173. Jisun An, Daniele Quercia, & Jon Crowcroft, Partisan Sharing: Facebook Evidence
and Societal Consequences, PROCEEDINGS OF THE SECOND ACM CONFERENCE ON ONLINE
SOcIAL NETWORKS 13, 17 (Oct. 2014) (showing that “partisan skew” in the sharing of news
stories on social media “holds not only for high-activity users but also for low-activity ones’).

174. See Starbird, supra note 108.
88 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

seldom grappled with the issue of truth versus falsity; or, in today’s
vernacular, facts versus “alternative facts.” '7 Schauer proceeds to
convincingly demonstrate that, “nearly all of the components that have made
up our free speech tradition . . . in the cases and in the literature, and in the
political events that inspired free speech controversies, have had very little to
say about the relationship between freedom of speech and questions of
demonstrable fact. Implicit in much of that tradition may have been the belief
that the power of the marketplace of ideas to select truth was as applicable to
factual as to religious, ideological, political, and social truth, but rarely is the
topic mentioned.” !’° Continuing in this vein, Schauer distressingly notes,
“although factual truth is important, surprisingly little of the free speech
tradition is addressed directly to the question of the relationship between a
regime of freedom of speech and the goal of increasing public knowledge of
facts or decreasing public belief in false factual propositions.”!””

As a result, the First Amendment has essentially facilitated the type of
speech that, ironically, undermines the very democratic process that the First
Amendment is intended to serve and strengthen. Historically, different
categories of speech have received different levels of First Amendment
protection based upon its relevance and value to the democratic process.!”
For instance, commercial speech receives less First Amendment protection
(and more rigorous restrictions against falsity) than political speech, which
represents the pinnacle of speech protection given its centrality to the
democratic process.!” The irony here is that fake news is a type of speech that
is most directly and irrefutably damaging to the integrity of the democratic
process, yet because it resides within the large and undifferentiated protective
bubble of political speech (where journalism generally resides), it receives (as
long as it is not libelous) the highest level of First Amendment protection.

B. Market Failure in the Marketplace of Ideas

It is also worth considering the troubling state of counterspeech in
relation to the marketplace of ideas metaphor from which it arose, and
whether the increasing inefficacy of counterspeech may cause failure in the
marketplace of ideas. From a strictly economic perspective on the
marketplace of ideas, false speech can be thought of as a negative externality

 

175. For a transcript of the Meet the Press broadcast in which the term was famously
introduced, see Rebecca Sinderbrand, How Kellyanne Conway Ushered in the Era of
“Alternative Facts,” WASHINGTON Post (Jan. 22, 2017),
https: //www. washingtonpost.com/news/the-fix/wp/2017/01/22/how-kellyanne-conway-
ushered-in-the-era-of-alternative-facts/?utm_term=.b633a394a39f. [https://perma.cc/MMC2-
23J6].

176. See Schauer, supra note 46 at 907.

177. Id. at 902.

178. See generally T.M. Scanlon, Jr., Freedom of Expression and Categories of
Expression, 40 U. PITT. L. REV. 519 (1979).

179. See, e.g., Alex Kozinski & Stuart Banner, Who’s Afraid of Commercial Speech?, 76
Va. L. REV. 627 (May 1990).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 89

of free speech,'*° but a negative externality of increasing magnitude, given
counterspeech’s increasing inadequacy as an antidote. In economics, negative
externalities are accepted indicators of market failure.'*!

When considering the implications of the diminished potency of
counterspeech for the effective functioning of the marketplace of ideas, the
presence of such negative externalities raises the question: should the public
be concemed about the possibility of market failure in the marketplace of
ideas? And if so, how does market failure in the marketplace of ideas look?
The prospect and nature of market failure in the marketplace of ideas has
received relatively little discussion, particularly within the context of news
and journalism.!** Economist Ronald Coase, in his landmark comparative
analysis of regulatory perspectives toward the market for goods and the
market for ideas, noted the “results actually achieved by this particular
political system suggest that there is a good deal of ‘market failure’” in the
marketplace of ideas, though he deemed the topic “a large subject on which I
will avoid comment.”!®

In addressing these questions, an important starting point is to consider
some key causes and indicators of market failure. At the general level, a
market failure occurs when the allocation of goods and services are
inefficient. '** Markets for public goods, such as journalism, have proven to
be uniquely prone to market failure.!** Public goods have a tendency to be
under-produced relative to their full value, given the ease with which they can
be shared or consumed without payment.'** Journalism also produces value

 

180. See Richard A. Tybout, Pricing Pollution and Other Negative Externalities, 3 BELL
J. Econ. & Men. Sci. 252 (Spring 1972). Therefore, as Schauer notes in a statement from
2009 that sounds particularly contemporary, “[W]e are left with the conclusion that the
seemingly increased pervasiveness of falsity in public discussion is a phenomenon that may
possibly be a consequence of a strong free speech culture, but is certainly not a phenomenon
that a free speech regime is likely to be able to remedy.” Schauer, supra note 46 at 911-912.

181. See, e.g, Francis M. Bator, The Anatomy of Market Failure, 72 QUARTERLY J. Econ.
351, 3633-371 (1958).

182. For exceptions, see Tamara Piety, Market Failure in the Marketplace of Ideas:
Commercial Speech and the Problem that Won’t Go Away. 41 LOYOLAL.A. L. REV. 181 (2007)
(focusing on market failures in the marketplace of ideas within the specific context of
commercial speech), Gregory Brazeal, How Much Does a Belief Cost? Revisiting the
Marketplace of Ideas. 21 8. CAL. INTERDISC. L.J. 46 (2011). For a more general overview of
forms of market failure that may affect the marketplace of ideas, see Bush, supra note 17, nn.
47-90 and accompanying text, see also C. Edwin Baker, Scope of the First Amendment
Freedom of Speech, 25 UCLA L. REV. 964 (1978) nn 61-83 and accompanying text.

183. See Ronald H. Coase, The Market for Goods and the Market for Ideas, 64 AM. ECON.
REV. 384, 385 (1974).

184. Kenneth A. Shepsle and Barry R. Weingast, Political Solutions to Market Problems,
78 Am. POL. Scl. REV. 417 (1984) (“According to the market failure orthodoxy, inefficiency in
the marketplace provides a prima facie case for public intervention”).

185. See Victor Pickard, The Great Evasion: Confronting Market Failure in American
Media Policy, 31 CRITICAL STUDIES STUD. IN MEDIA CoMM.153, 154 (2014) (“Because public
goods are non-rivalrous (one person’s consumption does not detract from another’s) and non-
excludable (difficult to monetize and to exclude from free nders), they differ from other
commodities, like cars or clothes, within a capitalistic economy’).

186. See Hamilton, supra note 100 at 8 (“A person can consume a public good without
paying for it, since it may be difficult or impossible to exclude any person from consumption”).
90 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

for society as a whole (positive externalities) that often is not captured in the
economic transactions between news organizations and news consumers,
and/or between news organizations and advertisers.'*” All of this leads to
market inefficiency in the form of the underproduction of journalism,'* a
situation only exacerbated by the more challenging economic environment
discussed above.!*

From an economic theory perspective, an informed citizenry and an
effectively functioning democratic process are positive externalities. From a
democratic theory perspective, however, these characteristics are not
peripheral; they are fundamental. Thus, an effectively functioning
marketplace of ideas needs to be assessed according to different standards.
According to Piety, market failures in the marketplace of ideas can be
exemplified by characteristics such as: “(1) the proliferation and acceptance
of false ideas, (2) the suppression of truthful information, (3) the failure to
produce truthful information, and... (4) limitations on choice, and the
channeling of the exercise of preferences within those limitations.”!°° Each of
these characteristics connects fairly clearly to the conditions described
above.'?! For example, items one and two reflect the apparent increasing
prominence and influence potential of fake news and the role of filter bubbles
in inhibiting exposure to legitimate news. '? Item three reflects the
diminishing journalistic capacity of legitimate news organizations. Item four
concerns the operation of algorithmic filter bubbles, and how they tend to
constrict news and information consumption within a narrower range of
options determined by demonstrated preferences.

Some might argue that the increasing production, dissemination, and
consumption of fake news is a reflection of the ways in which technological
changes have allowed the market to more efficiently identify and meet
consumer demand for falsity (the marketplace of ideas essentially becoming
more efficient in serving consumer demand for fake news), rather than a
reflection of consumers’ diminished ability to accurately distinguish between
legitimate and false news.!*} In considering this possibility, the notion that

 

187. Jd at 13 (“... since individuals do not calculate the full benefit to society of their
learning about politics, they will express less than optimal levels of interest in public affairs
coverage and generate less than desirable demands for news about government’).

188. See Pickard, supra note 195 at 155 (“The inadequacy of commercial support for
democracy-sustaining infrastructures suggests what should be obvious by now: the systematic
underproduction of vital communications like journalistic media”).

189. See Downie & Schudson, supra note 76.

190. See Piety, supra note 191 at 189-190.

191. See supra notes 75-180 and accompanying text.

192. See Piety, supra note 191 at 189-190.

193. See Goldman & Cox, supra note 11 at 18 (“The whole idea of economic efficiency
is that the system should be responsive to consumers' tastes or preferences (subject to the limits
of technology), not that it should produce certain goods in comparatively large quantities no
matter what people want. Thus, if consumers have no very strong preference for truth as
compared with other goods or dimensions of goods, then there is no reason to expect that the
bundle of intellectual goods provided and "traded" in a competitive market will have maximum
truth content. If people valued falsehood, then perfect competition would provide falsehood in
a Pareto-optimal way”).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 91

consumer demand for fake news is now being better met is cynical in that it
reflects a grim view of the citizenry, in terms of a conscious desire to be
misinformed. Even the bulk of the literature discussed above delineating the
various cognitive biases that can lead to the consumption and acceptance of
false news and information does not suggest that individuals are consciously
and intentionally seeking false information, but rather that their cognitive
biases lead them to mistakenly embrace false news and information as true.!™

The notion that individuals desire true and accurate information but are
not always capable of making the distinction, reflects a less cynical view of
the citizenry and a reasonable sense of how an idea marketplace actually
functions, given the recognized prominence of “bounded rationality”! in
limiting marketplace efficiency. Further, this perspective represents the more
optimistic (and perhaps naive) normative principle that an effectively
functioning marketplace of ideas facilitates informed democratic decision-
making — something that is presumably incompatible with decisions based
upon false information. As Lidsky argues,

“The ideal of democratic self-governance . . . makes no sense
unless one assumes that citizens will generally make rational
choices to govern the fate of the nation. If the majority of citizens
make policy choices based on lies, half-truths, or propaganda,
sovereignty lies not with the people but with the purveyors of
disinformation. If this 1s the case, democracy is both impossible
and undesirable.'°

Reflecting this position, this analysis operates (perhaps naively and
optimistically — but First Amendment theory is nothing if not somewhat naive
and optimistic) from the perspective that consumers generally prefer
legitimate to false news.

From this perspective, the unintentional consumption of fake news is a
reflection of the bounded rationality of the news consumer, which can be seen
as a function of inadequate information for making determinations as to the
accuracy and reliability of available news sources. Inadequate information is
a recognized source of market failure.’ According to Brazeal, “[i]mperfect
information is arguably the most significant and pervasive source of market
failure in the marketplace of ideas.”!°* A market cannot operate efficiently if

 

194. See, e.g., Olson, supra note 62. (“Humans have an evolutionary tendency towards
gullibility and wanting to believe what people are telling them”).

194. See supra notes 62-63 and accompanying text.

195. See Conlisk, supra note 140.

196. Lidsky, supra note 23 at 839.

197. For a review see Deborah Haas-Wilson, Arrow and the Information Market Failure
in Health Care: The Changing Content and Sources of Health Care Information, 26 J. HEALTH
PoL. Pol’ y & L. 1031, 1034-1037 (2001).

198. See Brazeal, supra note 191 at 32.
92 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

consumers lack the information necessary to make well-informed decisions
about the relative value of the products and services available to them.!*”
Another widely acknowledged source of market failure — both in the
economic marketplace and in the marketplace of ideas — is imperfect
competition.*” From an ideas marketplace standpoint, a lack of competition
fails to provide the “diverse and antagonistic” sources upon which the
marketplace of ideas premise is founded.*”! More relevant to this analysis,
however, is the fact that any biases inherent in the monopolist producers or
distributors of news and information can undermine the extent to which the
news consumers that rely upon them are properly informed.*” A suddenly
more vocal concern in the wake of the 2016 election has been the extent to
which platforms, such as Facebook and Google play such an increasingly
powerful bottleneck role in the dissemination and consumption of news and
information.*"? Such concerns have tended to focus on these platforms’
dominant position in the online advertising marketplace, 7% or their
increasingly dominant position in the emerging data marketplace. *”
However, these platforms’ growing bottleneck position in the dissemination
of news and information has begun to receive more attention — and explicitly
in relationship to the fake news problem that is the focus here. As Sally
Hubbard convincingly argues, “fake news is [fundamentally] an antitrust
problem”, given the powerful intermediary position of Facebook, and the
extent to which the algorithms that underlie the platform can point news

 

199. Id. at 31-32.

200. Id.

201. See Associated Press v. United States, 326 U.S. 1, 20 (1945), (noting that the First
Amendment “rests on the assumption that the widest possible dissemination of information
from diverse and antagonistic sources is essential to the welfare of the public”).

202. See Brazeal, supranote 191 at 31 (“Imperfect competition in the marketplace of ideas
also occurs when the promotion of ideas is subsidized unequally”).

203. See, e.g., Brad Auerbach, Are Amazon, Facebook and Google Monopolies? Are They
Undermining Democracy? Taplin is Persuasive, FORBES (May 26, 2017),
https: //www. forbes.com/sites/bradauerbach/2017/05/26/taplin/#4f7d67d2G6daa,
[https://perma.cc/YHW4-XVYS]; On the Media, The Fight for Antitrust (Sept.ember 22,
2017), https://www.wnyc.org/story/fight-antitrust/, [https://perma.cc/6THS-KR3F].

204. See BitClave, The Facebook-Google Online Ads Duopoly is Bad for Business,
MEDIUM (July 8, 2017), https://medium.com/@BitClave/the-facebook-google-online-ads-
duopoly-is-bad-for-business-fa2 b3 88de8fd [https://perma.cc/E2VZ-B3 VK].

205. See Nick Srnicek, We Need to Nationalise Google, Facebook, and Amazon. Here’s

Why, THE GUARDIAN (Aug. 30, 2017),
https: //www.theguardian.com/commentisfree/20 1 7/aug/30/nationalise-google-facebook-
amazon-data-monopoly-platform-public-interest, [https://perma.cc/HG3K-S8KN].

https: //www.theguardian.com/commentisfree/2017/aug/30/nationalise-google-facebook-
amazon-data-monopoly-platform-public-interest, [https://perma.cc/HG3K-S8KN].
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 93
consumers toward fake news and away from legitimate news organizations.2”°
The extent to which so many news consumers are relying upon these same
algorithms (and whatever flaws or biases are baked into them) provides the
baseline from which the damage to the marketplace of ideas emerges.

C. The 2016 Presidential Election as Market Failure Case Study

In light of these market failure concerns, a looming question is whether
the results of the 2016 presidential election represent a case study of market
failure in the marketplace of ideas. Perhaps this is a way to make sense of an
election outcome that baffled and blind-sided many journalists, political
analysts, and voters**’ — and that took place within a media ecosystem that
has changed significantly in the years since the 2012 presidential election.
Certainly, there are other equally (and perhaps even more) plausible
explanations for this outcome (discussed below). The question being posed
here is whether market failure in the marketplace of ideas, as a byproduct of
the increased inefficacy of counterspeech, represents another potentially
plausible explanation.

In considering the increasing challenges discussed above that not only
news consumers, but news producers and (perhaps most importantly)
distributors face in discerning between real and fake news, there is an
“information asymmetry” — a classic cause of market failure — between the
creators and the distributors and consumers of news. This is a problem
potentially compounded by the “imperfect competition” scenario described
above. And in considering the consumption of fake news as a negative
externality, then there is a potential indicator of market failure. However, to
truly accept the consumption of fake news as a negative externality, one must
consider its negative consequences. Given that the idea marketplace is
intended to facilitate well-informed decision-making, if there is evidence of
poorly-informed decision-making, then that could potentially be seen as
evidence of market failure.

Well-informed voting decisions have been defined by many political
analysts in terms of the extent that citizens vote in ways that reflect their best

 

206. See Sally Hubbard, Why Fake News is an Antitrust Problem, FORBES (Jan. 10, 2017),
https: //www.forbes.com/sites/washingtonbytes/2017/01/10/why-fake-news-is-an-antitrust-
problem/#4c557dc730f1, [https://perma.cc/P8GP-TFGM] (“When viewed through an antitrust
lens, news publishers are Facebook’s competitors. They compete for users’ time spent online,
user data and advertising dollars. .. . Indeed, competitive biases baked into Facebook’s design
deserve a healthy portion of the responsibility for the nse of fake news. By pulling
technological levers that keep users on its platform, thereby lessening clicks to news
publishers’ sites, Facebook has sped the decline of legitimate news and provided a breeding
ground for the fake variety’).

207. See, e.g., Susan Davis and Scott Detrow, A Year Later, the Shock of Trump’s Win
Hasn't Totally Worm Off in Either Party, NPR (2017, Nov. 9),
https://www.npr.org/2017/11/09/562307566/a-year-later-the-shock-of-trumps-win-hasn-t-
totally-worn-off-in-either-party, Shane Goldmacher and Ben Schreckinger, Trump Pulls Off
Biggest Upset in US. History, POLITICO (2016, Nov. 11),
https://www. politico.com/story/2016/11/election-results-2016-clinton-trump-23 1070,
94 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

interests.*°° Economic approaches, in particular, have emphasized the role of
self-interest, 1.e., that voters will vote for those candidates whose policy
positions are likely to benefit them the most.?” And, it should be emphasized
that this notion of self-interest has been conceptualized not purely in terms of
narrow, short-term economic self-interest, but more broadly as well, to
accommodate family and social network affinities.?!°

There are a variety of competing theoretical perspectives that seek to
explain the dynamics of voting behavior. Other theoretical perspectives
emphasize the “expressive” dimension of voting, ?!! or the inherent
irrationality of voting that is a function of the negligible likelihood of rational
voting behavior having a meaningful impact.?"? The market failure argument
being put forth here in reference to the 2016 election does not reflect these
theoretical perspectives, but is rather an extension of the self-interested voter
hypothesis described above, which, it should be noted, has received strong
empirical support in recent research.?°

There have similarly been a variety of competing perspectives offered
to explain the results of the 2016 presidential election. Some of these
explanations have emphasized the likelihood that voters were motivated

 

208. For an overview of this perspective, see generally Gordon Tullock, On Voting: A
Public Choice Approach (1998).

209. See Bryan Caplan, The Myth of the Rational Voter 18 (2007) (“[M]ost economists .
. . compare voters to consumers who shrewdly ‘vote their pocketbooks”).

210. See Jason Weeden & Robert Kurzban, The Hidden Agenda of the Political Mind:
How Self-Interest Shapes Our Opinions and Why We Won’t Admit It 39-40 (2014) (Arguing
that “it’s probably best to jettison the term ‘self-interest’ altogether... [and] refer to ‘inclusive
interests.’ Something is in a person’s ‘inclusive interests’ when it advances their or their family
members’ everyday, typical goals,” as well as those of “their fnends, allies, and social
networks”).

211. See Geoffrey Brennan and Loren Lomasky, Democracy & Decision: The Pure
Theory of Electoral Preference (1993) 15-16 (contending that because “electoral outcome is
detached from electoral ‘choice’ for each voter,” voting becomes a form of “expressive
behavior [that reflects] various kinds of ethical and ideological principles that are suppressed
in the market setting. Politics, therefore, gives much freer range to ethical considerations than
do markets”).

212. See Caplan, supra note 225 at 3 (arguing that “Voter irrationality is precisely what
economic theory implies once we adopt introspectively plausible assumptions about human
motivation’).

213. See Weeden & Kurzban, supra note 226 at 203 (“The key debate in these discussions

..1s how much interests matter in driving political opinions. In chapter 2 we responded to
claims that self-interest hardly matters: When we run simple tests of these simple claims, quite
often the simple claims are simply untrue”).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 95

primarily by informed self-interest.?!4 Others have emphasized factors, such
as frustration with the entirety of the political system (i.e., a desire to “blow
up the status quo” in protest),?!° or prejudices, such as racism?!* and sexism.?!7

An additional possibility is that the 2016 election represented a case of
market failure in the marketplace of ideas. Under this scenario, some segment
of self-interested voters was sufficiently ill-informed (1e., “boundedly
rational”) due to the changing conditions in the media ecosystem described
above that they failed to vote in a way that reflected their best interests, an
outcome that is associated with market failure. This market failure outcome
is premised upon the substantial body of analysis that has been produced in
the wake of the election that has repeatedly demonstrated that many
categories of voters who voted for Donald Trump are actually those most

 

214. See Robert Kurzban & Jason Weeden, No, Trump Voters Were Not Irrational,
WASHINGTON PosT (Nov. 9, 2016), _ https://(www.washingtonpost.com/news/in-
theory/wp/2016/11/09/no-trump-voters-were-not-irrational/?utm_term=.45ad6fae23c6,
[https://perma.cc/QU7H-4A3U] (arguing that white, blue collar voters voted for Trump not
“because they’ re irrational, but because they are self-interested — something generally true of
voters on both sides”) , see also David Goodhart, White Self-Interest is not the Same Thing as
Racism, AMERICAN RENAISSANCE (Mar. 2, 2017),
https://www.amren.com/news/2017/03/white-self-interest-not-thing-racism/,
[https://perma.cc/JB4A-JM33]; Ned Barnett, Duke Professor Dispels Myth About Trump and
Working Class Voters, THE NEWS-OBSERVER (Jun. 10, 2017),
http://www.newsobserver.com/opinion/opn-columns-blogs/ned-
barnett/article 155509549 html [https://perma.cc/U87C-AKMP].

215. See Daniel Henninger, The Trump Question, WALL STREET JOURNAL (Jan. 18, 2017),
https://www. wsj.com/articles/the-trump-question-1484784436 (“It is said that the Trump
electorate wanted to blow up the status quo”).

216. See generally Sean McElwee & Jason McDaniel, Economic Anxiety Didn’t Make
People Vote Trump, Racism = Did THE NATION (May 8, 2017),
https: //www.thenation.com/article/economic-anxiety-didnt-make-people-vote-trump-racism-
did’, [https://perma.cc/2K AH-97U4] (“Our analysis shows Trump accelerated a realignment in
the electorate around racism, across several different measures of racial animus—and that it
helped him win. By contrast, we found little evidence to suggest individual economic distress
benefited Trump”).

217. See Carl Bialik, How Unconscious Sexism Could Help Explain Trump’s Win,
FIVETHIRTYEIGHT (January 21, 2017), https://fivethirtyeight.com/features/how-unconscious-
sexism-could-help-explain-trumps-win/, [https://perma.cc/)WM6E-DCLM] (“an important
obstacle to the first woman president remains: the hidden, internalized bias many people hold
against career advancement by women. And perhaps surprisingly, there is evidence that women
hold more of this bias, on average, than men do”).
96 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

likely to be harmed by his policies.7!* These analyses have concluded, for
instance, that elderly and rural voters (two demographics who were strong
Trump supporters) face the greatest economic harms from Trump policy
initiatives such as the repeal of the Affordable Care Act, the abandoning of
the Trans-Pacific Partnership, and dramatic cuts to Medicaid and agriculture
subsidies.*”? Such patterns may reflect that the role of partisan affiliation in
contemporary voting decisions has become largely disconnected from the
associated policy positions of the candidates,*° which is evidence of the
Spiral of Partisanship phenomenon discussed above.””!

If we accept the conclusions of these analyses (for arguments sake) that
there was an unusual degree of voter failure to engage in self-interested voting
behaviors, then this could reflect the possibility that a segment of voters
lacked adequate information to accurately determine the voting decision that
best reflected their self-interest. From the standpoint of a politically-oriented
analysis of the operation of the marketplace of ideas, such indicators of voters
failing to vote in their best interests, possibly due to false or inadequate
information (through the spread of fake news, which was facilitated by the

 

218. See, e.g., Martha C. White, Trump Voters Stand to Suffer Most from Obamacare
Repeal and Trade War. NBC NEws (Feb. 6, 2017)
http://www.nbenews.com/business/business-news/trump-voters-stand-suffer-most-
obamacare-repeal-trade-war-n717491 [https://perma.cc/HWU7-PP8N]; Paul Krugman, Coal
Country Is a_ State of Mind NEw York TIMES, (Mar. 31, 2017)
https://www.nytimes.com/2017/03/31/opinion/coal-country-is-a-state-of-mind html,
[https://perma.cc/9AGM-ZLBY]; Andrew Restuccia et al., Trump Releases Budget Hitting His
Own Voters Hardest, POLITICO (May 22, 2017),
http://www. politico.com/story/2017/05/22/trump-budget-cut-social-programs-23 8696,
[https://perma.cc/8JW9-AHRU],; Amanda Taub, Why Americans Vote “Against Their
Interest’: Partisanship. NEW YORK TIMES (Apr. 12, 2017),
https://www.nytimes.com/2017/04/12/upshot/why-americans-vote-against-their-interest-
partisanship.html? 1-0, [https://perma.cc/3 VEG-7GRS] ; Catherine Rampell, Why the White
Working Class Votes Against Itself, WASHINGTON PosT (December 22, 2016)
https://www. washingtonpost.com/opinions/why-the-white-working-class-votes-against-
itself/2016/12/22/3aa65c04-c88b-1 1e6-8bee-
54e800ef2a63_ story. html?utm_term=.99d233ea82fb, [https://perma.cc/EW5N-NX22], Neil
H. Buchanan, Why Did So Many Americans Vote to Be Poorer? NEWSWEEK (January 15, 2017),
http://www.newsweek.com/neil-buchanan-why-did-so-many-americans-vote-be-poorer-
542453, [https://perma.cc/E9V7-C5LN]; Neil Macdonald, 7rump’s Poor and Rural Supporters
Line Up to Take their Economic Beating CBC News (April 5, 2017),
http://www.cbe.ca/news/opinion/americans-voting-for-cuts-1.4055389,
[https://perma.cc/TGP8-A58M].

219. See White, supra note 234 (“Donald Trump’s most ardent supporters are likely to be
hit the hardest if he makes good on his promise to dismantle the Affordable Care Act and
embark on trade wars with China and Mexico”); Restuccia et al., supra note 218 (“Donald
Trump, whose populist message and promises to help American workers propelled him to the
White House, issued a budget proposal on Tuesday that instead takes aim at the social safety
net on which many of his supporters rely”).

220. See Taub, supra note 234 (“Why do people vote against their economic interests?
The answer, experts say, is partisanship. Party affiliation has become an all-encompassing
identity that outweighs the details of specific policies’).

221. See supra notes 128-131 and accompanying text.
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 97

economic and technological conditions outlined above), could be seen as
evidence of market failure.”

Whether or not one accepts this explanation as the cause of the 2016
election results, it still seems worth considering the ramifications of the
market failure in the marketplace of ideas concerns being raised here.
Accepting this possibility highlights the danger inherent in the
institutionalized confidence in truth to overcome falsity that is endemic of
First Amendment theory. It may very well be that the media ecosystem has
evolved in such a manner that the gap between normative theory and
empirical reality is no longer just a gap, but something much greater and more
dangerous.

D. The Future of Counterspeech and the Marketplace of Ideas

Even if this market failure argument remains unconvincing, it seems
necessary that, going forward, First Amendment jurisprudence and the
operational decision-making of social media platforms, recognize the more
limited efficacy of counterspeech within the context of the operation social
media platforms. It seems appropriate that, within the context of news on
social media, the counterspeech doctrine should receive the same kind of
more circumspect and limited application that has been advocated for in
speech contexts, such as hate speech?” and adopted by the courts in contexts
such as libel.*** The Supreme Court’s recognition that “false statements of
fact” are particularly resistant to counterspeech*** needs to extend beyond the
context of individual reputation that provided the basis for that decision. In
sum, the analytical frameworks of policymakers and the courts, and the
governance approaches taken by social media platforms, need to take into
account that the dissemination and consumption of news in the increasingly
social-mediated online environment (what we might term the algorithmic
marketplace of ideas) merits inclusion amongst those speech contexts in
which reliance on counterspeech is increasingly ineffectual and potentially
damaging to democracy.

In the end, perhaps this discussion illustrates a larger problem, which is
the extent to which the application of First Amendment theory has tended to
conflate the marketplace of ideas with what should perhaps be termed the
marketplace of facts, particularly in relation to the role and function of
journalism. The “ideas” terminology contains an inherent embrace of
subjectivity, analysis, and opinion that reflects some, but not all, of the
functionality of journalism in a democracy. A fundamental dimension of
journalism is to provide factual information to facilitate informed decision-

 

222. In this scenario, the decision by some voters to vote for Donald Trump is essentially
the marketplace equivalent of purchasing a lemon, see Akerlof, supra note 138.

223. See Delgado and Yun, supra note 69.

224. See, e.g., Hustler Magazine, Inc. v. Falwell, 485 U.S. 46 (1988).

225. Id. at 52.
98 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

making.**° To the extent that this functionality is folded into the broader
marketplace of ideas metaphor, the result is something of a
mischaracterization of this aspect of journalism’s function.??”7 One could
argue that the very notion of facts competing for acceptance in the
marketplace in the same way as ideas fundamentally undermines the very
meaning of the term “fact” as something “that is indisputably the case.” In
any case, the end result is that mtentional disinformation under the guise of
journalism receives a degree of First Amendment protection that is not
afforded to other categories of false speech; this despite the Supreme Court’s
explicit statement that “there is no constitutional value in false statements of
fact.”°

From this standpoint, it is encouraging that, in the wake of the 2016
election, there has been a dramatic increase in efforts by the news aggregators
and social media platforms that played central roles in the dissemination of
fake news to alter their policies and procedures in ways intended to combat
the spread of fake news. Thus, platforms, such as Google and Facebook, have
dropped fake news sites from their ad networks.**° Facebook and Google have
created initiatives to integrate fact-checking and content labeling from third
parties into their presentation of news stories to users.**! There have been
more concerted efforts to shut down disguised social media accounts
operating as fronts for disinformation efforts.***

Initiatives such as these address the growing need for “tools of truth
recognition” that operate “independent of the market in order for the market
to be optimal.”**3 Such efforts can be seen as working to reduce the
“transaction costs”?*4 associated with evaluating the reliability of news
sources, and thereby addressing the information asymmetry that is the
fundamental cause of the postulated market failure in the marketplace of

 

226. See Irene Costera Meijer, The Public Quality of Popular Journalism: Developing a
Normative Framework, 2 JOURNALISM STUD.189, 189 (2001) (“Informing citizens in a way that
enables them to act as citizens has traditionally been the responsibility of the press”), Mark
Cooper, The Future of Journalism: Addressing Pervasive Market Failure with Public Policy,
WILL THE LAST REPORTER PLEASE TURN OUT THE LIGHTS, 320, 322 (2011) (“The core concept
of the monitorial role involves the journalist serving as a neutral watchdog, rather than a
partisan participant, holding social, economic, and political actors to account by presenting
facts rather than advocating positions and offering opinions”).

227. Fora discussion of the Supreme Court’s failure to develop adequate mechanisms for
distinguishing fact from opinion as it relates to journalistic output, see Robert Neal Webner,
The Fact-Opinion Distinction in First Amendment Libel Law: The Need for a Bright-Line Rule.
72 Geo. L. J. 1817 (1984).

228. See Google Dictionary (https://www.google.com/#q=fact&spf=14973654 12638).

229. See Gertz v. Robert Welch, Inc., 418 U.S. 323, 339-40 (1973).

230. See Silverman, supra, note 98.

231. See Bell, supra note 167.

232. See Stretch, supra note 167 at 4 (“we incorporated what we learned from the 2016
election in our detections systems, and as a result of these improvements, we disabled more
than 30,000 accounts in advance of the French election”).

233. See Goldman and Cox, supra notel1 at 23.

234. For a discussion of transaction costs in the marketplace of ideas, see Blocher, supra
note 140 at 852-60.
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 99

ideas. Going forward, these and other initiatives need to be evaluated in terms
of the extent to which they address one or more of the six changes outlined
above that have affected the marketplace of ideas in ways that have increased
the ability of false news to undermine legitimate news.

Of course, such efforts by news aggregators and social media platforms
raise the specter of further empowering already-powerful digital media
bottlenecks, such as Facebook, Twitter, Google, and YouTube. The irony in
this scenario is the extent to which it reflects a transition back towards the
limited number of powerful gatekeepers that characterized the pre-
fragmentation mass media era, but in a technological context in which many
of the barriers to entry characteristic of the mass media era are no longer
present. The mass media era was accompanied by critiques about
concentration of ownership and the accompanying systemic homogeneity of
viewpoints. **° These critiques gave rise to concerns about the production and
influence of propaganda that are similar to the concerns that underlie the
current fake news scenario. **° Given the extent to which different
technological contexts seem to be leading to surprisingly similar institutional
structures, it is tempting to conclude that a media ecosystem comprised of a
fairly limited number of powerful gatekeepers is an inevitability, borne of
larger mstitutional and economic forces, as well as nate audience behavior
tendencies.”2’

Fortunately, from a journalistic standpoint, it is also the case that the
mass media era of few, powerful gatekeepers cultivated a stronger “public
service ethos” than has been present since technological change facilitated
increased fragmentation and competition, and an associated need for news
organizations to prioritize audience and revenue maximization over public
service.*** Of course, within some media sectors (e.g., broadcasting), this
public service ethos could be attributed, at least n part, to a government-
imposed public interest regulatory framework.** In any case, one of the most
distressing aspects of contemporary social media gatekeepers is the extent to

 

235. See, eg., Edward S. Herman & Noam Chomsky, Manufacturing Consent: The
Political Economy of the Mass Media (1988).

236. Idat 1-36 (developing a “propaganda model” of the mass media).

237. For an historical description of evolutionary patterns in the media and
telecommunications sectors that support this argument, see Tim Wu, The Master Switch: The
Rise and Fall of Information Empires (2010) at 6 (illustrating that each communications
technology became “a highly centralized and integrated new industry” and that “Without

exception, the brave new technologies of the twentieth century .. . eventually evolved into
privately controlled industrial behemoths, the ‘old media’ giants of the twenty-first, through
which the flow and nature of content would be strictly controlled . . . History also shows that

whatever has been closed too long is ripe for ingenuity’s assault: in time a closed industry can
be opened anew, giving way to all sorts of technical possibilities and expressive uses for the
medium before he effort to close the system likewise begins again”).

238. Foran account of the increased emphasis on audience and revenue maximization that
took hold in journalism in the 1980s and 1990s, see John H. McManus, Market-Driven
Journalism: Let the Citizen Beware? (1994).

239. See Napoli, supra note 123 at 753 (“. . . articulations of public interest principles
inherent in the professional practice of journalism parallel, to some extent articulations of the
public interest that are found in the realms of media regulation and policy.”).
100 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

which they have originated and evolved from a technology sector milieu in
which the journalistic norms and/or regulatory framework associated with the
public interest and social responsibility have been largely foreign to them.*”°

Moving forward, then, perhaps the most essential development is that
these new gatekeepers evolve in such a way as to absorb and implement a
more robust public service ethos that is reflective of the institutional
responsibilities associated with serving as an essential gatekeeper to the news
and information necessary for an effectively functioning democracy. In the
aftermath of the 2016 election, and the associated critiques of social media
platforms and their role in disseminating fake news, it is certainly evident that
things are moving in this direction.4! Efforts by search engines and social
media platforms, such as Facebook and Google, to work with established and
reputable fact-checking organizations to identify and label fake news stories,
and to figure out ways at which such fact-checking and verification can
operate the scale necessary for social media seem particularly promising.?”?
However, it seems important that such collaborations go beyond mere content
labeling, and that the editorial discretion ascribed to these platforms under
Section 230 of the Telecommunications Act of 19967" be put to use to filter
out false news in the same way that this discretion has long been used to filter
out other types of harmful speech such as hate speech and pornography.
Indeed, the demonstrated commitment to counterspeech that has been

 

240. See, e.g., Philip M. Napoli & Robyn Caplan, Platform or Publisher? 44 INTERMEDIA
26, 27 (2017) (“One challenge in this regard, however, is a fundamentally different set of
institutional perceptions that are being cultivated around social media platforms.”), Emily Bell,
We Can’t Let Tech Giants, Like Facebook and Twitter, Control Our News Values, THE
GUARDIAN (Aug. 31, 2014), https://www.theguardian.com/media/media-
blog/2014/aug/31/tech-giants-facebook-twitter-algorithm-editorial-values,
[https://perma.cc/T8BQ-SL66] (“Platforms that want public trust should be employing many
more journalists than they presently do and using their knowledge to imbue automated process
with values... . Accountability is not part of Silicon Valley’s culture. But surely as news moves
beyond paper and publisher, it must become so.”).

241. See, e.g, Fidji Simo, Introducing the Facebook Journalism Project (Jan. 11, 2017),
https://media.fb.com/2017/01/11/facebook-journalism-project/, [https://perma.cc/V59V-
S5CLA]; Mark Zuckerberg, Building Global Community (Feb. 17, 2017),
https: //www.facebook.com/notes/mark-zuckerberg/building-global-
community/10154544292806634/, [https://perma.cc/PMA9-S72D] (Among the questions
Zuckerberg raises for Facebook is “How do we help people build an informed community that
exposes us to new ideas and builds common understanding in a world where every person has
a voice?”).

242. See Samuel Gibbs, Google to Display Fact-Checking Labels to Show if News is True
or False, THE GUARDIAN: TECH (Apr. 7, 2017, 11:37 AM),
https: //www.theguardian.com/technology/2017/apr/07/goo0gle-to-display-fact-checking-
labels-to-show-if-news-is-true-or-false, [https://perma.cc/M4RV-DH25]; Eile Hunt, ‘Disputed
by multiple fact-checkers’: Facebook Rolls Out New Alert to Combat Fake News, THE
GUARDIAN: TECH (Mar. 21, 2017, 8:37 PM),
https://www.theguardian.com/technology/2017/mar/22/facebook-fact-checking-tool-fake-
news, [https://perma.cc/34GB-5GS5H]. ; Samuel Gibbs, Google to Display Fact-Checking
Labels to Show if News is True or False, THE GUARDIAN (Apr. 7, 2017),
https: //www.theguardian.com/technology/2017/apr/07/google-to-display-fact-checking-
labels-to-show-if-news-is-true-or-false.

243. 47U SC. § 230.
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 101

articulated by social media platforms such as Facebook, YouTube, and
Twitter“ needs to be tempered and surpassed by a greater commitment and
editorial responsibility toward truth and accuracy that is reflective of our most
reputable journalistic institutions.“

It is unclear at this point, however, whether the efforts put forth by
social media platforms reflect a politically savvy (and perhaps temporary)
response to the current moment of increased scrutiny, or whether these efforts
represent the starting point for much-needed and more substantial institutional
change. If it 1s the former, then with the key question is if or how government
intervention might be an appropriate response. Other countries have already
begun heading down this path. Germany, for instance, recently adopted a law
that requires social media platforms to remove stories identified as fake news
(along with other content types, such as hate speech and child pornography),
or face government-imposed fines of up to 50 million Euros. *“° Such
approaches, of course, raise the contentious question of who should be in the
position of making judgments as to what constitutes fake news.

In the U.S., given the indiscriminate and politicized ways in which the
fake news label is being applied by governmental actors,” the prospect of
establishing an objective, reliable, and widely-trusted arbiter of fake news
within a government agency seems more dangerous now than perhaps at any
time in recent U.S. history.

It is perhaps worth remembering that, within fairly narrow
technological contexts (e.g., broadcasting), a precedent for regulatory
intervention in response to false news reporting has been established.

 

244. See, e.g., Bartlett & Krasodomski-Jones supra note 55, at 5, TweeSurfing supra note
58, ONLINE CIVIL COURAGE INITIATIVE, supra note 56.

245. See, e.g., Robyn Caplan, Like it or Not, Facebook is Now a Media Company, NEW
YorK TIMES (May 17, 2016), https:/www.nytimes.com/roomfordebate/2016/05/17/1s-
facebook-saving-journalism-or-ruining-it/like-it-or-not-facebook-is-now-a-media-company,
[https://perma.cce/ZY Y9-VDLK], Seth Fiegerman, Dear Facebook, You're a Media Company
Now. Start Acting Like One, MASHABLE: BUSINESS (May 15, 2016),
http://mashable.com/2016/05/15/facebook-media-company/#zOF0ooxw0aqo
[https://perma.cc/25PB-Y366; Seth Fiegerman, Dear Facebook, You’re a Media Company
Now. Start Acting Like One, MASHABLE: BUSINESS (May 15, 2016), [https://perma.cc/25PB-
Y366].

246. See Staff, Germany Approves Plan to Fine Social Media Firms Up to 50 Million
Euros, THE GUARDIAN (June 30, 2017),
https://www.theguardian.com/media/2017/jun/30/germany-approves-plans-to-fine-social-
media-firms-up-to-50m. [https://perma.cc/_L6EW-TKF9].

247. See Lloyd Grove, How Will the Media Fight the Right’s Weaponization of “Fake
News,” THE DAILY BEAST, (Jan. 11, 2017), http:/Awww.thedailybeast.com/how-will-the-
media-fight-the-n ghts-weaponization-of-fake-news/ [https://perma.cc/HBY6-QFR7] (“. . . the
term ‘fake news’—the enduring catchphrase of the 2016 presidential campaign, initially used
to describe made-up tales and internet hoaxes that tended to benefit Trump and damage Hillary
Clinton—is fast becoming the nascent Trump administration’s rightwing-populist bludgeon to
delegitimize the purveyors of real news” [emphasis in original].),; see also Wardle &
Derakhshan, supra note 75 at 5 (“the term has also begun to be appropriated by politicians
around the world to describe news organizations whose coverage they find disagreeable. In this
way, it’s becoming a mechanism by which the powerful can clamp down upon, restrict,
undermine and circumvent the free press’).
102 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

Specifically, current FCC regulations prohibit broadcast licensees from
knowingly broadcasting false information conceming a crime or catastrophe,
if the licensee also knows beforehand that “broadcasting the information will
cause substantial ‘public harm.’”?4* This public harm must begin immediately
and cause direct and actual damage to the property, health, or safety of the
general public, or divert law enforcement or public health and safety
authorities from their duties.”

In addition, since the late 1960s, the Federal Communications
Commission (“FCC”) also has maintained a more general policy that it will
“imvestigate a station for news distortion if 1t receives documented evidence
of such rigging or slanting, such as testimony or other documentation, from
individuals with direct personal knowledge that a licensee or its management
engaged in the intentional falsification of the news.’?°° According to the FCC,
“of particular concern would be evidence of the direction to employees from
station management to falsify the news. However, absent such a compelling
showing, the Commission will not intervene.” *! News distortion
investigations have been rare (especially since the deregulatory trend that
began in the 1980s), and seldom have led to any significant repercussions for
broadcast licensees.?

Of course, the nature of the regulatory rationales that have traditionally
applied to broadcasting (spectrum scarcity, pervasiveness) generally do not
apply to a technological context such as social media. 7? However,
discussions about possible regulatory interventions into the social media

 

248. See Federal Communications Commission, Broadcasting False Information
(November 3, 2015), _ http://transition.fcc.gov/cgb/consumerfacts/falsebroadcast.pdf.,
[https://perma.cc/4PJU-GVLS].

249. Id.

250. See Federal Communications Commission, The Public and Broadcasting (July,
2008), https://www.fec. gov/media/radio/public-and-broadcasting# DISTORT,
[https://perma.cc/FZX9-QFWV].

251. Id.

252. See Chad Raphael, The FCC’s Broadcast News Distortion Rules: Regulation by
Drooping Eyelid, 6 CoMM. L. & PoLicy 485 (2001) (Arguing that the FCC’s news distortion
regulations are more symbolic than genuine). See also William B. Ray, FCC: The Ups and
Down of Radio-TV Regulation at 31 (1990) (“On the whole, the commission has done less to
carry out its stated policies regarding news broadcasting than in any other field”).

253. For a detailed discussion of established rationales for U.S. media regulation, the
distinction between regulatory rationales and motivations, and the significance of this
distinction for possible regulatory responses to issues related to social media, see Philip M.
Napoli, Bridging the Disconnect Between Digital Media and the Public Interest, Paper
Presented at the XVIII Nordic Political Science Congress, Odense, Denmark (August, 2017).
Issue 1 FAKE NEWS AND THE FILTER BUBBLE 103
space have gained some momentum of late,”
the role of social media in the 2016 elections having recently taken place.
Given these indicators of potential shifts m the political environment, it is
important to recognize that concerns about fake news have an established, if
not modest and somewhat forgotten, foothold in the U.S. media regulatory
framework.

Ultimately, though, it is important to acknowledge that the current
political environment lends strength to the First Amendment tradition that has
placed the judgment of truth and falsity in the realm of political speech
completely outside the bounds of government authority,?°° and points us back
to what might — at least for the time being — be considered the lesser of two
evils — the need for today’s dominant digital gatekeepers to more aggressively
impose editorial authority in ways that reflect well-established norms of
journalistic service in the public interest.?*”

with congressional hearings on
235

V. CONCLUSION

The goal here has been to consider how the evolution of the news
ecosystem has undermined legitimate news’ ability to overcome fake news.
This argument builds upon a body of critique of the counterspeech doctrine
that is grounded in the persistent psychological and cognitive tendencies in
news consumption that also undermine the efficacy of counterspeech.*°* From
this standpoint, it may be that the news ecosystem, as previously constructed,
has helped to protect citizens, to some extent, from some of their innate flaws
and biases as news consumers.

 

254. See, e.g., Lincoln Caplan, Should Facebook and Twitter be Regulated Under the First
Amendment? WIRED (November 11, 2017), https://www.wired.com/story/should-facebook-
and-twitter-be-regulated-under-the-first-amendment/, [https://perma.cc/83HM4-P4HB];, John
Herrmann, What If Platforms Like Facebook are Too Big to Regulate? N.Y. TIMES (October 4,
2017), https://www.nytimes.com/2017/10/04/magazine/what-if- platforms-like-facebook-are-
too-big-to-regulate html, [https://perma.cc/RD3R-NNY7]; Sally Hubbard, Why Fake News is
an Antitrust Problem, Vox (September 23, 2017),
https://www.vox.com/technology/2017/9/22/16330008/facebook-google-amazon-monopoly-
antitrust-regulation, [https://perma.cc/EGSW-2K5G].

255. See Extremist Content and Russian Disinformation Online: Working with Tech to
Find Solutions, Hearing Before the S. Comm. on the Judiciary, Subcomm. on Crime and
Terrorism, 115" Cong. (Oct. 31, 2017), https://www judiciary.senate.gov/meetings/extremist-
content-and-russian-disinformation-online-working-with-tech-to-find-solutions
[https://perma.cc/42VE-5HSD]; Social Media Influence in the 2016 United States Elections,
Hearing Before the 8S. Select Comm on Intelligence (Nov. 1, 2017),
https: //www intelligence.senate.gov/hearings/open-hearing-social-media-influence-2016-us-
elections [https://perma.cc/K65 Y-KAQ4], Russia Investigative Task Force Open Hearing with
Social Media Companies, Hearing before the H. Permanent Select Comm. on Intelligence
(Nov. 1, 2017), _ https://intelligence house .gov/calendar/eventsingle.aspx?EventI D=814
[https://perma.cc/8DYT-QRJU].

256. See Thomas v. Collins, 323 U.S. 516, 545 (1945) (Jackson, J., concurring) (“every
person must be his own watchman for truth, because our forefathers did not trust any
government to separate the true from the false for us”).

257. For a discussion of journalistic norms of public service and their applicability to
social media platforms, see Napoli, supra note 123.

258. See Bambauer, supra note 62.
104 FEDERAL COMMUNICATIONS LAW JOURNAL Vol. 70

And it may be that the contemporary news ecosystem has been doing
the exact opposite. The end result may be a state of market failure in the
marketplace of ideas. Consequently, this Article has suggested social media
platforms, content aggregators, policymakers, and the courts temper their
commitment to counterspeech. This Article has also suggested that these
platforms adopt a greater institutional commitment to a public interest-
grounded approach to content filtering, in keeping with the editorial
responsibilities that have characterized previous generations of news
organizations. In the end, counterspeech can no longer function as a viable
assumption when considering the current dynamics of the social media-based
flow of news and information.
