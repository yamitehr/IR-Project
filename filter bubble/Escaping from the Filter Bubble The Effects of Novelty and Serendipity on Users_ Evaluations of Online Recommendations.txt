ResearchGate

See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/272723200

Escaping from the Filter Bubble? The Effects of Novelty and Serendipity on
Users’ Evaluations of Online Recommendations

Conference Paper: December 2014

CITATIONS READS
34 1,124

4 authors, including:

Christian Matt Alexander Benlian
@ Universitat Bern Technische Universitat Darmstadt
104 PUBLICATIONS 3,613 CITATIONS 255 PUBLICATIONS 8,156 CITATIONS

SEE PROFILE SEE PROFILE

Thomas Hess
Ludwig-Maximilians-University of Munich
555 PUBLICATIONS 11,152 CITATIONS

SEE PROFILE

Some of the authors of this publication are also working on these related projects:

Project Research on Interaction Dynamics on Software Platform Ecosystems View project

Project Research Project on Digital Transformation of Corporations View project

All content following this page was uploaded by Thomas Hess on 05 January 2019.

The user has requested enhancement of the downloaded file.
Escaping from the Filter Bubble? The Effects
of Novelty and Serendipity on Users’
Evaluations of Online Recommendations
Completed Research Paper

Christian Matt Alexander Benlian
LMU Munich TU Darmstadt
Ludwigstr. 28, Hochschulstr. 1
80539 Munich, Germany 64289 Darmstadt, Germany
matt@bwl.lmu.de benlian@ise.tu-darmstadt.de
Thomas Hess Christian WeiB
LMU Munich LMU Munich
Ludwigstr. 28, Ludwigstr. 28,
80539 Munich, Germany 80539 Munich, Germany
thess@bwl.lmu.de weiss.christian@campus.|mu.de
Abstract

Recommender systems aim to support users in identifying the most relevant items.
However, there are concerns that recommenders may imprison users in a “filter bubble”
by recommending items predominantly known to them. On the other hand, providing
unconventional items may increase risks of not meeting users’ taste. Given this trade-off,
we analyze the effects of consumers’ perceived levels of recommendation novelty and
serendipity on perceived preference fit and enjoyment. We find that merely increasing
the level of novel recommendations is disadvantageous. Instead, recommenders should
provide more serendipitous recommendations as this leads to higher perceived
preference fit and enjoyment. In addition, market and recommender technology
characteristics must be taken into account, since they partially determine the level of
novel and serendipitous recommendations. Our findings have significant implications
for research as they add additional insights on users’ evaluations of recommender
systems. For practice, our results support online retailers in developing better
recommenders.

Keywords: Online recommendations, user preferences, recommendation novelty,
recommendation serendipity, recommender systems

Thirty Fifth International Conference on Information Systems, Auckland 2014 1
Human Behavior and IS

Introduction

Recommender systems have become prevalent on the Internet. Based on statistical patterns they aim to
suggest the most relevant products, information or actions for users and thus can also affect users’ life
besides online shopping (Hess et al. 2014; Hosanagar et al. 2014). This has become even more important,
since there are numerous online stores that carry vast numbers of different products and it is practically
impossible for consumers to manually browse through the whole product range (Hinz and Eckert 2010;
Veit et al. 2014). Compared to the pre-internet era, many online stores now focus profitably on the so
called “long tail”, i.e. these are niche products which are sold only rarely, but can still amount to a
substantial revenue (Anderson 2006; Brynjolfsson et al. 2011).

For online stores, efficient reeommender systems are essential and can help to increase sales (Pathak et al.
2010). The performance of recommender systems can be measured in terms of users’ acceptance and the
perceived quality of the recommendations, which in turn has an influence on users’ intention to
repurchase (Zhang et al. 2011). It is known that the perceived quality of online reeommendations differs
across different recommender technologies. In particular, computer science research has invested
significant efforts in increasing the precision of anticipations of future purchases based on previous
purchases (Adamopoulos and Tuzhilin 2011; Bell et al. 2009). Despite substantial progress in improving
recommendation accuracy, there have been concerns that the increasing usage of recommender systems
can create a “filter bubble” (Pariser 2011).

Following this, users mostly receive recommendations which match their pre-stated implicit or explicit
preferences very closely, and thus restrict them from finding something new (McNee et al. 2006; Zhou et
al. 2010). When providing online reeommendations that match previous purchases, there is a higher
chance that users will also like other recommended items. However, sticking too close to their own
comfort zone is not always desirable for users, as sometimes it takes looking beyond the obvious to
discover different, but highly valued items. So, when browsing through different websites and also in
traditional retail, users may discover interesting items they were originally not looking for.

There are concerns that current recommender systems do not sufficiently account for niche products, and
that retailers focusing on niche products may suffer from this (Zhou et al. 2010). However, tuning
recommender systems to more novel and serendipitous recommendations instead of accuracy can
increase the risk of deviations from users’ taste and may, as a consequence, lead users to stop following
recommendations in the future. Therefore, a good balance between novelty, serendipity, as well as
accuracy of recommendations seems to be necessary. Most research related to this stems from computer
science and focuses on altering existing recommendation algorithms to provide more diverse
recommendations (e.g., Zhang et al. 2012; Zhou et al. 2010), and on effects on the popularity of
recommended items (Adomavicius and Kwon 2012). However, apart from technical specifications, the
user’s side remains mostly unexplored. Research in IS and e-commerce has recently discussed this issue
from a different angle and has shown that a more diverse product offer can increase customer retention
rates (Park and Han 2013). Consequently, the authors suggest that vendors should optimize their
recommender systems for more diversity. However, there is still an evident lack of knowledge on how
users perceive recommendations on items that are different from what they are already familiar with.

Using a web-based field experiment with high ecological validity, we assess whether consumers really
want to “escape from the filter bubble”, i.e. whether they prefer recommendations of items that are close
to their previously stated taste preferences. We draw on concepts of recommendation novelty and
recommendation serendipity and address the following research questions:

e What is the effect of perceived recommendation novelty and perceived recommendation
serendipity on the evaluation of online product recommendations?

e Do the effects of perceived recommendation novelty and perceived recommendation serendipity
differ between recommender technologies and underlying markets?

Our research aims to close research gaps concerning users’ acceptance and evaluation of recommender
systems by providing a more accurate picture of antecedents that constitute, whether a reeommendation
is relevant for users or not. We expect these results to provide a better basis for optimizing current

2 Thirty Fifth International Conference on Information Systems, Auckland 2014
Escaping from the Filter Bubble?

recommender systems as well as the development of new ones. In addition, we believe that our results
have implications for any kind of decision support in general.

The rest of the paper is organized as follows: In the next section we present the conceptual foundations of
the effects of recommender systems on users and markets, as well as the focal concepts of
recommendation novelty and serendipity. Next, we introduce our research model and develop the
underlying hypotheses, followed by a description of the experimental layout. The results of this study are
presented and discussed thereafter. Finally, we provide further implications and a summary of the results
as well as the limitations of the paper.

Conceptual Foundations

Effects of Recommender Systems on Markets and Users

Due to their ability to reduce information overload by filtering the most relevant products for different
users, recommender systems have become ubiquitous in e-commerce (Hinz and Eckert 2010; Xiao and
Benbasat 2007). Their usage has had an effect both on aggregated markets as well as on individual
consumers.

For the former, their role has mostly been analyzed in respect of the long-tail-phenomenon and associated
changes in the distribution of sales diversity (Anderson 2006; Brynjolfsson et al. 2011). In contrast to
many physical stores and physical markets, for which few bestseller products typically account for large
shares of the overall revenue, online stores can easily carry a large number of niche products at little cost
(Fleder and Hosanagar 2009; Ho et al. 2011). However, there is still conflicting evidence on the impact of
recommender technologies on this long-tail phenomenon and whether recommenders lead to a
fragmentation or homogenization of consumers in respect of common purchases (Brynjolfsson et al. 2011;
Brynjolfsson et al. 2006; Hosanagar et al. 2014). While some authors argue that recommender systems
enable consumers to better find niche products, others hold that they increase the popularity of already
popular items (Fleder and Hosanagar 2009). However, more recent research indicates that to answer this
question a further differentiation between recommender technologies is necessary (Matt et al. 2013).

In comparison to this, numerous other studies have investigated the influence of recommender systems
on individual users. It has been shown that recommender systems influence consumers’ purchases (e.g.,
Senecal and Nantel 2004) and that they can boost sales, which is why they are often used to sell additional
or higher-priced products (Ahn 2006). However, there are different factors which can influence users’
perceptions of online recommendations, including the source of the recommendation. Online
recommendations can have a higher influence on consumer decisions than social recommendations from
the user’s environment (Fleder and Hosanagar 2009). It has also been shown that users perceive provider
and user generated product recommendations differently with regard to the perceived usefulness, but also
related to their trustworthiness (Benlian et al. 2012). The potential effect of recommender systems is
therefore a cause of how users evaluate recommendations and how they perceive their quality.

Accuracy of Recommender Systems

For a long time, improving recommendation accuracy has been seen as the key to increasing the perceived
quality of recommender systems. Accuracy is mostly measured by comparing the underlying
recommender algorithm’s prediction against user’s rating of a product (MecNee et al. 2006). Both research
and practice have invested significant effort to increase the accuracy of recommender systems
(Adamopoulos and Tuzhilin 2011; Hurley 2011). The underlying reasoning is that more information about
products and users enables a better basis for future decisions and helps online stores to create a stronger
link between previous purchases and future recommendations (Bechwati and Xia 2003).

However, there have been concerns that high recommendation accuracy does not necessarily correlate
with providing the most relevant recommendations for users (Adomavicius and Kwon 2011; Zhou et al.
2010). When users receive very accurate recommendations (i.e. the recommended items match their
preferences well), they are likely to receive reeommendations which are within a narrow scope of products
already familiar to them. Since the number of recommendations and users’ cognitive capacity is limited,
they are therefore more likely to miss opportunities to see different products (Hosanagar et al. 2014;
MeNee et al. 2006).

Thirty Fifth International Conference on Information Systems, Auckland 2014 3
Human Behavior and IS

Although Internet technologies have led to a “world full of niches” (Anderson 2006) most current
recommender systems are not able to provide unexpected recommendations to users (Ahn 2006). This
phenomenon is known as the “filter bubble” and describes “that users could be trapped in a self-
reinforcing cycle of opinion, never being pushed to discover alternative genres or viewpoints“ (Zhang et al.
2012).

Thus, many researchers argue that other characteristics should be taken into account to increase users’
satisfaction with recommender systems (Adomavicius and Kwon 2011; Adomavicius and Kwon 2012;
MceNee et al. 2006). Some hold that recommender design should be less focused on technical aspects, but
more on the underlying user behavior (Fleder and Hosanagar 2009). In this context, recommendation
novelty is frequently stated as being considerably influential (Adomavicius and Kwon 2011; Adomavicius
and Tuzhilin 2005). More recent approaches also target recommendation serendipity, which involves a
positive feeling of surprise (Zhang et al. 2012). We follow this line of research and hold that in addition to
accuracy, it is recommendation novelty as well as recommendation serendipity which mainly govern
users’ evaluation of recommendations.

Novelty and Serendipity of Online Recommendations

Research claims that novelty is highly desirable for online recommendations (Vargas and Castells 2011).
Novelty measures whether recommended items are already known to distinct users or to a community as
a whole. At the same time, novel recommendations should not consist of obvious items. Therefore, items
which are very likely to be already familiar to users should not be reeommended, since these users could
have already made a considerate decision to not purchase the item (Herlocker et al. 2004). There are
various approaches to measuring novelty, and most of them try to take the overall recognition of a product
on a market basis into account. Since users may have already seen an item in a different place, taking
market sales figures into account could help to estimate, whether an item is already familiar to users.
However, in the past many authors believed that there is a trade-off between accuracy and novelty, i.e.
more recommendation novelty may lead to less accurate recommendations and thus could elicit
unsatisfactory results for users (Vargas and Castells 2011). On the other hand, for online store providers,
generating more recommendations of previously unrated items increases the likelihood of receiving more
first time customer reviews for these products and can therefore, in turn, increase the accuracy of future
recommendations (Adomavicius and Kwon 2012).

As another potential measure that has recently gained more popularity, reeommendation serendipity
builds upon the concept of novelty, but expands this by the factor of a positive, unexpected discovery
(Herlocker et al. 2004). The positive, emotional surprise requires that in order to be attractive to users, a
recommendation must be useful for users as well. McNee et al. (2006) stress that serendipity means
experiencing fortuitous and unexpected recommendations. Ge et al. (2010) list unexpectedness and
usefulness as two core characteristics of serendipity. According to them, besides novelty as one
requirement for serendipity, the user should be unlikely to discover the recommended item unaided.
Therefore, a recommendation of a new film by one’s favorite movie director may be novel as well as
useful, but it is not necessarily serendipitous as it is very likely that users would have found this new film
sooner or later themselves (Herlocker et al. 2004).

Research in computer science continues to discuss the challenges in adjusting current recommender
technologies to provide more novel and serendipitous recommendation (Zhang et al. 2012). However,
there is a significant research gap in targeting users’ perspective and analyzing what the ideal levels of
novelty and serendipity from users’ perspective actually are and how they relate to technological and
market-based influence factors.

Research Model and Hypotheses

To empirically validate the impact of perceived recommendation novelty and perceived recommendation
serendipity on perceived preference fit and perceived enjoyment, we developed the research model
depicted in Figure 1. With this, we do not only seek to clarify the relationships between perceived
recommendation serendipity/perceived recommendation novelty and perceived preference fit/perceived
enjoyment. In addition, we aim to provide a more comprehensive picture, by accounting for different
antecedents in form of two technological and two market type influence factors. For the former, this

4. Thirty Fifth International Conference on Information Systems, Auckland 2014
 

Escaping from the Filter Bubble?

includes the two most common basic recommendation approaches (content-based and collaborative
filtering). For the latter, we varied the ratios of known and unknown songs to assemble blockbuster and
niche markets. We will discuss each of the resulting hypotheses in the following:

 

 

 

 

 

 

Perceived i
. Perceived
Recommendation Preference Fit
Novelty
Recommender
Technology
Market
Characteristics
Perceived ; Perceived
Recommendation j
nd Enjoyment
Serendipity

 

Figure 1. Conceptual Research Model

 

Effects of Perceived Recommendation Novelty on Perceived Preference
Fit/Perceived Enjoyment

One main challenge is to measure the actual degree of novelty for a particular user/item-combination.
Even if consumers have not previously seen a specific item in an online store, it does not necessarily mean
that they do not know this item, as they could have seen the item elsewhere (and they may also like it).
Therefore, taking store-wide data for unseen items for each user into account does not guarantee that all
of these items are new to users. Even when taking market purchase data into account, it is still not fully
clear whether an item is already familiar to users.

Therefore, instead of the system-inherent perspective, we consider the users’ perceived level of
recommendation novelty and what the effect on perceived preference fit and perceived enjoyment are.
Research and practice have focused on increasing reeommenders’ accuracy, mainly due to concerns that
an increase in novelty can potentially decrease recommendation accuracy. In line with this, if
recommendations are new to users they may still provide only little value if they do not fit the user’s taste.
The higher risk of providing recommendations that do not match user preferences is due to the lower
amount of underlying data that a provider has about a specific item/user relation. We follow this
reasoning and conclude:

Hypothesis 1a: Perceived novelty of online recommendations will have a negative effect on perceived
preference fit.

Independent of the aforementioned challenges in calculating recommendation novelty for specific
user/item-combinations it is generally believed that users are interested in receiving novel online
recommendations (Herlocker et al. 2004). However, the provision of recommendations of already known
items can lead to unsatisfactory results for users. We believe that in contrast to this, receiving
recommendations of novel items can have affective effects on users, leading to a higher enjoyment of the
item selection task. In addition to experiencing something new, this is also because the recommender
system has increased the number of salient products users can choose from. We thus hold:

Hypothesis 1b: Perceived novelty of online recommendations will have a positive effect on perceived
enjoyment.

Effects of Perceived Recommendation Serendipity on Perceived Preference
Fit/Perceived Enjoyment

For novelty we assumed that recommendations are not of high value to users if they are merely novel, but
do not match users’ taste. In contrast to this, we argue that serendipity is a key element to providing

Thirty Fifth International Conference on Information Systems, Auckland 2014 5

 
Human Behavior and IS

better recommendations to users. In addition to the novelty component, being a valuable and surprising
discovery to users is inherent to serendipity. We believe that this combination of factors is suitable to
ensure a high preference fit for users. Therefore, in contrast to novelty, we argue:

Hypothesis 2a: Perceived serendipity of online recommendations will have a positive effect on perceived
preference fit.

Serendipity and its effects on people has mostly been discussed in the context of Internet browsing and
social media (Hart et al. 2008). Public media also discusses the potential effects of filtering algorithms on
peoples’ discovery of unexpected items — both from an outcome-oriented effectiveness angle as well as
from an affective perspective (CNN 2013). In addition to providing recommendations that fit users’
preferences better, we believe that unexpected, but rewarding discoveries of items can also have a positive
effect on consumers’ perceived enjoyment since users may realize that they have taken a better purchase
decision than expected. We thus argue:

Hypothesis 2b: Perceived serendipity of online recommendations will have a positive effect on perceived
enjoyment.

Effects of Recommender Technology on Perceived Recommendation Novelty/
Perceived Recommendation Serendipity

The two main recommender technologies are content-based filtering (CBF) and collaborative filtering
(CLF) (Burke 2000; Xiao and Benbasat 2007). However, today various sub-forms and also hybrid
combinations of both methods are used to combine the advantages of both approaches (Burke 2002).
CBF-systems create recommendations based on similarities between different items. Here, the main idea
is that users are more likely to select or purchase items that are similar to the ones they have already
purchased. Product similarities are calculated based on product characteristics, and for music, they
include genre, artists or song length for instance. Product characteristics are more difficult to describe for
experience goods (such as music) than for search goods (such as cars). In contrast to this, CLF-systems
create recommendations based on similarities between users (Balabanovié and Shoham 1997). The main
assumption is that if two users have purchased similar goods in the past, they are also likely to enjoy
similar items in the future. Thus, purchases that only one of the two similar users has made, are
recommended to the other user. CLF-recommenders frequently use the Pearson correlation coefficient or
the cosine function to calculate similarities (Ahn 2006).

Previous research argues that CBF-recommenders are less likely to create novel and unexpected
recommendations since if products are recommended that are close to users’ tastes, there is a high
likelihood that users are already familiar with this product (Herlocker et al. 2004). We acknowledge this
point, but believe that this is difficult to generalize and probably differs between products and domains.
As mentioned before, product characteristics are difficult to describe for experience goods. Thus, if
similarities between two songs are calculated merely based on their content (i.e. music-related similarities
such as genre or tone), they could be seen as similar content-wise, but still appear fairly different to users.

CBF-recommenders promote products based on their characteristics and not based on_ their
popularity. Thus, even slow-selling products have equal chances of being recommended by CBF-systems.
In contrast to this, for CLF-recommendations a self-enhancing circle can arise, for which products that
are purchased by many customers (popular products) are more likely to be recommended by CLF-
recommenders. If these already popular products are recommended more often, they are more likely to be
purchased more often and so on (Fleder and Hosanagar 2009). Therefore, we hold that CBF-
recommenders could lead consumers to discover more unfamiliar products and hold:

Hypothesis 3a: Consumers will perceive higher novelty of online recommendations generated with CBF
than with CLF.

The assumptions for the effects of the reeommender technology in use on perceived recommendation
serendipity are more difficult to estimate. Since we believe that CBF-recommendations will include a
higher number of novel recommendations, one requirement for serendipity is fulfilled. Moreover,
serendipitous recommendations must be both unexpected and useful to consumers. We argue that in
addition to the higher level of novelty, CBF will also successfully generate more unexpected, but still
useful recommendations. The recommendations are likely to be more unexpected, given that the

6 Thirty Fifth International Conference on Information Systems, Auckland 2014
Escaping from the Filter Bubble?

underlying popularity of the song is not taken into account and thus songs from rather unknown artists
can be recommended. Recommendations are likely to be still useful, considering that CBF-systems seek to
recommend products that match users’ preferences closely. We therefore propose:

Hypothesis 3b: Consumers will perceive higher serendipity of online recommendations generated with
CBF than with CLF.

Effects of Market Characteristics on Perceived Recommendation Novelty/
Perceived Recommendation Serendipity

In many online markets a steady growth of long-tail market distributions has been observed (Anderson
2006; Brynjolfsson et al. 2011). Markets for media products are typically blockbuster markets, for which
few bestseller products typically account for large shares of the overall market sales. In contrast to this,
niche markets are characterized by a high share of slow-selling products which, viewed aggregately, can
amount to a large share of revenue for vendors (Fleder and Hosanagar 2009; Ho et al. 2011). Providing
more niche products can help vendors to increase profits and retention rates (Park and Han 2013).

From a statistical point of view, it seems rather obvious that a higher share of niche songs increases the
probability that recommendations will contain more niche songs. However, apart from population-based
assumptions it is not fully clear whether a higher share of niche items in the population will lead to a
higher share of novel recommendations. Instead, it could well be that rather popular items remain more
successful in being promoted, leaving the ratio of recommended blockbuster and niche products
unchanged. For CBF this does not seem realistic. Since sales-popularity is not taken into account when
calculating similarities, we follow the statistical assumption that a higher share of unpopular songs in the
population will lead to more recommendations of niche songs.

For CLF things are slightly different. If a high proportion of users still decides to purchase generally well-
known items, these are more likely to be reeommended. So it would be possible that a higher number of
less well-known items does not change the ratio of blockbuster versus niche recommendations. However,
since niche songs do not need to be of worse quality, we believe that a higher number of the previously
unknown songs will be purchased and build the basis for further recommendations to other users. We
thus hypothesize:

Hypothesis 4a: Consumers will perceive higher novelty of online recommendations in niche markets
than in blockbuster markets.

Furthermore, for recommendation serendipity, again we follow the previously discussed statistical
assumptions that a higher number of unknown songs in the population will lead to more
recommendations of unknown songs. Assuming identical quality and an identical ratio of novel and
serendipitous songs among the niche songs compared to the blockbuster-market, we suggest:

Hypothesis 4b: Consumers will perceive higher serendipity of online recommendations in niche markets
than in blockbuster markets.

Implementation as a Web-Experiment

Experimental Design, Incentives and Procedures

In contrast to simulations and analytical models, a web-based field experiment allows us to analyze
actual, instead of intended, user behavior. In addition, it provides us with a high level of control over the
environment and thus enables us to clearly exclude undesired effects. To ensure a high ecological validity,
we used state-of-the-art technologies and designed the experiment in the form of a very interactive web
application (Appendix 1 and 2). The interactive features and the elaborate design helped to enable our
online music store to look similar to real online stores for digital music.

We have chosen digital music as the product in question because purchasing music over the Internet has
become very popular among consumers. Furthermore, music is considered to be an experience good and
its quality is therefore difficult to evaluate prior to consumption, based solely on product information. In
contrast, even a short trial of the product enables consumers to better anticipate the fit of a music track to

Thirty Fifth International Conference on Information Systems, Auckland 2014 7
Human Behavior and IS

their taste. Therefore, in our experiment, participants had the opportunity to listen to free 30-second
previews for all tracks.

To increase participants’ motivation to choose among all available songs carefully, participants were told
that every 10% participant would win the 5 songs they were asked to select during the experiment. We did
not apply atime limit to leave participants as much time as needed to make well-founded choices.

In a 2x2 between-subjects-design we implemented four different treatments to which participants were
randomly assigned. The treatments included two different recommender system technologies, namely
collaborative filtering (CLF) and content-based filtering (CBF), as well as two different underlying market
characteristics - “blockbuster” and “niche” markets, which differed in the share of well-known and less
well-known songs (Table 1). To make participants believe that the recommendations were individually
calculated for them, the recommendations were introduced as “personal recommendations”. However,
participants did not learn which type of recommender technology was used to calculate their
recommendations.

 

Table 1. Overview of Treatments

 

 

 

 

Recommender Type
Market Type oa ae
Collaborative Filtering (CLF) Content-based Filtering (CBF)
Blockbuster (BB) CLF x BB (n=33) CBF x BB (n=31)
Niche (NI) CLF x NI (n=32) CBF x NI (n=34)

 

 

 

 

 

To provide CBF- and CLF-recommendations, it is necessary to have information on participants’ tastes.
For this purpose a separate rating phase was conducted first, in which all participants were asked to
evaluate 15 different songs (“rating tracks”) on a Likert scale from 1 (do not like the song at all) to 5 (like
the song very much). These tracks included the currently most popular (#1), the fifth (45) and the 500th
most popular song (#500) as indicated by the music intelligence platform Echo Nest in the genres pop,
rock, hip-hop/r&b, electronic music, and oldies. The track selection was intended to cover a wide range of
songs and genres to gain a differentiated picture of the participants’ musical tastes and to provide an
appropriate basis for the content-based and collaborative recommendations.

In the subsequent purchasing phase, participants received recommendations which were created by the
two different recommender technologies. Here, participants had to purchase 5 out of 500 digital music
tracks (“choice tracks” in the following). For the blockbuster treatments these songs consisted of 350
popular and 150 niche songs, while in the niche market the ratio of popular and niche songs was inverse.
Popular tracks were randomly drawn from the 500 most popular tracks as indicated by Echo Nest. As in
the rating phase, participants again had unlimited access to 30-second samples of each song to see
whether they liked the song. In addition, participants received 5 recommendations of different music
tracks. These tracks (“recommendation tracks”) were clearly marked as recommendations and located in a
dedicated part of the website. Participants were not obliged to listen to or to select any of the
recommended tracks.

In a post-experimental survey, we asked participants to rate their music selection experience during the
experiment and in relation to the reeommendations they received. We also gave participants the option to
see and listen to the previously obtained recommendations again, in case they had not yet listened to all of
the recommendations during the music selection task. Based on the different survey items, we measured
participants’ levels of perceived recommendation novelty, perceived recommendation serendipity,
perceived preference fit, and perceived enjoyment.

Implemented Recommender Technologies
Collaborative Filtering

To provide recommendations, collaborative filtering calculates similarities between different users. The
underlying assumption is that if two users have had similar opinions on two common products in the past,

8 Thirty Fifth International Conference on Information Systems, Auckland 2014
Escaping from the Filter Bubble?

they are more likely to share the same opinion on future items. We used the cosine similarity function to
calculate the collaborative filtering function.

CLF-recommenders may suffer from a cold-start problem if they are based on little or no initial data. In
this case, early recommendations can be heavily affected by new incoming data, since a small change in
votes or purchases may have a strong impact on the recommendation order of the items. Since we are
interested in the general effect of CLF and not its potential problems in special situations (most online
stores use proxy data to reduce these issues), we previously collected data about music tastes from two
different groups of participants (in the following they are referred to as “basic profiles”). These
participants received the same experimental conditions as those in the experimental treatment (e.g.
interface design, selection of songs), but they did not have access to a recommender system. One of the
two basic profile groups received the blockbuster and the other the niche market selection of songs.

Based on this, for each current participant », the most similar participant from the basic profiles was
identified. Given p, as the current participant with b, as the 15-dimensional vector that contained the

participant’s rating, then the cosine similarity 5,,, to another participant from the set of basic profiles
»; © P with their respective vector 5,, is calculated as:

Seas (Pa?) = by, * Bp;
cos Pa PI Tb, Mbp.

The cosine function returns the highest similarity between two users, the closer 5,,; is to 1. Therefore, it
was the highest similarity with one of the participants from the basic profiles p,; € P, where the difference
to 1 was minimal 5,,, (p,. p;) . For each participant »,, the 5 tracks that were selected by the most similar
participant ; from the basic profiles were reeommended.

Content-based Filtering

From all 500 songs in the purchasing phase, the implemented content-based filter t:37 reeommended
those songs to participants that have the highest similarity coefficient with the aggregated rating of the 15
songs that were evaluated in the rating phase. For the content-similarity calculation between music
tracks, we used a professional music comparison program that involved a number of different algorithms
and parameters for the similarity calculation and that returned a matrix with content-based “distances”
between all tracks. The similarity coefficient was calculated based on the degree of similarity between the
two most similar songs (as reported by the music comparison program) multiplied with the participant’s
rating of this song. In line with this, let #; © T be a track from the choice set T and y the most similar
track from the rating set. Furthermore, let R(¥) be the rating of the current participant », for the track
and S(i;, 7) the degree of similarity between t; and y. Under consideration of the rating R,, of the current

participant », the similarity coefficient @ of track t; was calculated and based on which participant
B, received the 5 tracks with the highest similarity coefficient as recommendations:

Olt Ay.) = AO) Say)

For content-based filters, no data from other users is needed. The data basis for both CBF and CLF were
dynamically updated during the experiment once new data arrived.

Survey Instruments and Measurement Model

The survey instruments used validated scales with minor wording changes to achieve a better fit with the
local scenario (see Table 2). All the questionnaire items were measured on Likert-type scales, anchored at
1 = “strongly disagree,” 4 = “neutral”, and 7 = “strongly agree.” As in Kamis et al. (2008), two binary
variables were constructed (i.e., reeommender type = 1 for CBF, recommender type = 0 for CLF; market
type = 1 for niche market, market type = o for blockbuster market) to capture the four experimental group
conditions.

The model was tested via partial least squares (PLS) analysis using SmartPLS 2.0 with the bootstrapping
resampling procedure (Ringle et al. 2005). The measurement models were validated using recommended
validation procedures (Chin 2010). Scale items in one domain were pooled and factor analyzed to assess

Thirty Fifth International Conference on Information Systems, Auckland 2014. 9
Human Behavior and IS

their convergent and discriminant validity (Table 2). While convergent validity was determined both at
the individual item level and at the specified construct level, discriminant validity was assessed by
analyzing the average variance extracted (AVE). Further, all standardized factor loadings were significant
(p<0.05), thus providing evidence of convergent validity. Construct reliability was assessed by computing
the composite reliability for each construct. All constructs had a composite reliability above the suggested
threshold value of 0.70 (Bagozzi and Yi 1988). Further, all constructs met the suggested threshold value
for the average variance extracted (AVE>0.50).

To prevent common method bias, we followed the reeommendations related to questionnaire design (e.g.,
assurance of respondent anonymity, concrete survey instructions to answer questions as honestly as
possible, and to reduce ambiguity) as suggested by Podsakoff et al. (2003). To statistically test for
common method bias, we used Harman’s one-factor test (Harman 1967). We conducted an exploratory
factor analysis on all the variables, but the first single factor accounted for only 34.29% of the covariance
in the variables. Besides, correlation statistics indicate that correlations between all latent variables were
significantly below 0.9 as recommended by Bagozzi et al. (1991). The procedural and statistical remedies
used in our study suggest that common method bias is unlikely to have significantly affected our results.

 

Table 2. Survey Instruments and Descriptive Statistics

 

 

 

 

 

 

 

 

 

 

 

Constructs* | Indicators Loadings Source
Perceived Please indicate how familiar you are with the reeommended songs: Becker-
Recommen- a: a: Olsen
dation not at all familiar / extremely familiar 0.946 (2002);
Novelty - - - - Simonin
a=0.925 definitely do not recognize / definitely do recognize 0.917 and Ruth
- ‘ 1998
CR=0.953 definitely have not heard of it / definitely have heard of it before 0.02 (2998)
AVE=0.870 “935
Perceived The recommendation system provided me with:
Recommen- ws : : new
: ..Surprising recommendations that helped me discover new
dation : A 0.780
we music that I wouldn’t have found elsewhere.
Serendipity
a=0.881 ..recommendations that I had not considered in the first place 0
CR=0.924 but turned out to be a positive and surprising discovery. ‘947
AVE= 0.803 | ... recommendations that were a pleasant surprise to me because 0.0F1
I would not have discovered them somewhere else. ‘95
Perceived Conformity between recommended songs and user preferences. Franke et
Preference Fit al. (2009);

I like the selection of songs recommended to me on the website. | 0.931

 

 

 

 

 

 

 

 

 

 

 

a=0.918 Randall et
CR=0.924 The selection of music titles reeommended to me on the website | 0.901 al. (2007)
AVE=0.856 comes close to my idea of a perfect selection.

The music titles recommended to me on the website coincide 0.943

with my personal preferences.
Perceived While using the music website: Kamis et
Enjoyment ..I found my visit interesting. 0.943 al. (2008);
a=0.937 ———— Koufaris
CR=0.958 ..1 found my visit enjoyable. 0.961 (2002)
AVE=0.884 ..1 found my visit fun. 0.917

 

* Presentation of latent variable correlations is omitted for brevity.

10 Thirty Fifth International Conference on Information Systems, Auckland 2014
Escaping from the Filter Bubble?

Results
Descriptive Statistics

The experiment was conducted in March/April 2014 and included one pre-test to ensure the usability of
the user interface and the readability of the task. Invitations to participate were distributed in several
university-administered mailing lists and on social media sites. Thus, our sample consisted of a
particularly high share of students among the participants. However, we deliberately decided to target
students as participants not only for accessibility reasons, but also since students constitute a main
purchasing group, both in e-commerce in general, but also with respect to purchasing music online.
Eventually, a total of 130 participants completed the final experiment, of which 47 (36.15%) were male, 76
(58.46%) were female and 7 (5.35%) did not provide their gender. As expected, 98 (75.38%) and thus the
majority of participants was in the age group of 20-29 years.

During the experiment we recorded participants’ song ratings, as well the number of songs they listened
to and the number of recommendations that were played or purchased by them. The main characteristics
for the different treatment groups are shown in Table 3. The high average level of decision-making
involvement (based on Zhang et al. 2011, also measured on a Likert-type scale from 1-7) indicated that our
incentive scheme, offering the chance to win the songs that were selected during the experiment, seemed
successful in increasing participants’ motivation.

 

 

 

 

 

 

 

 

Table 3. Overview of Participation
Treatment* CLF x BB CLF x NI CBF x BB CBF x NI
Number of 33 32 31 34
Participants
Number of Played | 43.00 63.50 51.00 60.50
Songs (Median)
Number of 2.76 3.34 3.84 4.00
Recommendations
Played (Mean)
Number of 0.39 0.84 0.45 0.32
Recommendations
Purchased (Mean)
Decision Making 6.34 6.51 6.11 6.57
Involvement

 

 

 

 

 

 

* CLF=collaborative filtering, CBF=content-based filtering, BB=blockbuster market, NI=niche market
Test of Hypotheses

We tested Hypotheses 1 and 2 by analyzing the total (pooled) sample of our model (Figure 2). Based on
this, 32.9% of the variance in perceived preference fit and 7.3 % of the variance in perceived enjoyment is
explained by the research model. Regardless of recommender technology and market characteristics, a
significant negative effect of perceived recommendation novelty on perceived preference fit was found,
thus supporting Hia. The effect of perceived recommendation novelty on perceived enjoyment was
negative, and not statistically significant — therefore Hib was rejected. As hypothesized, perceived
recommendation serendipity had a significant positive effect on both perceived preference fit and on
perceived enjoyment, thus supporting H2a and H2b.

Thirty Fifth International Conference on Information Systems, Auckland 2014 11
Human Behavior and IS

 

 
    
 

   
  
 

     
   
    
  
   
 

  

Perceived
Preference Fit
32.9%

Perceived
Recommendation
Novelty

-0.449***

0.413***

  
  
 

  
  
  
 

Perceived
Enjoyment
7-3%

Perceived
Recommendation
Serendipity

*p<0.05, **p<0.01, ***p<0.001

 

 

Figure 2. Measurement Model Results

 

 

To analyze Hypotheses 3 and 4 and to account for the influences of reeommender technology and market
type characteristics, we split the data according to their treatment groups. Table 4 depicts the means and
standard deviations for the construct variables for each treatment.

 

Table 4. Means and Standard Deviations for the Different Treatments

 

 

 

 

 

 

 

 

 

 

 

Construct/ Treatment CLF x BB CLF x NI CBF x BB CBF x NI

Perceived Recommendation Novelty (PRN) 2.32 (1.27) 3.66 (1.61) 3.23 (1.51) 4.29 (1.57)
Perceived Recommendation Serendipity (PRS) | 2-24.39) | 3.72.72) | 2.908(4.29) | 3.39 (2.50)
Perceived Preference Fit (PPF) 3.22 (1.96) 3.47 01.63) 3.09 (1.48) 2.37 (1.29)
Perceived Enjoyment (PE) 4.77 (1.53) 4.92 (1.73) 5.11 (1.18) 5.36 (1.40)

 

Effect sizes were calculated using partial n2, whereas 0.009 constitutes a small, 0.058 a medium and
0.138 a large effect (Cohen 1988). A two-way MANOVA revealed significant multivariate main effects for
both recommender type (Pillai’s Trace=0.111, F=3.838, p<o0.01, partial 72=0.111) and market type (Pillai’s
Trace=0.216, F=8.472, p<0.001, partial n2=0.216), while the interaction effect of recommender and
market type was not significant (Pillai’s Trace=0.053, F=1.733, p=0.147, partial n2=0.053). Given the
significance of the tests of the two main influence factors, we continued with the analysis of the univariate
effects. Significant univariate main effects were present for the influence of recommender type on
perceived novelty (F=8.644, p<0.01, partial n2=0.064) as well as for the effects of market type on
perceived novelty (F=21.006, p<o.001, partial n2=0.143) and on perceived serendipity (F=13.151,
p<0.001, partial n2=0.095). The effect of recommender technology on perceived serendipity was not
significant (F=0.617, p=0.434, partial n2=0.005). However, taking into account the fairly large mean
differences for the different reeommender groups, pair-wise differences were calculated and tested for all
relevant combinations of treatments (Table 5).

Pairwise comparisons of means across groups revealed that CBFs lead to significantly higher levels of
perceived recommendation novelty in blockbuster markets. Since the effects were not significant for niche
markets, we see partial support for H3a. In respect of perceived recommendation serendipity, CBFs elicit
higher levels only in blockbuster, but not in niche markets, where perceived serendipity is slightly (but not
significantly) higher for CLFs - thus there is partial support for H3b.

12 Thirty Fifth International Conference on Information Systems, Auckland 2014
Escaping from the Filter Bubble?

 

Table 5. Pair-wise Comparisons of Differential Effects of Recommender
Technology and Market Characteristics

 

 

 

 

 

 

 

 

 

 

Mean Differences for Different Perceived Recommen-_ | Perceived Recommen-
Treatment Groups (I-J) dation Novelty dation Serendipity
Recommender Technology
CLF x BB (D CBF x BB (J) -0.90* -0.74*
CLF x NI (2) CBF x NI (J) -0.64 0.33
Market Characteristics
CLF x BB (D CLF x NI (J) -1.33%** -1.48***
CBF x BB (1) CBF x NI (J) -1.07** -0.41

 

 

 

*p< 0.05, **p< 0.01, ***p< 0.001, based on LSD-test

 

When comparing differences between blockbuster and niche markets, perceived recommendation novelty
is higher for both recommender technologies and is therefore evidence for supporting H4a. When
comparing levels of perceived recommendation serendipity, the differences are only significant for CLFs,
but not for CBFs. This gives partial support for H4b.

In Figure 3, the estimated means of perceived recommendation serendipity were plotted for each of the

two recommender technologies and market types.

 

Estimated Marginal Means of Perceived Recommendation Serendipity

 

4,005

3,505

Estimated Marginal Means
&
i

2.504

2,005

 

 

 

T
Collaborative Filtering

T
Content-based Filtering

Recommender Type

 

Market Type

— Blockbuster
—Nliche

4004

3504

3,004

Estimated Marginal Means

2,004

 

 

 

 

T
Blockbuster

T
Niche

Market Type

Estimated Marginal Means of Perceived Recommendation Serendipity

Recommender Type

— Collaborative Fittering
— Content-based Fittering

 

Figure 3. Means of Perceived Recommendation Serendipity

 

 

 

Discussion and Further Implications

The main objective of this paper was to unravel the effects of perceived recommendation novelty and
perceived recommendation serendipity on the evaluation of online product recommendations and to
account for contextual factors, involving different reeommender system technologies and different market
characteristics. Our findings provide a finer-grained understanding of users’ evaluation of online
recommendations and help to answer the initial question of whether users want to escape from the so-
called “filter bubble”. This was necessary as previous research has focused too much on optimizing
recommender systems for accuracy, and the IS literature had not yet theorized about how different levels
of perceived recommendation novelty and perceived recommendation serendipity impact users’ perceived
preference fit and their perceived enjoyment. Our results demonstrate that recommendation novelty
alone is not a sufficient means to escape from the filter bubble, since more novelty comes at the costs of

Thirty Fifth International Conference on Information Systems, Auckland 2014 13
Human Behavior and IS

lower perceived preference fit. Higher levels of perceived serendipity on the other hand can positively
influence users’ perceived preference fit and their perceived enjoyment.

Another important contribution of this study is related to its investigation of two antecedents of the
perceived levels of recommendation novelty and serendipity: recommender technology and market type.
The results show that CBF-systems are more likely to provide novel and serendipitous items in
blockbuster markets, while this is not the case for niche markets. This is probably because CBF-
recommenders do not take the items’ popularity into account. Thus, in niche markets, the relative share of
CBF-recommendations of niche products is likely to be larger than for CLF-recommenders. Particularly in
niche markets, the higher values for perceived preference fit indicate that CLF-systems seem to profit
from the quality assessment of users who have previously decided to purchase certain songs and thus
these songs are more likely to be recommended again.

From a practical perspective, the present results suggest that online retailers should place a stronger focus
on providing serendipitous recommendations and integrate serendipity considerations into the design of
recommendation algorithms. Most of the current recommender systems have been criticized to not
sufficiently account for serendipity. Accordingly, providers of online stores need to analyze their current
recommender systems and reassess their suitability of providing serendipitous recommendations.
However, optimizing current recommender systems for more serendipitous recommendations is not a
trivial task. The creation of serendipitous recommendations involves deviations from users’ predefined
preferences. This in turn entails higher risks that users may not like recommendations, since they do not
fit their tastes and thus users could stop following recommendations in the future (Ge et al. 2010).
Therefore, recommender systems need to be optimized for novel recommendations that are to some
degree aligned to users’ previous preferences. By monitoring user behavior over time, recommender
systems could become more sophisticated in identifying such recommendations. But also since user
preferences can change over time, it seems reasonable that serendipity metrics need to follow a user’s
actions and interests over a longer period of time to identify patterns for deviations from users’ regular
behavior. A time-variant factor could also be used to identify items that are “on the rise”. If items receive
many positive evaluations or are purchased often within a short period of time, they appear to be rather
“hip”. This could serve as an indicator that such an item would also be liked by other users who have just
not yet discovered it. However, since users may deviate in their personal attitude towards novel and
serendipitous recommendations, online vendors may also think about explicitly asking users about their
individual attitude and adopt recommendations based on this.

Limitations and Opportunities for Further Research

Despite extensive efforts to provide an experimental environment with high ecological validity, the
current study at hand is subject to several limitations. First of all, our experiment only covered digital
music. Digital music is an experience good and thus it is more difficult to describe and to be evaluated
prior to consumption. Research has shown that effects of reeommender systems can differ between search
and experience goods (Benlian et al. 2012). In addition, music is a product that is known to affect
consumers emotionally rather than being evaluated by objective measures. Consequently, consumers’
perceptions and desires for novelty and serendipity may well be affected by the product type we have
chosen and should thus be validated with other types of products.

Secondly, even for a distinct product type the perception of an ideal level of recommendation novelty and
recommendation serendipity may differ dependent on the concrete usage situation and the evaluation
costs of novel or serendipitous recommendations. For users of flat-rate-based streaming services for
instance, trying out new products may be seen as a positive experience, since evaluation costs are little.
However, with regard to product purchases, a very high share of unknown product recommendations
could be seen as less constructive, since users may rather wish to stay closer to their current preferences
(Herlocker et al. 2004). We therefore encourage the analysis of the effects of different levels of
recommendation novelty and recommendation serendipity in other usage scenarios.

Lastly, as previously mentioned, our sample consisted of a disproportionately high proportion of students.
We believe that due to our incentive scheme which ensured participants’ motivation and the fact that
students are a consumer group who frequently purchases music online, they are appropriate for our study.

14. Thirty Fifth International Conference on Information Systems, Auckland 2014
Escaping from the Filter Bubble?

However, our results should be validated with a representative sample of Internet users to ensure that our
sample has not confounded the results.

Conclusion

Recommender systems have become omnipresent in e-commerce. Their wide usage spectrum has raised
concerns that users could too often receive recommendations for products which they are already familiar
with or that are too similar to their previous purchases. The proposed “filter bubble” phenomenon
motivated our research to analyze how consumers perceive recommendations of items that are different
from previously discovered items. By drawing on concepts of recommendation novelty and
recommendation serendipity, the present study found that perceived recommendation serendipity has a
strong positive effect, both on perceived preference fit as well as on the perceived enjoyment of the users.
In contrast to this, a higher level of perceived recommendation novelty reduces perceived preference fit
and does not lead to significant changes to users’ perceived enjoyment. Theoretically, the study
disentangles the differential effects of perceived recommendation novelty and perceived recommendation
serendipity on both a directly reeommendation-related parameter (preference fit) as well as on an
affective parameter (perceived enjoyment). Practically, the study emphasizes that there should be a focus
on recommendation serendipity, and not on recommendation novelty, in recommender system
development. In respect of moving recommender algorithm design in this direction, environmental
factors, such as the distribution of niche and blockbuster products, need to be considered. Therefore we
advise the development of domain-specific recommender solutions. It is hoped that the present study’s
results inspire future research which aims to improve and develop recommender systems that are capable
of providing users with a suitable level of serendipitous recommendations.

References

Adamopoulos, P., and Tuzhilin, A. 2011. "On Unexpectedness in Recommender Systems: Or How to
Expect the Unexpected,” in Proceedings of the Workshop on Novelty and Diversity in Recommender
Systems at the Fifth ACM International Conference on Recommender Systems, Chicago, IL, USA.

Adomavicius, G., and Kwon, Y. 2011. "Maximizing Aggregate Recommendation Diversity: A Graph-
Theoretic Approach," in Proceedings of the Workshop on Novelty and Diversity in Recommender
Systems at the Fifth ACM International Conference on Recommender Systems, Chicago, IL, USA, pp.
3-10.

Adomavicius, G., and Kwon, Y. 2012. "Improving Aggregate Recommendation Diversity Using Ranking-
Based Techniques," IEEE Transactions on Knowledge and Data Engineering (24:5), pp. 896-911.
Adomavicius, G., and Tuzhilin, A. 2005. "Towards the Next Generation of Recommender Systems: A
Survey of the State-of-the-Art and Possible Extensions,” JEEE Transactions on Knowledge and Data

Engineering (17:6), pp. 734-749.

Ahn, H. J. 2006. "Utilizing Popularity Characteristics for Product Recommendation," International
Journal of Electronic Commerce (11:2), pp. 59-80.

Anderson, C. 2006. The Long Tail: Why the Future of Business Is Selling Less of More. New York:
Hyperion.

Bagozzi, R. P., and Yi, Y. 1988. "On the Evaluation of Structural Equation Models," Journal of the
Academy of Marketing Science (16:1), pp. 74-94.

Bagozzi, R. P., Yi, Y., and Phillips, L. W. 1991. "Assessing Construct Validity in Organizational Research,”
Administrative Science Quarterly (36:3), pp. 421-458.

Balabanovié, M., and Shoham, Y. 1997. "Content-Based, Collaborative Recommendation,"
Communications of the ACM (40:3), pp. 66-72.

Bechwati, N. N., and Xia, L. 2003. "Do Computers Sweat? The Impact of Perceived Effort of Online
Decision Aids on Consumers’ Satisfaction with the Decision Process," Journal of Consumer
Psychology (13:1/2), pp. 139-148.

Becker-Olsen, K. L. 2003. "And Now, a Word from Our Sponsor: A Look at the Effects of Sponsored
Content and Banner Advertising,” Journal of Advertising (32:2), pp. 17-32.

Bell, R., Bennett, J., Koren, Y., and Volinsky, C. 2009. "The Million Dollar Programming Prize," IEEE
Spectrum (46:5), pp. 28-33.

Thirty Fifth International Conference on Information Systems, Auckland 2014 15
Human Behavior and IS

Benlian, A., Titah, R., and Hess, T. 2012. "Differential Effects of Provider and User Recommendations in
E-Commerce Transactions: An Experimental Study," Journal of Management Information Systems
(29:1), pp. 237-272.

Brynjolfsson, E., Hu, Y. J., and Simester, D. 2011. "Goodbye Pareto Principle, Hello Long Tail: The Effect
of Search Costs on the Concentration of Product Sales," Management Science (57:8), pp. 1373-1386.

Brynjolfsson, E., Hu, Y. J., and Smith, M. D. 2006. "From Niches to Riches: Anatomy of the Long Tail,”
MIT Sloan Management Review (47:4), pp. 67-71.

Chin, W. W. 2010. "How to Write up and Report PLS Analyses,” in Handbook of Partial Least Squares.
Springer, pp. 655-690.

CNN. 2013. “Internet Gains Are  Serendipity's Loss." Retrieved 26.04.2014, from
http://edition.cnn.com/2013/11/20/tech/web/internet-serendipit

Cohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences. Hillsdale: Psychology Press.

Fleder, D., and Hosanagar, K. 2009. "Blockbuster Culture's Next Rise or Fall: The Impact of
Recommender Systems on Sales Diversity," Management Science (55:5), pp. 697-712.

Franke, N., Keinz, P., and Steger, C. J. 2009. "Testing the Value of Customization: When Do Customers
Really Prefer Products Tailored to Their Preferences?," Journal of Marketing (73:5), pp. 103-121.

Ge, M., Delgado-Battenfeld, C., and Jannach, D. 2010. "Beyond Accuracy: Evaluating Recommender
Systems by Coverage and Serendipity," in Proceedings of the Fourth ACM Conference on
Recommender Systems, Barcelona, Spain, pp. 257-260.

Harman, H. H. 1967. Modern Factor Analysis. Chicago, IL, USA: Univ. of Chicago Press.

Hart, J., Ridley, C., Taher, F., Sas, C., and Dix, A. 2008. "Exploring the Facebook Experience: A New
Approach to Usability," in Proceedings of the 5th Nordic Conference on Human-Computer
Interaction: Building Bridges, pp. 471-474.

Herlocker, J. A., Konstan, J. A., Terveen, L. G., and Riedl, J. T. 2004. "Evaluating Collaborative Filtering
Recommender Systems,” ACM Transactions on Information Systems (22:1), pp. 5-53.

Hess, T., Legner, C., Esswein, W., MaaB, W., Matt, C., Osterle, H., Schlieter, H., Richter, P., and
Zarnekow, R. 2014. "Digital Life as a Topic of Business and Information Systems Engineering?,”
Business & Information Systems Engineering (6:4), pp. 1-7.

Hinz, O., and Eckert, J. 2010. "The Impact of Search and Recommendation Systems on Sales in Electronic
Commerce,” Business & Information Systems Engineering (2:2), pp. 67-77.

Ho, S. Y., Bodoff, D., and Tam, K. Y. 2011. "Timing of Adaptive Web Personalization and Its Effects on
Online Consumer Behavior," Information Systems Research (22:3), pp. 660-679.

Hosanagar, K., Fleder, D., Lee, D., and Buja, A. 2014. "Will the Global Village Fracture into Tribes?
Recommender Systems and Their Effects on Consumer Fragmentation," Management Science (60:4),
pp. 805-823.

Hurley, N. J. 2011. "Towards Diverse Recommendation,” in Proceedings of the Workshop on Novelty and
Diversity in Recommender Systems at the Fifth ACM International Conference on Recommender
Systems, Chicago, IL, USA.

Kamis, A., Koufaris, M., and Stern, T. 2008. "Using an Attribute-Based Decision Support System for User-
Customized Products Online: An Experimental Investigation," MIS Quarterly (32:1), pp. 159-177.
Koufaris, M. 2002. "Applying the Technology Acceptance Model and Flow Theory to Online Consumer

Behavior," Information Systems Research (13:2), pp. 205-223.

Matt, C., Hess, T., and WeiB, C. 2013. "The Differences between Recommender Technologies in Their
Impact on Sales Diversity," in 2013 International Conference on Information Systems (ICTS 2013),
Milano, Italy.

McNee, S. M., Riedl, J., and Konstan, J. A. 2006. "Being Accurate Is Not Enough: How Accuracy Metrics
Have Hurt Recommender Systems," in Extended Abstracts on Human Factors in Computing
Systems, Montréal, Québec, Canada, pp. 1097-1101.

Pariser, E. 2011. The Filter Bubble: What the Internet Is Hiding from You. Penguin UK.

Park, S.-H., and Han, S. P. 2013. "From Accuracy to Diversity in Product Recommendations: Relationship
between Diversity and Customer Retention,” International Journal of Electronic Commerce (18:2),
pp. 51-72.

Pathak, B., Garfinkel, R., Gopal, R. D., Venkatesan, R., and Yin, F. 2010. "Empirical Analysis of the Impact
of Recommender Systems on Sales," Journal of Management Information Systems (27:2), pp. 159-
188.

16 Thirty Fifth International Conference on Information Systems, Auckland 2014
Escaping from the Filter Bubble?

Podsakoff, P. M., MacKenzie, S. B., Lee, J.-Y., and Podsakoff, N. P. 2003. "Common Method Biases in
Behavioral Research: A Critical Review of the Literature and Recommended Remedies,” Journal of
Applied Psychology (88:5), pp. 879-903.

Randall, T., Terwiesch, C., and Ulrich, K. T. 2007. "User Design of Customized Products,” Marketing
Science (26:2), pp. 268-280.

Ringle, C. M., Wende, S., and Will, A. 2005. "SmartPLS 2.0." Hamburg, Germany.

Senecal, S., and Nantel, J. 2004. "The Influence of Online Product Recommendations on Consumers’
Online Choices," Journal of Retailing (80:2), pp. 159-169.

Simonin, B. L., and Ruth, J. A. 1998. "Is a Company Known by the Company It Keeps? Assessing the
Spillover Effects of Brand Alliances on Consumer Brand Attitudes,” Journal of Marketing Research
(35:1), Pp. 30-42.

Vargas, S., and Castells, P. 2011. "Rank and Relevance in Novelty and Diversity Metrics for Recommender
Systems,” in Proceedings of the Fifth ACM International Conference on Recommender Systems,
Chicago, IL, USA, pp. 109-116.

Veit, D. J., Clemons, E. K., Benlian, A., Buxmann, P., Hess, T., Kundisch, D., Leimeister, J. M., Loos, P.,
and Spann, M. 2014. "Business Models - an Information Systems Research Agenda,” Business &
Information Systems Engineering (6:1), pp. 45-53.

Xiao, B., and Benbasat, I. 2007. "E-Commerce Product Recommendation Agents: Use, Characteristics,
and Impact,” MIS Quarterly (31:1), pp. 137-209.

Zhang, T. C., Agarwal, R., and Lucas, H. C. 2011. "The Value of IT-Enabled Retailer Learning:
Personalized Product Recommendations and Customer Store Loyalty in Electronic Markets," MIS
Quarterly (35:4), pp. 859-882.

Zhang, Y. C., Séaghdha, D. ©., Quereia, D., and Jambor, T. 2012. "Auralist: Introducing Serendipity into
Music Recommendation,” in Proceedings of the Fifth ACM International Conference on Web Search
and Data Mining, Seattle, WA, USA.

Zhou, T., Kusesik, Z., Liu, J.-G., Medo, M., Wakeling, J. R., and Zhang, Y.-C. 2010. "Solving the Apparent
Diversity-Accuracy Dilemma of Recommender Systems,” Proceedings of the National Academy of
Sciences (107:10), pp. 4511-4515.

Thirty Fifth International Conference on Information Systems, Auckland 2014 17
Human Behavior and IS

Appendix

> Diamonds
7 Weean’ Stop

 

Be

Cinderella

 

   

= ater sie Symphony

. Sete Nata amy

> piso Bose

a Super Bass

- ee From The Bottom (Explicit Version)

‘Space City (Feat. Tow Down & Lucky Luciano)

I Need Your Love

Titanium (feat. Sia)

HEHE & @

IWant Your Soul (TV Rock Remix)

 

 

KKK KK

Hee ve ok oe

Wwe

week kx

Kk ik kr

KKK KH

Wek Heke

wHeK KK

Wee we ok ok

wk KK

woke kk

ww K

 

Appendix 1. Screenshot of Rating Phase

 

eT a)

Set Fire To The Rain is p Lights (Single Version)

> >

 
 

Dire

Rolling In The Deep

 
     

Cay  entiomen |

 

5 A Tes Suatoer
. = Kryptonite Cre

Mi Mi
. El amma Miia

Dancing Queen

uw x
A
g z

   

> ABE

3 na In Black

> i awe

z Rollg In The Deep Ecc
. Someone Like You (Live From The Brit Awards 2011)
= sf Fire To The Rain ¥ aA
> Peed

   

Ihr Einkaufskorb (3/5)

 

 

Appendix 2. Screenshot of Purchasing Phase

 

 

18 Thirty Fifth International Conference on Information Systems, Auckland 2014

 
