Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

Burst the Filter Bubble: Towards an Integrated Tool

Full Paper

Alireza Amrollahi

Peter Faber Business School
Australian Catholic University
Sydney, Australia

Email: alireza.amrollahi@acu.edu.au

Abstract

Formation of filter bubbles is known as a risk for democracy and can bring negative consequences like
polarisation of the society, users’ tendency to extremist viewpoints, and the proliferation of fake news.
Previous studies, including prescriptive studies, focused on limited aspects of filter bubbles. The
current study aims to propose a model for an integrated tool that assists users in avoiding filter
bubbles in social networks. To this end, a systematic literature review has been adopted and 571 papers
in six top-ranked scientific databases have been identified. After excluding irrelevant studies and an
in-depth study of the remaining papers, a classification of research studies is proposed. This
classification is then used to propose an overall architecture for an integrated tool that synthesises all
previous studies and proposes new features for avoiding filter bubbles. The study explains the
components and features of the proposed architecture and describes their focus on content and agents.

Keywords: Filter bubble, Social networks, Prescriptive study, Information bubble.
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

1 INTRODUCTION

The notion of filter bubble refers to the impact of our preferences and desires on the content and
results we view on search engines, social media, and other online platforms. This concept has been
central to social media and internet research since it was developed by Eli Pariser (Pariser 2011) and
have been investigated by various scholars using various terms. Some of the terms used in the
literature are information bubble (Liao and Fu 2013), [online] echo chamber (Moller et al. 2018),
personal ecosystem of information (Helberger et al. 2015), partial information blindness (Haim et al.
2018), and information cocoons (Sunstein 2007).

Several undesirable impacts have been mentioned in the literature for filter bubbles. Especially, a
potential risk to narrow the information sources for online users and “pushing users into the
psychological comfort zone of self-confirmation and risking polarisation on a societal level" (Courtois
et al. 2018, p. 2008) that can lead to polarisation of online debates (Seargeant and Tagg 2018) and
even extremism (Costello et al. 2016; Liao and Fu 2013).

To avoid these negative impacts, several studies in the literature have recommended solutions to
understand, avoid, and decrease the negative impacts of filter bubbles. These studies are focused on
various topics including quantification of the bubble in social networks (Hannak et al. 2013),
developing secondary apps (Wood et al. 2018), and approaches to stay anonymous in order to avoid
filter bubbles (Ridgway 2017). However, none of the studies in the literature, offer a comprehensive
and integrated tool to help users avoid the filter bubbles.

To tackle this shortcoming, in this study, we searched seven scientific databases with related phrases
in an attempt to systematically review the prescriptive literature and suggest a conceptual model for an
integrated tool. We investigated these studies based on their aim and approach to avoid filter bubble,
used technology, and the effectiveness of the approach. The results of this research can help future
research to find possible gaps in the literature and provide practitioners with a better understanding of
the tools available to them for avoiding filter bubbles.

The remainder of this paper, in section two, provides a background to the concept of the filter bubble
and posits the current study within the body of research. Section three introduces our methodology
and approach for review and analysis of the literature. In section four the integrated framework is
presented and results are discussed with possible implications for research and practice in section five.
The paper is concluded with explaining the contributions to the body of research in section six.

2 RESEARCH BACKGROUND
2.1 Filter Bubble

Although the notion of limiting sources of information to one’s preferences has been largely studied in
areas such as media (Jamieson and Cappella 2008) and psychology (Nickerson 1998), the application
of this notion on online and social media came under the spotlight after the development of the term
filter bubble.

There are two main research streams on the filter bubble. The first stream (inspired by the work of
Pariser (2011) is mainly focused on the impact of recommendation systems (LR et al. 2018; Nguyen et
al. 2014; Sanz-Cruzado and Castells 2018). These recommendation systems consider the user's
demographic information, history, and search behaviour in suggesting new content by social media
and search engines, creating a filter bubble for the information the user receives.

This stream of research has been increasingly challenged by the second wave of studies that focuses on
the role of social media users rather than recommendation system technologies (Garrett 2017; Moller
et al. 2018). This perspective is supported by empirical research including a study on Facebook content
that found only 5-8% of the content provided to people with various political viewpoints is based on
their profile (Bakshy et al. 2015).

Among previous studies, we found review research by Bozdag and van den Hoven (2015). The study
considers two different perspectives about democracy (namely: liberal view of democracy and
deliberative democracy) and introduces several software designs which have been introduced to
combat filter bubble. The study then suggests design criteria against filter bubble based on the two
models of democracy and concludes that the reviewed tools “do not define the filter bubble explicitly”
and most of them “are performed for US politics” (Bozdag and van den Hoven 2015, p. 263). Except for
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

this comparison of tools, we did not find any research to go beyond algorithmic enhancements of
recommendation systems and investigate possible social concepts leading to the formation of filter
bubbles and how the system can deal with these factors.

2.2 Impacts of filter bubbles

The negative consequences associated with filter bubbles are extensively studied in the literature.
Some of these impacts could be directly associated with the filter bubble. Some examples are a decline
in user trust (Nagulendra and Vassileva 2016), limiting people's access to information (Valdez et al.
2018), and social fragmentation (Moller et al. 2018).

A negative consequence that has been cited more specifically in the literature, is the polarization of
political discussions in social media when people are stuck in a bubble that prevents them from
receiving outsider information (Foth et al. 2016; Lahoti et al. 2018; Quraishi et al. 2018; Thonet et al.
2017; Yang et al. 2017). Previous literature has not found a significant relationship between exposure
to the opposite political view and a change in people's political opinion (Bail et al. 2018). However,
there are many studies which investigated the impact of filter bubbles on commitment to a populist
cause (Postill 2018), avoidance of cross-referencing (Van den Bulck and Moe 2018), creating a risk to
diversity of opinions and well-functioning democracy as a result (Bozdag and van den Hoven 2015;
Dylko et al. 2018).

On the other hand, filter bubble can indirectly impact or result in proliferation of recent challenges in
online media including fake news (Bhatt et al. 2018; Seargeant and Tagg 2018) as they “amplify any
content, from genuine, factual news to emotionally charged, politically biased news” (Rehm 2017, p.
218). As social science studies have found that homogenous groups are more likely to become extreme
in their thinking (Spohr 2017), the formation of these groups as a result of a filter bubble can lead to
extremism. Finally, the negative impacts of filter bubbles have been studied in specific areas. For
example, Taramigkou et al. (2013) investigated filter bubbles in music platforms and how the impacts
platform users’ taste of music. Other researchers have studied the negative impacts of filter bubbles in
areas such as online retail (Matt et al. 2014) and the source of information financial analysts receive
(Shah et al. 2016).

Despite these breakthroughs in the literature, previous studies are less focused on the long-term of
filter bubbles. For example, although there are several studies on the impact of social networks on
extremism (Awan 2017; O'Callaghan et al. 2013; Spohr 2017), no empirical has investigated the impact
of filter bubbles and human authority on the formation of extremist groups.

3 RESEARCH METHOD

The current paper aims to suggest an integrated tool that can deal with the problem of filter bubble in
social networks. To do this a systematic literature review has been adopted and previous prescriptive
studies on bursting filter bubbles have been reviewed. To conduct a systematic literature review the
following steps were undertaken as suggested by Kitchenham and Charters (2007): (1) identifying
resources; (2) study selection; (3) data extraction; (4) data synthesis; and (5) writing up the study as a
report. To follow these steps, we searched six scientific databases: Science Direct, Scopus, ProQuest,
ACM Digital Library, Association for Information Systems electronic library, and Springer Link. Table
1 shows the final set of papers in each scientific database.

 

 

 

Database The first setof The final set of
papers papers

Association for Information Systems electronic library 99 2

Pro Quest 119 5

Science Direct 19 8

Scopus 147 32

Springer Link 146 4

ACM Digital Library 41 20

Total 571 71

 

Table 1 - Distribution of first/final set of papers in different databases

We searched for the following terms in title, keywords and abstracts depending on the services offered
by the relevant search engines:
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

” 6

"filter bubble" or "information bubble" or “social recommendation systems”, “social personalisation”,

” «6 ” 6 ” 6

“news gatekeepers”, “information gatekeepers”, “personalised filtering”, “online echo chamber”

We found 571 papers after our initial search for the above keywords. This number was reduced to 147
papers when reading the titles and abstracts and excluded irrelevant papers. Finally, duplicated papers
included in more than one database were removed and in another round, we referred to papers in full
text to formulate the final pool of 71 papers. Table 2 illustrates the process through which we arrived at
the final pool of research papers.

 

 

Round Number of Papers Number of Papers
Excluded Remaining

The initial list of papers - 571

Exclusion based on the title 107 464

Exclusion based on abstract 317 147

Removal of duplicate papers 9 138

Exclusion based on full text (Final list) 67 71

 

Table 2- Different Stages of Inclusion / Exclusion and Number of Papers in Each Round

For the current paper, we studied all the papers in our pool of 71 papers and focused on those which
were prescriptive and suggested an approach for dealing with filter bubbles. The results of further
analysis on the content of those papers are presented in the future sections. While the study focuses on
the prescriptive approaches suggested in each article to prevent the formation of filter bubbles, there is
less focus on the approach used to evaluate the rigour research data or data analysis. Instead, we have
focused on the robustness of the proposed approach and if it can be applied in practice.

4 RESULTS

The final set of prescriptive papers formed the basis of the results described below. These final papers
are studied in detail, and their advice on how to overcome the filter bubble phenomenon has been
investigated. The results of this study helped us to differentiate two different perspectives in the
reviewed studies on the filter bubble. Each of these perspectives is studied in further detail to
understand and categorise their reeommended approach.

There was a group of papers which proposed approaches to identify the filter bubble. This category
includes identification of the bubble, confirming its existence, and quantification of the impact of the
bubble. The second category of research studies, however, is directly focused on approaches to take
users out of the filter bubble or as we call it in this paper, burst the bubble. Details about each category
are explained below:

4.1. Alert about the bubble

Research studies under this category are focused on the identification and evaluation of filter bubbles.
Filter identification studies are mainly focused on tools that check and alert users (in different ways) if
they are trapped in a filter bubble. Nagulendra and Vassileva (2014) for example, proposed an
interactive visualisation to enable the user to see the filtering. According to the authors, the tool has
four goals which are: awareness, understanding, control of personalised filtering, and to increase the
users’ trust in the system. The tool has implemented and tested on an independent platform.

The authors have extended this tool in their future work (Nagulendra and Vassileva 2016) to include
both content and agent (users) in visualisation. This goal to detect the bubble has been continued in
future studies using different approaches including diffusion of topics (content) (TK et al. 2015),
network theory (agents) (Thonet et al. 2017), and machine learning (Lahoti et al. 2018).

Another stream of research on alerting filter bubble goes one step beyond bubble identification and
considers evaluation and quantification of filter bubbles. Hannak et al. (2013) for example, developed
a methodology for measuring personalisation in Web search results. The proposed methodology
compares different search results on Google considering the attributes of the agent (user) who
performs the search. Also, Matakos et al. (2017) developed an index to measure the tendency of
opinion polarisation in network communities that can lead to the development of filter bubbles. This
measure considers the opinion of agents (users) and the structure of the network.

Despite these studies and a few in-progress studies, no study has been used as a comprehensive
framework for measuring the filter bubble. The proposed frameworks are mainly focused on agent and
less focused on the content. Finally, the proposed frameworks are less applied in real-time on social
networks to show the users existence or significance of a filter bubble.
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

4.2 Burst the bubble

This category of studies explains the suggested approach to disable or decrease the negative impact of
recommendation systems creating filter bubble through exploring new ideas and diverse perspectives.
The first stream of research in this category is formed around bypassing or changing algorithms.
Ridgway (2017) for example, suggest staying anonymous while being online as a solution to avoid
potential filter bubbles. Bozdag and van den Hoven (2015) on the other hand, reviewed possible design
criteria proposed for bursting filter bubble.

Another stream of research under this category is focused on bursting the bubble by extending users’
awareness and encouraging them to explore different ideas. In this stream of research, again the focus
is on either new content or new agents. The majority of studies in our final pool are focused on viewing
new content. Among them, the work of Taramigkou et al. (2013) is the first study we identified that
proposed a methodology helping users to explore new music genres outside their zone of interest.
Webberley et al. (2016) also suggested an algorithm for avoiding filter bubble through focusing on re-
twitting behaviour of users rather the scope of the user’s social circle. Finally, several studies have
suggested applications to enable users to view new content outside their preference (Linder et al. 2018;
Wood et al. 2018).

Recent studies, however, have shifted the focus from content to the agent. Quraishi et al. (2018
proposed a graph partitioning method that exploits social interactions to represent different
viewpoints in a social network. A qualitative evaluation of the proposed method is also presented
based on implementing the method on a dataset retrieved from Twitter. Also, Sanz-Cruzado and
Castells (2018) focused on contact recommendation and based on the concept of weak connection,
proposed an index for diversity. Despite the diversity of research studies in this category, a lack of
focus on the real-time application of the proposed methods in social networks is observable among all
the studies.

5 DISCUSSION

The results of our review indicate that studying the filter bubble phenomenon is an interdisciplinary
research area. Our final pool of research studies includes work from areas ranging from information
systems, information technology, and management to political science, sociology, law, and journalism.
In the analysis of the related literature, we could observe a focus on the content provided in social
networks in few studies in various categories while many others were focused on the users posting the
content (agent) and how they impact the formation of filter bubbles.

Based on the outcome of our review we propose an architecture for an integrated tool that can be
implemented in social networks (regardless of the content type) and help to avoid the formation of
filter bubbles. Based on the outcome of our literature review, we propose two major functions for this
integrated tool: (i) alerting users about a potential filter bubble; and (ii) bursting the bubble.

Under the alert component, the integrated tool first focuses on the identification of a filter bubble.
While many users of social networks are not aware of the filter bubble they were kept in as a result of a
lack of transparency in the algorithms used by social networks (Bozdag and Timmermans 2011), the
tool needs to alert users. As the cause of filter bubbles shift from the recommendation algorithms to
features enabling users to put themselves in filter bubble (Amrollahi and McBride 2019), this is
important to also inform the users about the consequences of their actions. For example, users should
have the right to see how blocking or muting one specific user, may result in missing out a network of
users and their perspective. Therefore, this bubble identification feature should be designed in
connection with a bubble evaluation feature that assesses the significance of the bubble and also can
predict future significance after certain events.

Potential improvements in the recommendation systems have been suggested as a possible solution for
bursting the bubble. However, in the current study we have not considered this as a feature in the
proposed tool. Recommendation systems are not included in the tool for two reasons: (i) the proposed
tool is proposed independent to the social network, type of content they provide, and the
recommendation algorithm they use; (ii) the proposed integrated tool is focused on not only the
recommendation algorithm, but also on social network facilities that enable users to build a bubble
around them. The architecture of the proposed integrated tool is illustrated in Figure 1.

As illustrated in Figure 1, the proposed tool, will focus on both agent and content. It means that in
order to identify filter bubbles (as part of the alert component), both connections of and the content
viewed by the user under study should be investigated. Also, the significance of the bubble should be
evaluated by considering both the recommended content and recommended users. Finally, the
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

awareness of users should be increased by suggesting both novel (out of bubble) content and
connections.

 

 

 

Identify Evaluate Increasing Awareness
QA

ee a
Agent Content Agent Content

Tm ‘ Tm

Figure 1 The proposed architecture for an integrated tool

6 CONCLUSION

Filter bubbles are problematic consequences of modern media and social networks as they create
barriers to rational and diversified dialogue that is necessary for a democratic society. This research
looks at filter bubble as not only a product of recommendation algorithms in social networks but also a
social issue which considers an active role for users building a filter bubble around them.

In the current paper, we proposed an architecture for an integrated tool that can be incorporated into
social networks to prevent the formation of filter bubbles around users. This tool is proposed based on
a systematic review of the literature and classification of the studies under different categories
considering their aim. The proposed components of the integrated tool cover both liberal (through
alert component) and deliberative (through awareness component) models of democracy (Bozdag and
van den Hoven 2015).

The results of our review show a lack of empirical studies on the effectiveness of the proposed tools.
Even those studies which included their empirical results, did so by using test data on developed
hypothetical platforms. Therefore, the application of the proposed methods in social networks should
be considered in future studies. This improvement in future research will lead to a better evaluation of
the effectiveness of the proposed methods which is another shortcoming we identified in the literature.

Based on the results of our literature review, the components of an integrated tool are proposed in the
form of an architecture map. The proposed method, unlike what is proposed in the previous literature,
considers different perspectives on filter bubbles. These perspectives include a concurrent focus on
alerting users about the formation of bubble and bursting bubbles through increasing users’
awareness. The proposed integrated tool also has a dual focus on both content and agent which cannot
be found in the previous literature.

Although the proposed framework in this study is expected to consider various approaches for busting
the filter bubble in the literature, it has not been put to practice as a solution in any social network.

17
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

Therefore, we propose future study to consider this as a principle of implementation and evaluation of
the system. In particular, the results of the current study can inform future studies especially
upcoming design research. Moreover, there is currently no evidence of effectiveness of the proposed
components of the system as a whole. Future studies should focus on the effectiveness of the proposed
approach and check if people in such filter bubbles will break free when given an opportunity. Future
studies can also focus on different parts of the proposed tool and develop algorithms for each part. The
study also proposes a real-time (predictive) bubble evaluation which is not developed in the previous
studies. Finally, the results of this study can benefit practitioners and managers of social networks to
see various avenues for improving their service or possible pitfalls in their social network allowing the
formation of filter bubbles.

7 REFERENCES

Amrollahi, A., and McBride, N. 2019. "How to Burst the Bubble in Social Networks?," in:
24th UK Academy for Information Systems International Conference. Oxford, UK.

Awan, I. 2017. "Cyber-Extremism: Isis and the Power of Social Media," Society (54:2), pp.
138-149.

Bail, C. A., Argyle, L. P., Brown, T. W., Bumpus, J. P., Chen, H., Hunzaker, M. F., Lee, J.,
Mann, M., Merhout, F., and Volfovsky, A. 2018. "Exposure to Opposing Views on Social
Media Can Increase Political Polarization," Proceedings of the National Academy of
Sciences (115:37), pp. 9216-9221.

Bakshy, E., Messing, S., and Adamic, L. A. 2015. "Exposure to Ideologically Diverse News and
Opinion on Facebook,” Science (348:6239), pp. 1130-1132.

Bhatt, S., Joglekar, S., Bano, S., and Sastry, N. 2018. “Illuminating an Ecosystem of Partisan
Websites,” arXiv preprint arXiv:1803.03576).
Bozdag, E., and Timmermans, J. 2011. "Values in the Filter Bubble Ethics of Personalization

Algorithms in Cloud Computing,” ist International Workshop on Values in Design—
Building Bridges between RE, HCI and Ethics.

Bozdag, E., and van den Hoven, J. 2015. "Breaking the Filter Bubble: Democracy and
Design," Ethics and Information Technology (17:4), pp. 249-265.

Costello, M., Hawdon, J., Ratliff, T., and Grantham, T. 2016. "Who Views Online Extremism?
Individual Attributes Leading to Exposure," Computers in Human Behavior (63), pp.
311-320.

Courtois, C., Slechten, L., and Coenen, L. 2018. "Challenging Google Search Filter Bubbles in
Social and Political Information: Disconforming Evidence from a Digital Methods Case
Study," Telematics and Informatics (35:7), pp. 2006-2015.

Dylko, I., Dolgov, I., Hoffman, W., Eckhart, N., Molina, M., and Aaziz, O. 2018. "Impact of
Customizability Technology on Political Polarization," Journal of Information
Technology & Politics (15:1), pp. 19-33.

Foth, M., Tomitsch, M., Forlano, L., Haeusler, M. H., and Satchell, C. 2016. "Citizens
Breaking out of Filter Bubbles: Urban Screens as Civic Media," Proceedings of the 5th
ACM International Symposium on Pervasive Displays: ACM, pp. 140-147.

Garrett, R. K. 2017. "The “Echo Chamber” Distraction: Disinformation Campaigns Are the
Problem, Not Audience Fragmentation," Journal of Applied Research in Memory and
Cognition (6:4), pp. 370-376.

Haim, M., Graefe, A., and Brosius, H.-B. 2018. "Burst of the Filter Bubble? Effects of
Personalization on the Diversity of Google News," Digital journalism (6:3), pp. 330-
343.

Hannak, A., Sapiezynski, P., Molavi Kakhki, A., Krishnamurthy, B., Lazer, D., Mislove, A.,

and Wilson, C. 2013. "Measuring Personalization of Web Search,” Proceedings of the
22nd international conference on World Wide Web: ACM, pp. 527-538.
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

Helberger, N., Kleinen-von Konigsléw, K., and van der Noll, R. 2015. “Regulating the New
Information Intermediaries as Gatekeepers of Information Diversity," info (17:6), pp.
50-71.

Jamieson, K. H., and Cappella, J. N. 2008. Echo Chamber: Rush Limbaugh and the
Conservative Media Establishment. Oxford University Press.

Kitchenham, B. A., and Charters, S. 2007. "Guidelines for Performing Systematic Literature
Reviews in Software Engineering,").

Lahoti, P., Garimella, K., and Gionis, A. 2018. "Joint Non-Negative Matrix Factorization for
Learning Ideological Leaning on Twitter," Proceedings of the Eleventh ACM
International Conference on Web Search and Data Mining: ACM, pp. 351-359.

Liao, Q. V., and Fu, W.-T. 2013. "Beyond the Filter Bubble: Interactive Effects of Perceived
Threat and Topic Involvement on Selective Exposure to Information," Proceedings of
the SIGCHI conference on human factors in computing systems: ACM, pp. 2359-2368.

Linder, R., Stacy, A. M., Lupfer, N., Kerne, A., and Ragan, E. D. 2018. "Pop the Feed Filter
Bubble: Making Reddit Social Media a Vr Cityscape," 2018 IEEE Conference on Virtual
Reality and 3D User Interfaces (VR): IEEE, pp. 619-620.

LR, D., Tamhane, A., and Pervin, N. 2018. "A Clustering Based Social Matrix Factorization
Technique for Personalized Recommender Systems,").

Matakos, A., Terzi, E., and Tsaparas, P. 2017. "Measuring and Moderating Opinion
Polarization in Social Networks," Data Mining and Knowledge Discovery (31:5), pp.
1480-1505.

Matt, C., Benlian, A., Hess, T., and Wei}, C. 2014. "Escaping from the Filter Bubble? The

Effects of Novelty and Serendipity on Users’ Evaluations of Online
Recommendations,").

Moller, J., Trilling, D., Helberger, N., and van Es, B. 2018. "Do Not Blame It on the
Algorithm: An Empirical Assessment of Multiple Recommender Systems and Their
Impact on Content Diversity," Information, Communication & Society (21:7), pp. 959-
977.

Nagulendra, S., and Vassileva, J. 2014. "Understanding and Controlling the Filter Bubble
through Interactive Visualization: A User Study," Proceedings of the 25th ACM
conference on Hypertext and social media: ACM, pp. 107-115.

Nagulendra, S., and Vassileva, J. 2016. "Providing Awareness, Explanation and Control of
Personalized Filtering in a Social Networking Site," Information Systems Frontiers
(18:1), pp. 145-158.

Nguyen, T. T., Hui, P.-M., Harper, F. M., Terveen, L., and Konstan, J. A. 2014. "Exploring the
Filter Bubble: The Effect of Using Recommender Systems on Content Diversity,"

Proceedings of the 23rd international conference on World wide web: ACM, pp. 677-
686.

Nickerson, R. S. 1998. "Confirmation Bias: A Ubiquitous Phenomenon in Many Guises,”
Review of general psychology (2:2), pp. 175-220.

O'Callaghan, D., Greene, D., Conway, M., Carthy, J., and Cunningham, P. 2013. "The Extreme
Right Filter Bubble," arXiv preprint arXiv:1308.6149).

Pariser, E. 2011. The Filter Bubble: What the Internet Is Hiding from You. Penguin UK.
Postill, J. 2018. "Populism and Social Media: A Global Perspective," Media, Culture & Society
(40:5), PP. 754-765.

Quraishi, M., Fafalios, P., and Herder, E. 2018. “Viewpoint Discovery and Understanding in
Social Networks," Proceedings of the 10th ACM Conference on Web Science: ACM, pp.

47-56.
Australasian Conference on Information Systems Amrollahi
2019, Perth Western Australia Burst the filter bubble

Rehm, G. 2017. "An Infrastructure for Empowering Internet Users to Handle Fake News and
Other Online Media Phenomena,” International Conference of the German Society for
Computational Linguistics and Language Technology: Springer, pp. 216-231.

Ridgway, R. 2017. "Against a Personalisation of the Self," ephemera: theory & politics in
organization (17:2).

Sanz-Cruzado, J., and Castells, P. 2018. "Enhancing Structural Diversity in Social Networks
by Recommending Weak Ties," Proceedings of the 12th ACM Conference on
Recommender Systems: ACM, pp. 233-241.

Seargeant, P., and Tagg, C. 2018. "Social Media and the Future of Open Debate: A User-
Oriented Approach to Facebook’s Filter Bubble Conundrum,” Discourse, Context &
Media).

Shah, D., Koneru, P., Shah, P., and Parimi, R. 2016. "News Recommendations at Scale at
Bloomberg Media: Challenges and Approaches," Proceedings of the 10th ACM
Conference on Recommender Systems: ACM, pp. 369-369.

Spohr, D. 2017. "Fake News and Ideological Polarization: Filter Bubbles and Selective
Exposure on Social Media," Business Information Review (34:3), pp. 150-160.

Sunstein, C. 2007. "Republic. Com 2.0." Princeton, NJ: Princeton University Press.

Taramigkou, M., Bothos, E., Christidis, K., Apostolou, D., and Mentzas, G. 2013. "Escape the
Bubble: Guided Exploration of Music Preferences for Serendipity and Novelty,”
Proceedings of the 7th ACM conference on Recommender systems: ACM, pp. 335-338.

Thonet, T., Cabanac, G., Boughanem, M., and Pinel-Sauvagnat, K. 2017. "Users Are Known
by the Company They Keep: Topic Models for Viewpoint Discovery in Social Networks,”
Proceedings of the 2017 ACM on Conference on Information and Knowledge
Management: ACM, pp. 87-96.

TK, A. K., George, K., and Thomas, J. P. 2015. "An Empirical Approach to Detection of Topic
Bubbles in Tweets," 2015 [IEEE/ACM 2nd International Symposium on Big Data
Computing (BDC): TEEE, pp. 31-40.

Valdez, A. C., Kluge, J., and Ziefle, M. 2018. "Elitism, Trust, Opinion Leadership and Politics
in Social Protests in Germany," Energy Research & Social Science).

Van den Bulck, H., and Moe, H. 2018. "Public Service Media, Universality and
Personalisation through Algorithms: Mapping Strategies and Exploring Dilemmas,"
Media, Culture & Society (40:6), pp. 875-892.

Webberley, W. M., Allen, S. M., and Whitaker, R. M. 2016. "Retweeting Beyond Expectation:
Inferring Interestingness in Twitter,” Computer Communications (73), pp. 229-235.

Wood, G., Long, K., Feltwell, T., Rowland, S., Brooker, P., Mahoney, J., Vines, J., Barnett, J.,
and Lawson, S. 2018. "Rethinking Engagement with Online News through Social and
Visual Co-Annotation,” Proceedings of the 2018 CHI Conference on Human Factors in
Computing Systems: ACM, p. 576.

Yang, M., Wen, X., Lin, Y.-R., and Deng, L. 2017. "Quantifying Content Polarization on
Twitter,” 2017 IEEE 3rd International Conference on Collaboration and Internet
Computing (CIC): IEEE, pp. 299-308.

Copyright: © 2019 Amrollahi. This is an open-access article distributed under the terms of the

Creative Commons Attribution-NonCommercial 3.0 Australia License, which permits non-commercial
use, distribution, and reproduction in any medium, provided the original author and ACIS are

credited.

20
