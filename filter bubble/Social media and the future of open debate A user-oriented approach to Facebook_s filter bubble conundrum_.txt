iversity

 

The Open

Un

Open Research Online

The Open University’s repository of research publications
and other research outputs

 

Social media and the future of open debate: a
user-oriented approach to Facebook's filter bubble
conundrum

Journal Item

 

How to cite:

Seargeant, Philip and Tagg, Caroline (2019). Social media and the future of open debate: a user-oriented
approach to Facebook's filter bubble conundrum. Discourse, Context & Media, 27 pp. 41-48.

 

 

 

For guidance on citations see FAQs.

©) 2018 Elsevier Ltd.

KOS® https: / /creativecommons.org/licenses/by-nc-nd/4.0/

Version: Accepted Manuscript

 

Link(s) to article on publisher's website:
http://dx.doi.org/doi:10.1016/j.dcm.2018.03.005

 

 

Copyright and Moral Rights for the articles on this site are retained by the individual authors and/or other copyright
owners. For more information on Open Research Online's data policy on reuse of materials please consult the policies

page.

 

oro.open.ac.uk
Social media and the future of open debate 1

Abstract

Drawing on a two-year project, Creating Facebook, this article explores how the actions and
agency of Facebook users contribute to the distortion of information and polarisation of socio-
political opinion. Facebook’s influence as a channel for the circulation of news has come under
intense scrutiny recently, especially with regard to the dissemination of false stories. While this
criticism has focused on the ‘filter bubbles’ created by the site’s personalisation algorithms, our
research indicates that users’ own actions also play a key role in how the site operates as a forum
for debate. Our findings show that the strategies people use to navigate the complex social space
contribute to the polarising of debate, as they seek to avoid conflict with the diverse members of

their network.

Keywords: context design, Facebook, filter bubbles, intradiversity, media ideologies
Social media and the future of open debate 2

Social media and the Future of Open Debate:

a User-Oriented Approach to Facebook’s Filter Bubble Conundrum

Introduction

This article examines data collected as part of a two-year project, Creating Facebook, to argue
that users’ online actions contribute to the creation of a filter bubble effect and to put forward
user-oriented suggestions for addressing this problem as it impacts on the use of the platform as a
site for discussion of ideas and opinions. Creating Facebook, which explored user perspectives
on the suitability of Facebook as a forum for open debate, reveals how the communicative
strategies that people employ on the site influence their exposure to and engagement with a
diversity of opinion and conflicting worldviews. The concept of the online filter bubble (Pariser,
2011) — the way that personalisation algorithms used in site architectures foreground material
that will be of particular interest to individual users while suppressing stories which may diverge
from or challenge their views — has emerged in recent years as an apparent challenge for
contemporary society. The socio-political implications of the phenomenon, it is argued, include
the polarisation of debate and the spread of false and highly-partisan information (e.g. Solon,
2016), including so-called ‘fake news’. While algorithms are certainly an important element in
the spread of false or fabricated reports about events in the world, we argue in this article that
they are only one side of the story. Of equal importance is what people themselves do, how they
fashion their experience of Facebook as a communicative space through their actions, and how,
in effect, they contribute to the construction of these opinion-ghettos themselves, creating the

conditions in which fabricated and partisan news can more easily be disseminated.
Social media and the future of open debate 3

The research project which informs our argument, Creating Facebook, examined
people’s reflections on their communication via Facebook, with a particular focus on what they
considered suitable behaviour on the site, and how they regulated their own interactions in
response to their emergent beliefs about appropriate behavioural norms. The data is comprised of
the questionnaire responses of over a hundred Facebook users about their experiences of and
beliefs about personal communication on the site (i.e. user-shared status updates), as well as in-
depth follow-up interviews with selected participants. The analysis explores the way that
communication of this sort on Facebook apparently gives rise to recurrent examples of conflict,
disagreement, or a sense of frustration with other interactants, which, we argue, is in part a result
of the specific form of diversity which exists on the site. We refer to this as intradiversity, and
suggest that it results from the type of “ego-centred’ network (Androutsopoulos, 2014, p. 63) that
Facebook facilitates, whereby communication is predominantly structured around the personal
connections of individual users as these are accrued across that user’s biography.

Key to our reasoning for the importance of intradiversity and the way it influences users’
actions is our concept of context design, which we put forward as an important theoretical model
for understanding online communication. Context design, which builds on the concept of
audience design (Bell, 1984) as well as models concerning the interactive construction of context
(Duranti and Goodwin, 1992), illuminates the ways in which Facebook users imagine and
respond to a complex set of contextual variables as they design the style and content of their
interactions. In combination with intradiversity, context design offers a refinement and
enhancement of the widely-used notion of context collapse which has been highly influential in
social science research (Marwick and boyd, 2014), and helps to explain the significance of user

practices within the broader debate about the influence of filter bubbles in online civic discourse.
Social media and the future of open debate 4

Filter Bubbles and their Impact on Civic Discourse

Facebook continues to dominate the global social media landscape and has emerged as an
important outlet for the sharing and consuming of news (as well as discussion around it), with
the Pew Research Center reporting that two-thirds of Facebook users in the United States — or
44% of the general population (Gottfried & Shearer, 2016) — say they get news from the site.
Given its reach, concern has been voiced about the way in which the type of dialogue needed for
balanced and informed public opinion-forming is poorly served by the site (Benton, 2016). This
was particularly considered the case in the aftermath of the rise of the populist movements which
led to the Brexit (Viner, 2016) and Trump (Solon, 2016) victories. The argument voiced in some
quarters following the Trump victory (e.g. El-Bermawy, 2016) is that polarisation, in addition to
misinformation, is causing a break-down in civic discourse. Furthermore, the polarised nature of
debate prevents misinformation from being challenged, thus letting its malignant influence
spread (Read, 2016).

The term ‘filter bubble’ was coined by Eli Pariser (2011) to refer to the concept that a
website’s personalisation algorithm selectively predicts the information that users will find of
most interest based on data about each individual — including signals such as their history of
Likes, search history, and other past online behaviour — and that this creates a form of online
isolation from a diversity of opinions. The concept, which focuses specifically on the
implications of algorithmic personalisation, is a complement to research examining the way that
people choose to read articles that predominantly align with their political opinions, and tend to
share and discuss these with their social groups, thus creating “echo chambers’ of opinion
(Garrett, 2009). In the days before algorithmic personalisation became commonplace, Sunstein

(2007) argued that online communities resulted in people cutting themselves off from opinion
Social media and the future of open debate 5

and information that challenged their belief systems, and that this was likely to have a negative
impact on democratic debate. The development of algorithms, however, has led to a new
situation in which people’s actions are increasingly shaped by processes which are hidden to
most users (Jones, 2016).

On Facebook, the personalisation algorithm is designed to provide an experience for
users which prioritises information which is most ‘meaningful’ to them (Zuckerberg, 2016).
Although this applies to all information that is shared on Facebook, it also includes opinions and
expressions about social or political values as well as news stories, which, so the argument goes,
results in a newsfeed filled predominantly with opinions with which the user agrees — a
phenomenon which Jones and Hafner (2012, p. 126) refer to as the ‘ghetto-ization’ of the
internet. The significance of this, according to Pariser (2011, p. 5), is that “[d]emocracy requires
a reliance on shared facts: instead we’re being offered parallel but separate universes’. Pariser’s
warning relates to the way that civic debate is not best served by intellectual segregation, and
leads more readily to extremism than to consensus. Research shows that when people discuss
issues with those who share their opinion, this leads to more polarized attitudes towards the topic
(Stinchcombe, 2010), whereas exposure to diversity increases people’s tolerance for those with
different or opposing views (Garrett & Resnick, 2011).

It is worth pointing out that other studies have suggested a different phenomenon,
whereby the extensiveness of online networks means that a small but significant fraction of ties
are with people with different political outlooks, which increases exposure to different opinions
(Sharad et al. 2010). Flaxman et al. (2016, pp. 20-21), in their study of online news consumption,
arrive at the conclusion that both the above phenomena seem to occur. Their research points to

an apparent paradox that, although users are pushed towards “ideological segregation’ in terms of
Social media and the future of open debate 6

the information they consume, this is not necessarily linked to a lack of contact with people who
hold divergent views. As we shall show, our user-oriented focus goes some way to explaining
this apparent contradiction by pointing to the interplay between user actions and the algorithm.

The way the discourse over the influence of Facebook’s filter bubble ‘problem’ was
framed in the media in the aftermath of the 2016 US presidential election had a distinct element
of technological determinism to it, at least in headlines which suggest, for example, that “Donald
Trump Won Because of Facebook’ (Read, 2016). In line with the view that the solution to the
filter bubble conundrum lies with the technology, numerous attempts have been made to develop
software which enhance open dialogue and create an environment of open-mindedness (Bozdag
& van den Hoven, 2015). In December 2016 Facebook announced a set of measures to tackle the
problem themselves, including getting readers to flag stories for fact-checking, marking dubious
stories as being ‘disputed’ and dropping them down the newsfeed (Facebook, 2016a).

What these solutions neglect, however, is the role that users’ actions may play in
generating the effects popularly put down to the algorithm. In his discussion of digital
surveillance, Jones (2016) explores how social media communication increasingly involves users
interacting with computer code (that is, algorithms) as well as with the actions and utterances of
other users — a phenomenon he refers to as ‘algorithmic pragmatics’. In communicative
environments like Facebook, users tend to interpret and respond to the computer code as they
would in interaction with other users, inferring the underlying intentions and shaping their
subsequent actions in line with and in anticipation of the algorithm’s response. Jones’s argument
points to the way in which filter bubbles are created not only through the actions implemented
through the algorithm, but through the interactions that take place between the algorithm and the

site users.
Social media and the future of open debate 7

A less technological determinist position to tackling the issue would therefore be that,
with enhanced awareness of the affordances of the technology, people would be better able to
navigate them and respond to any influence the technology does produce. The concept of
affordances (i.e. the set of functional opportunities offered to a user by a platform) is useful here
in foregrounding the role that user responses to technology have in shaping user experience. An
important element of this relationship between platform and user is the way people perceive the
functionalities, and the extent to which they are aware of the range of possibilities available to
them and how these work. Affordances therefore emerge from the interaction that users have
with the technology and their critical awareness. As we discuss below, the beliefs that people
have about a technology have a bearing on what they do with it, and are thus a vital element in
how a particular platform is used as a communicative resource. In other words, affordances are a
product not simply of the design of the technology, but people’s cultural judgements about it as
well as their awareness of its complex and shifting functionalities (Facebook, for example, is
prone to update its software on a very frequent basis).

Returning to the issue of the filter bubble and its role in the spread of fake news, the
appeal of an explanation that focuses almost exclusively on the technology is easy to understand,
as Garrett (2016) has commented, because it suggests that if you alter the algorithm you solve
the problem (and that blame lies solely with the technology company rather than with more
complex social reasons). But as noted above, there is also research showing that people are
exposed to a diversity of viewpoints, which would put into question the extent to which
personalisation algorithms alone are responsible for this closing down of debate. Our project
contributes to this research by highlighting a key communicative dynamic at work in Facebook

interaction — specifically, how users shape and construct the communicative space of Facebook
Social media and the future of open debate 8

in response to their media ideologies and their awareness of audience. It should be noted that
Facebook is now a multifaceted communication space, which not only allows people to interact
by means of posting and commenting on statuses, but also features extensive advertising, as well
as a feed of trending topics (mostly social or celebrity news), all of which is also influenced by
the personalisation algorithm. However, in order to explore how users’ interactions shape
Facebook as a space for the dissemination of various kinds of news, our focus is specifically on
users’ sharing of, and commenting on, contemporary news stories and wider political issues and
the debate that accompanies this. Before moving to the study itself, and an explanation of its
method and rationale, we introduce three key theoretical concepts through which we theorise

user agency and its implications.

User Agency: Media Ideologies, Intradiverse Networks and Context Design

Media ideologies

Our underlying premise is that Facebook as a communicative space is shaped to a significant
degree by its users’ practices, and that these practices are themselves shaped by the ideas users
have about the context in which they interact. The first of these precepts is widely accepted
across social studies of the internet; boyd (2001, p. 121), for example, describes how the
disembodied nature of social media contexts requires users ‘to write themselves into being’ and
to create the context for each of their posts. We theorise the second precept — that users’ actions
are shaped by their understandings of a site — with reference to the concept of media ideologies.
Ideologies are entrenched beliefs about the social world which have a role in structuring the
understandings people have of social reality, and the ways they interpret or justify their actions.

These are understood as being dynamic, and often ‘multiple, competing and contradictory’
Social media and the future of open debate 9

(Schiefflin & Doucet 1998, p. 286). As applied to media, they constitute the beliefs people have
about communication technologies, and their norms and expectations regarding the nature of the
communication facilitated by these (Gershon, 2010). As Gershon (2010, p. 290) argues, the
popularity of social media platforms and their penetration into people’s everyday communicative
lives has led to the development of ‘culturally specific, nuanced understandings of how these
media shape communication’, which includes beliefs about what type of interaction is best suited
to which media. People develop an understanding of these beliefs in complex ways, often by
implicitly negotiating the norms with interactants, as well as, in the case of many of the people in
our study, learning through experience by unwittingly breaching these norms. The ideologies
they then develop become a means for rationalising their own behaviour on the site as well as
justifying their responses to the actions of others. These ideologies are shaped by a number of
different influences, including their current and previous experiences with Facebook, as well as
their evaluation of the site in comparison with other channels of communication with which they
now engage or have had experience of in the past (Madianou & Miller, 2012). These ideologies
can be seen as both emerging from, and shaping, the wider social context. In other words, not
only is how people feel about the site shaped by their experiences with it, but these attitudes go

on to shape the nature of future experiences.

Intradiversity

Another important element in the way people shape their communication relates to their
understanding of the audience for which they are writing, and the diversity of values and
relationship ties this can include. In describing the way this audience is constituted on Facebook,

we have developed the concept of intradiversity. A number of other studies have described the
Social media and the future of open debate 10

way in which the internet helps foster a form of superdiversity — the particularly complex and
often unpredictable social connections which transcend geographical distance — due to the way
contact can be kept up between migrants and their home communities, and the way people from
different cultural backgrounds are brought together in a single online space, often around shared
interests (Androutsopoulos & Juffermans, 2014). We argue, however, that on a site such as
Facebook, where the network is centred around one individual’s personal connections, this is less
likely to be the case. It is also unlikely that the audience for a Facebook post will be primarily
shaped by social characteristics such as national identity, ethnicity or common interests, but that
the diversity will be related to (and limited by) the individual’s life trajectory. That is, the links
which comprise the network are the result of encounters and relationships that have developed
across the user’s biography, and while this affords a certain type of diversity (e.g. the views and
beliefs of relatives from one’s hometown, as well as friends from school or university, plus work
colleagues), it is also likely that the various connections share some initial affinity with the user
which produced the connection in the first place. Our recognition of intradiversity is significant
because the fact that all these different people share the same communicative space makes
diversity very salient and leads to the possibility of people being offended and of inadvertently
causing offence. At the same time, the diverse, close and complex ties which people have with
members of their audience on Facebook — and their existing offline social roles and relationships
—are likely to constrain their behaviour in ways which differ from contexts in which people

interact with strangers.

Context Design
Social media and the future of open debate 11

Our theoretical model of context design accounts for the dynamic, socially co-constructed nature
of context, especially as this is a feature of social media, so as to better understand the particular
nature of online communication. In doing so, it builds on the widely used concept of context
collapse, which describes the way in which people from a variety of different contexts are
brought together in one online space, where they form the potential audience for a user’s status
updates (Marwick & boyd, 2014). The problem this poses in terms of communication is one of
self-presentation, given the fact that users cannot easily vary the way they come across to
different segments of their audience, as they would in offline spaces. While context collapse has
proved valuable in developing theories of networked privacy (Marwick & boyd, 2014), from a
sociolinguistics viewpoint the metaphor of ‘collapse’ does not accurately capture how context is
collaboratively co-constructed in interaction; that is, the extent to which the context of an
interaction is shaped by how interactants choose to position themselves and the linguistic choices
they make. This is particularly salient in online contexts where communication is virtual and
bodiless and where people must create a context for their posts through writing and other
semiotic means (boyd, 2001). This means that a context is not a fixed, predetermined set of
situational factors, and nor does it exist as a discrete entity (Duranti & Goodwin, 1992).

In line with sociolinguistic understandings of context, we argue that offline contexts
defined thus cannot be said to move online and to collapse into other contexts; but rather that
people co-create new contexts in the course of their online interactions. The concept of context
design thus captures the way in which people collaborate to (re-)design and negotiate these
online contexts. In doing so, we build on theories of audience design such as Bell’s (1984) which
similarly offer a more dynamic view of communication than that offered by context collapse,

through their recognition of the way in which speakers actively position their listeners and then
Social media and the future of open debate 12

style their utterances in accordance with their projected ideas about each listener. Unlike
audience design, however, context design takes into account situational factors beyond that of
the participants in an interaction, including the affordances of the site and of digital
communication more generally, local norms of communication, users’ immediate goals, and their
media ideologies.

Although context design is a feature of all forms of interaction, it is of particular salience
in online written interactions because of the enhanced level of reflexivity that often occurs there
(Androutsopoulos & Staehr, 2017), as well as the intradiverse and invisible nature of the online
audience. Importantly, Facebook users must also take into account the multiple trajectories along
which their posts may travel (Blommaert, 2005); that is, the likelihood that their posts will be
shared and thus reproduced and reinterpreted in new contexts. Processes of “entextualisation’
(Bauman & Briggs, 1990) can transform both the meaning and value attached to a post. Given
the large intradiverse nature of social networks on Facebook, and the ease with which digital text
can be copied and distributed, Facebook users must attend to an almost infinite array of
potentially relevant communicative spaces, including not only the multiple contexts made
relevant by their intradiverse audience, but also imagined future trajectories.

Central to context design is the notion of polycentricity (Blommaert, 2005) and the
observation that users orient towards multiple and competing centres of influence as they
construct a context for an online post. Through their actions, people design contexts for their
interactions in ways which draw upon (and, in the process, sustain and extend) existing sources
of authority — the communicative expectations of friends versus those of their parents, for
example — regarding what is deemed appropriate or valued behaviour. Also relevant is the

agency people feel they have in acting on this awareness. Their sense of agency relates to a
Social media and the future of open debate 13

number of different factors, including the communicative strategies they are able to implement in
order to achieve their interactional aims; the resources available to them; and how they (are able
to) use these. Agency can be constrained in various ways, both in terms of limited awareness and
access to resources, as well as existing social roles and the ways in which they are positioned by
others (Tagg & Seargeant, 2016). A focus on the strategies users have available to them, and
how they reflect upon these, is a key element of the methodology involved in investigating the
construction of context. Below we explore the relevance of this theory for understanding the
contribution that users make towards the construction of social media filter bubbles, and how this

relates to the circulation of opinion, information and news.

Creating Facebook: Participants, Data and Methods
The data for this study is drawn from our two-year project, Creating Facebook, and comprises
responses to an online questionnaire and series of follow-up interviews which were conducted
with the online network of the research associate on the project. An invitation to participate was
sent out via personal message to all members of the researcher’s Facebook network in mid-2014,
with a link to the survey also placed on her wall. This link was then shared by a number of her
Friends, thus extending the scope across the network. A total of 184 responses were collected, of
which 43 were discarded as incomplete. The remaining 141 responses were used for analysis.
An online questionnaire — rather than, for instance, face-to-face interviews — was
purposefully chosen in order to access a relatively large and ‘intradiverse’ network of active
Facebook users of the kind that we posit shapes communication on the site. The choice of

individual was motivated by the fact that, as an active user of social media, and as someone who
Social media and the future of open debate 14

had joined the site very early in its development, her network was likely to be representative of
the intradiverse dynamics outlined above.

The questionnaire comprised eighteen questions, and was carried out via the online
platform SurveyMonkey. The choice of distributing the questionnaire via a single individual’s
Facebook account was made in order to access the kind of ego-centred network we wished to
examine. It should be noted that we do not claim any great generalizability for the research; with
Facebook having a global reach of over 2 billion users (Facebook, 2016b) any qualitative study
is necessarily partial. Yet the approach does offer a means of evaluating precisely the kind of
intradiversity that we posit shapes interaction on the site. The social characteristics of the
participants were shaped by the node user’s age and gender, as well as her travels (most notably
in Japan and China), her life trajectory (including working abroad as a teacher of English) and
the various kinds of connections she has made along the way: close friends, acquaintances,
colleagues, and so on.

The survey questions were divided into two sections: those asking general demographic
details and information about individuals’ engagement with Facebook; and those soliciting
longer answers about what people do and do not post and the rationale behind their practices.
The aim was to encourage respondents to reflect on how they understood the diversity of their
audience, the site affordances, and their own agency in navigating the online space, as well as the
strategies they use when doing so.

As noted above, the focus was specifically on the interaction which took place around
status updates and comments as well as the sharing of news, rather than content generated by
Facebook itself, such as its trending topics section, or adverts or other featured posts. The

decision to limit the focus in this way was because the project as a whole was investigating
Social media and the future of open debate 15

social relations on the site, as illuminated by users’ reflections on their interactions with each
other. Although we did not ask participants specifically about this, it is likely that many of the
status updates that they found offensive were themselves comments on news articles that the
“offender” was simultaneously sharing.

Most of the questions were open-ended ones which invited respondents to elaborate in
depth on their answers and thus yielded rich qualitative data. From amongst respondents who
had evidenced particularly strong media ideologies in relation to their Facebook user, a selection
were approached to take part in follow-up interviews and we eventually conducted interviews
with three of the respondents — more was not deemed necessary given the richness of the survey
data. These were semi-structured, and conducted via online voice calls, which allowed
participation irrespective of physical location. The supporting interviews gave us the opportunity
to reconstruct these participants’ media ideologies in a more coherent way and, although this is
not the focus of the present article, they therefore supplemented the main data set. Consent for
the use of the data in the research project was collected from all those who took the
questionnaire, and precautions were put in place to ensure participants’ data were collected and
stored in a secure manner. Questionnaire and interview responses have also been anonymised,
with pseudonyms used for the interviews (Heather, Jessica and Jacob).

In analysing the data, we adopted what we call a ‘thematic-discourse analytic approach’.
This involved reading through the data to identify key themes (Guest, 2012), the selection of
which was influenced in part by the research questions for the project, as well as current
literature around relevant topics. We took care, however, not to impose a pre-existing framework
on our dataset, and instead watched for emergent themes, in this way adopting a data-driven

approach. Analysis then focused on the discourse generated by the questionnaire and interviews,
Social media and the future of open debate 16

paying close attention to the ways our respondents’ attitudes and perceptions were expressed
linguistically. We were thus able to identify and categorise the various stances toward
communication via Facebook which people discursively constructed in their answers, with

particular focus on reflections around agency.

Results and Discussion

Our focus in this article is primarily on responses to questions in the survey which asked about
the participants’ experiences of offence on Facebook, as a means of for exploring how user
actions create the experience they have of Facebook. As will be illustrated, this has particular
relevance for the ways in which information (including both news and opinion) is circulated, and
the way the construction of the communicative environment leads also to the construction of
social perspectives in terms of the views, opinions and information one accesses. The extracts
used below are taken from two questions asking participants to reflect on what they had been
offended by, and what happened as a result (Q26); and whether and how they had changed what
they write on Facebook in response to having offended (Q31). Reflexivity over the concept of
offence served as a catalyst for discussion around participants’ beliefs regarding the sort of
discursive space Facebook was or should be, and the nature of interactions — especially over
political or controversial topics — which took place on it. We break the analysis up under a
number of broad headings which identify the most salient ideologies underlying people’s

reported behaviour.

Being Offended by Divergent or Inaccurate Views on Politics and Other Issues
Social media and the future of open debate 17

The first point of note is that a majority of those surveyed (60%) said they had been offended by
others — and were able to recall specific instances, often in some detail. For most of those who
had been offended (69 of 78 responses), the flashpoint for disagreement was issues around
politics, or other topics considered controversial, as well as remarks considered racist or

misogynistic. The following extracts illustrate the issues raised across the survey.

[1] Political things that I don't agree with, particularly negative posts about Obama, or against
homosexuality. I have unfriended homophobic people, and turned off posts from a relative who
has different political values. [Q26-15]

[2] Some people can be very ignorant to other peoples views and lives. Comments on

immigration, Britishness, poverty, and racism have led me to delete friends in the past. [Q26-75]

What these and other responses suggest is that it is not unusual for Facebook users to be faced
online with an array of divergent opinions, at least not in the case of the network of users who
participated in our project, despite the alleged role of the personalisation algorithm in reducing
people’s exposure to different viewpoints. We explain this in part by reference to the intradiverse
nature of most people’s online networks, and the various factors — social background, education,
values — that constitute this kind of diversity.

A number of respondents claimed they were offended not by opinions they disagreed

with but rather when they felt other people had not checked the accuracy of their posts.
Social media and the future of open debate 18

[3] Recently, a bunch of friends posted things on Facebook about welfare recipients during
tax season. It was both rude in my opinion, but also factually inaccurate. I posted some facts
on my page because it made me so mad. [Q26: 5]

[4] Stuff that I will respond to includes a lot of pseudoscience new age stuff. It doesn't

offend me so much as annoy me it people don't verify facts. [Q26: 22]

The issue of inaccurate information was elaborated on in interview by Jessica, who repeatedly
expressed her feeling that what she wanted to access on Facebook — and what she considered as
desirable normative behaviour — was ‘verifiable’ information (supported by evidence she could

check) rather than people’s opinions.

[5] I do read some of what people post but I am also, I am getting to the point where I
don’t want to read about your opinion. I want to read about some factual information that
is coming from a credible source ..._ Because it is great that you have got your opinion but
you are just sitting at your computer, the same as I am, re-posting and typing and it is not
verifiable and if you are not actually linking something that is an external source that I can
see and go ‘oh really, that is something that I have learned’ it just kind of becomes lazy

and an argument for the sake of arguing [Jessica, interview]

There are two issues of particular interest here. The first is the fairly obvious point that the way
Facebook operates as a hybrid media-communications platform means that opinion and fact are
mixed or juxtaposed to a far greater degree than they are for ‘traditional’ media platforms. In

other words, a different level of criticality needs to be employed when consuming information on
Social media and the future of open debate 19

the platform, yet as we can see from Jessica, this is not something she is unaware of, or unable to

deal with, but simply something she finds frustrating.

The second point of interest is that these users are claiming to receive information which they
identify as false (as well as that with which they disagree), and that they seem willing to look
beyond the post itself to check the facts. In other words, these users claim not to blindly accept
what is posted on Facebook but to engage with and challenge it. Another point of note is that the
way Jessica presents her perspective (‘I am getting to the point where ...’) implies that her ideas
about communication on Facebook have developed in response to prolonged experience on the
site. Specifically, this experience has presumably been negative, in the sense that Jessica has
become tired of reading what she sees as unverifiable opinions, and this has led to her belief that
Facebook is best suited for the exchange of evidence-based facts. How Jessica responds to this
through her future actions on the site constitutes her attempt to redesign the online context in line

with her emergent media ideologies.

Responses to being Offended

In explaining what people did in response to having been offended, a clear picture of the ways in
which users design the context of their Facebook experience emerges. Our respondents reported
a number of different strategies for dealing with offensive or inaccurate posts. Most of these
come under the general heading of avoidance; that is, users responded by either unfriending the

offender or blocking their posts so that they were no longer exposed to them.
Social media and the future of open debate 20

[6] When I start realizing some one's option is very divergent, especially when it contains
any kind of prejudice, I tend to remove that person. [Q26-39]
[7] [know someone who posts quite racist comments. I cannot defriend her so have

simply adjusted things so I never see her posts. [Q26-2]

These acts of avoidance constitute cases of context design, based on users’ experiences of the
site over time. In [6], the user suggests that their decision to ‘remove’ someone from their
newsfeed is based on their evaluation of that person’s political stance as markedly different from
their own, as evidenced in their repeated posts.

As suggested in [7], users also take into account the nature of their connection with the
offender; in this case, [7] appears not to have taken more radical action than blocking an
offender’s post because she is someone they ‘cannot defriend’. In other words, the decision about
what sort of action to take depends to some extent on the nature of the tie, with close or strong
ties prompting different behaviour to distant or weak ties. The variety of ties between individuals
within a network on Facebook — and the fact that the audience for any one post on Facebook will
comprise people with very different ties to the poster — is a crucial aspect of intradiversity. The
importance of the nature of particular social ties in determining how people respond to being
offended is also evident in the following example in which the respondent claims to try to

resolve disagreements only with close or ‘real’ friends.

[8] If I find someone is continually posting things that I find distasteful or against my

beliefs, and I have no genuine friendship with them (i.e. they're an acquaintance from
Social media and the future of open debate 21

junior school) I'll defriend them. If they're my real friends we'll talk in person about

disagreements of views. [Q26-30]

The examples so far belie some of the complexity inherent in such social judgements. In
[9] below, the user points to the polycentric nature of contemporary life (Blommaert,
2005) and the negotiation involved in orienting to different contexts of value as these are
manifest in different situations; as someone from a Jewish family, s/he is offended by
comments that a ‘good friend’ makes; but their friendship and the fact that the offender is

‘thoughtful and informative’ in other respects mitigates against the need to unfriend them.

[9] I have a good friend who occasionally posts anti-semitic comments, and this can be
offensive to me as my family is Jewish. I have considered defriending him but don't

because many of his other posts are quite thoughtful and informative. [Q26-65]

Furthermore, judgements as to whether offenders can be unfriended or blocked are made
not only on the basis of the underlying relationship with the offender, but also on a myriad
of other factors implicated in their relationship. In [10], the user suggests that they cannot
unfriend people whose religious views they disagree with because of the wider offline
context in which they know them — the workplace — and their desire not to unsettle the

working environment.

[10] Usually it [disagreement or conflict] is with facebook friends that I need to be friends

with to keep the peace at work. They tend to be very conservative Christians with very
Social media and the future of open debate 22

dichotomous from my ideology etc. I usually just ask to unsubscribe from their posts.

[Q26-9]

One final example involves our interviewee Heather who reported being offended such that ‘I am
getting to the point where I just take things out my news feed’ but who also claimed that another
consideration guiding her decisions as to how to respond to offensive posts lay in her judgement
as to how the offender was likely to respond to a confrontation (whether she judges ‘there is a
chance of making a comment and educating them’), based presumably on her knowledge of the
individual and their shared communicative history. As with Jessica, Heather’s phrase, ‘getting to
the point where’ gives a sense of how repeated exposure to particular types of behaviour feeds
into emerging media ideologies and thus future behaviour.

In these examples, we can see that acts of context design on Facebook are shaped not
only by people’s experience of being offended on the site, and their assessment of offenders’
ideological or political viewpoints, but also the nature of their relationship with the offender,
their shared communicative history, the wider contexts in which they interact, the overlapping
networks to which they belong, and their assumptions about the likely future scenarios that
confrontation would lead to. In most cases, respondents report a tendency to avoid conflict —
overwhelmingly they claim not to engage in debate, for example — and instead to deal with the
perceived offence by reducing the likelihood of future offences by blocking that user’s posts or
removing them as a Friend. In this incremental fashion, they are likely to inadvertently redesign

their newsfeed in a way which renders it increasingly inoffensive and accurate (to their mind).

Offending Others
Social media and the future of open debate 23

In relation to the question of offending others, 32% (n=41) respondents claimed that something
they had posted on Facebook had offended someone else. When prompted, the respondents
talked of self-censoring to ensure they do not inadvertently provoke conflict themselves. This
often involves careful scrutiny of posts, and it is driven, in the main, by three dominant
motivations. The first occurs where users avoid particular behaviour because they have been

offended by it in the past:

[11] I wouldn't write poor me' messages because I've found other people doing that really
annoying! I think Facebook is a good tool for communicating and sharing but if you have real

problems seek help in the real world. [Q3 1-24]

In [11], for example, the user avoids writing a particular kind of post (‘poor me’ messages)
because they find it annoying when others do it. This reactive practice — to avoid engaging in
behaviour which a user has seen and disliked in other people’s posts — was a recurring theme
across the data. The second, related motivation is for users to avoid a certain behaviour because

they have seen over time that it has offended others when people have engaged in it.

[12] i'm careful anyway, but yeah people getting upset has made me more cautious. [Q31-10]

The final motivation relates to examples where users modify their behaviour in direct response to

their having offended others in the past. In some cases, the change in behaviour can be

specifically attributed to a particular instance.
Social media and the future of open debate 24

[13] A cousin publicly posted a meme-style pic of Jesus casually throwing the word "fuckin'
into a public statement. I commented telling her I'd unfriend her if she was going to keep doing
that kind of thing. She got really upset that I'd commented that way on her wall. I deleted my
comment, apologized, and thought a lot more about what should be said and done in private and

what in public. [Q26-28]

These examples also illustrate the complex way in which communicative norms are organised on
the site: evident in [13], for instance, is the user’s (growing) realisation that actions that may be
appropriate “in private’ may not be well received in the relatively more public space of
someone’s wall. The comments suggest that these are emergent norms which users pick up

through interaction on the site.

Facebook as a Space for Debate

Another aspect of people’s ideas about the site that was often mentioned by respondents was that
Facebook is simply not a good place for debate. Jacob, for example, argued in interview that the
site is not suited to ‘fruitful genuine’ debates, and instead ‘I would much rather do it face to

face’, and similar points were made by other respondents:

[14] I have a particularly hard time with pro-gun posts. ... I really, really wish guns were
significantly less accessible and less glorified in American culture. Still, I don't think
Facebook is really the place that people chose to listen to opposing views, so I usually

ignore posts of that nature. [Q26-4]
Social media and the future of open debate 25

A related belief is that the affordances of digital communication — the fact that people are not co-
present and must rely on graphic means to signal attitude and intention — limit the effectiveness

of Facebook as a place for debate. Heather, for example, felt:

[15] you can misconstrue certain comments ... I mean the obvious thing about tone, about the
way we write something. I say something that is in my head or if people know me really well
they would know how I would say it and respect me for saying it, whereas in that situation

[Facebook] it has lost me friends. [Heather, interview]

The observation that people tend not to think of Facebook as an appropriate place for debate is
supported by the handful of people who claimed to have responded to an offence in a context

other than on Facebook:

[16] Nothing happened as a result other than that I ranted about it to someone. I took no

action on Facebook. [Q26-38]

These beliefs about Facebook may go some way towards explaining the tendency for users to
report not responding to offensive posts by challenging the offender or engaging them in debate.
If so, then it is a belief that likely contributes to the creation of a filter bubble-like effect, as users

instead seek to remove divergent views from their newsfeeds.

Conclusion: Context Design and Filter Bubbles
Social media and the future of open debate 26

The findings from our research project show, firstly, that Facebook, at the time of the study, was
being used as a place for sharing news stories and opinions about them, and airing political
views; and, importantly, that viewpoints around political and other contentious issues were
among the most likely cause of offence for users. The likelihood that the voicing of such
opinions will offend others can be explained with reference to various affordances and features
of social media interactions, among them the intradiverse nature of most Facebook users’
potential audience; that is, the fact that despite some similarities in class, education levels or
values, Friends are likely to diverge in their thinking around particular issues, given the way in
which people orient to multiple, often competing centres of influence. What is important is that,
because of their intradiverse networks, users are coming across divergent opinions and
alternative viewpoints, as well as information they deem to be inaccurate or false, despite the
Facebook personalisation algorithm working to feed them posts which are likely to appeal most
to them — and which in media commentary is often interpreted as being those which consist of
news stories, opinions and values with which they are likely to agree.

Secondly, the ways in which most participants reported responding to acts of
unintentional offence show how many people purposefully avoid conflict on Facebook, in part
because of their attempts to navigate and manage the complex set of social relations which make
up their online audience. Through these actions, they create and maintain a sense of online
conviviality — a term we use to describe the desire for non-confrontational co-existence through
negotiating or ignoring difference and avoiding contentious debate (for uses in non-online
contexts see, for example, Blommaert 2013). As an interactional principle, online conviviality on
Facebook appears to encourage users not to challenge or engage with difference (with what they

see as inaccurate or offensive material), but to quietly ignore it. Another apparent reason behind
Social media and the future of open debate 27

people’s lack of engagement with contentious views or disagreeable stories was their explicitly
expressed opinion that Facebook was not ideally suited for effective debate. This mix of media
ideologies about Facebook thus leads people to filter out of their newsfeed views and
information with which they do not agree.

Throughout our analysis, we have shown how this process can be theorised through the
concept of context design. Context design posits that social media users draw on particularly
complex sets of contextual variables in designing a context for each post. We have seen how
posters of content on Facebook draw not only on their ideas about the purpose and
communicative norms of the site, but also on the particular nature of their relationships with
different people and their shared communicative histories, the wider offline contexts with which
different interlocutors are associated, the overlapping social networks within which both the
poster and their audience operate, and their previous experience on the site. When a user offends
or is offended, they draw on consideration of all these variables in shaping their future
behaviour, which in tum contributes towards determining the nature of communication on the

site. Participants in our study expressed some awareness of this, with Jacob stating:

[17] the topics that are chosen actually end up shaping what Facebook is for many people, so I
think in choosing to talk about different topics, that becomes their Facebook experience [Jacob,

interview]

The idea that users ‘control [their own] experience’, is also one of the principal values Facebook
advertises for its newsfeed: ‘[u]ltimately, you know what’s most meaningful to you - and that’s

why we’ve developed controls so you can customize what you see. Features such as “unfollow,”
Social media and the future of open debate 28

“hide” and “see first” help you design your own experience’ (Facebook, 2016c, italics added).
Actions such as these are noted by the algorithm, which reads them as ‘signals that you’ re [more
or] less interested’ in seeing similar content in future, and it is this aspect of the process that has
been highlighted in public and academic discussions around filter bubbles and fake news. But
our research draws attention to the role that user agency plays in that process, showing that
people’s role in shaping their own newsfeed can be explained in terms of context design. An
important point in this respect is the fact that news stories which originate with established news
media is circulated by and because of social relations — in other words, the media is mediated by
the friendships you have with the people in your network. Although, as was noted above, stories
are also circulated via the trending topics feature, and in some cases via advertisements (those for
news outlets themselves, for example), the core dynamic at the heart of Facebook is still social
sharing, which results in the fact that material in your newsfeed, whatever the original source,
has, as part of the context in which you view it, associations with the person who shared it. We
argue therefore that this focus on people’s actual communicative behaviours is a vital counterpart
to the quantitative work being done around the influence of the algorithm on information flows.
Our approach is aimed at assisting understanding of the ways that online behaviour is shaped not
solely — or even primarily — by the technology, but by the beliefs that users have about what the
technology is best suited for, how they use it for this purpose, and the norms they develop in
doing this. It is ultimately these beliefs that lead to the construction of an online social space in

which false news can — or cannot — easily spread.
Social media and the future of open debate 29

References

Androutsopoulos, J. (2014) Languaging when contexts collapse: audience design in social
networking. Discourse, Context and Media, 4-5, 62-73.

Androutsopoulos, J., & K. Juffermans (2014) Digital language practices in superdiversity:
introduction. Discourse, Context and Media, 4-5, 7-18.

Androutsopoulos, J., & A. Staehr (2017) Moving methods online: researching digital language
practices. In Creese, A. and A. Blackledge (Eds) The Routledge handbook of language
and superdiversity. Abingdon: Routledge.

Bauman, R., & C.L. Briggs (1990) Poetics and performance as critical perspectives on social life.
Annual Review of Anthropology, 19, 59-88.

Bell, A. (1984) ‘Language style as audience design’ Language in Society, 13/2, 145-204.

Benton, J. (2016) The forces that drove this election’s media failure are likely to get worse,
Nieman Journalism Lab, 9 November, available at www.niemanlab.org/2016/1 1/the-
forces-that-drove-this-elections-media-failure-are-likely-to-get-worse/

Blommaert, J. (2005) Discourse: a critical introduction. Cambridge: Cambridge University
Press.

Blommaert, J. (2013) Ethnography, superdiversity and linguistic landscapes: Chronicles of
complexity. Bristol: Multilingual Matters.

boyd, d. (2001) Taken out of context: American teen sociality in networked publics. Unpublished
doctoral thesis, University of California, Berkeley.

Bozdag, E., & van den Hoven, J. (2015) Breaking the filter bubble: democracy and design.

Journal of Ethics and Information Technology, 17/4, 249-265.
Social media and the future of open debate 30

Duranti, A., & C. Goodwin (Eds) (1992) Rethinking context: Language as an interactive
phenomenon. Cambridge: Cambridge University Press.

El-Bermawy, M. M. (2016) Your filter bubble is destroying democracy, Wired, 18 November,
www.wired.com/2016/1 1/filter-bubble-destroying-democracy/

Facebook (2016a) . Retrieved from: http://newsroom.fb.com/news/2016/12/news-feed-fyi-
addressing-hoaxes-and-fake-news/ (accessed 20 December, 2016)

Facebook (2016b) Retrieved from:http://newsroom.fb.com/company-info/ (accessed 20
December, 2016)

Facebook (2016c) News Feed Values. Retrieved from: https://newsfeed.fb.com/values/

Flaxman, S., Goel, 8S. & Rao, J. (2016) Filter bubbles, echo chambers, and online news
consumption. Public Opinion Quarterly, doi:10.1093/poq/nfw006

Garrett, R. K. (2009) Echo chambers online? Politically motivated selective exposure among
internet news users. Journal of Computer-Mediated Communication, 14, 265-85.

Garrett, R. K. (2016) Facebook’s problem is more complicated than fake news. Scientific
American, 17 November. Retrieved from: www.scientificamerican.com/article/facebook-
s-problem-is-more-complicated-than-fake-news/

Gershon, I. (2010b) Media ideologies: an introduction. Journal of Anthropology, 20/2, 283-293.

Gibbs, S. (2016) Google alters search autocomplete to remove 'are Jews evil’ suggestion, The
Guardian, 5 December. Retrieved from:
www.theguardian.com/technology/20 16/dec/05/google-alters-search-autocomplete-
remove-are-jews-evil-suggestion

Goel, S., Mason, W, & Watts, D. J. (2010) Real and perceived attitude agreement in social

networks. Journal of Personality and Social Psychology, 99/4, 611-621.
Social media and the future of open debate 31

Gottfried, J., & Shearer, E. (2016) News use across social media platforms 2016. Pew Research
Center, 26 May. Retrieved from: www.journalism.org/20 16/05/26/news-use-across-
social-media-platforms-2016/

Jones, R.H. (2015) Surveillance. In Georgakopoulou, A. and T. Spilioti (Eds) The Routledge
handbook of language and digital communication (pp. 408-411). Abingdon: Routledge.

Madianou, M., & D. Miller (2012) Polymedia: towards a new theory of digital media in
interpersonal communication. /nternational Journal of Cultural Studies, 16/2: 169-187.

Marwick, A., & boyd, d. (2014) Networked privacy: how teenagers negotiate context in social
media. New Media & Society, 16/7, 1051-1067.

Pariser, E. (2011) The filter bubble: What the Internet is hiding from you. London: Penguin.

Pressman, A. (2016) Facebook resists label as media company, Fortune, 25 Oct. Retrieved from:
http://fortune.com/2016/10/25/facebook-resists-media-company/

Read, M. (2016) Donald Trump won because of Facebook. New York Magazine, 9 Nov.
Retrieved from: http://nymag.com/selectall/2016/11/donald-tramp-won-because-of-
facebook. html

Schiefflin, B., & R. Doucet (1998) The “real” Haitian Creole: ideology, metalinguistics, and
orthographic Choice. In Schieffelin, B. K.A. Woolard, & P.V. Kroskrity (Eds) Language
ideologies: Practice and theory (pp. 285-316). New York: Oxford University Press.

Sharad, G. Winter Mason, W., & Watts, D. J. (2010) Real and perceived attitude agreement in
social networks. Journal of Personality and Social Psychology, 99, 611-21.

Solon, O. (2016) Facebook’s failure: did fake news and polarized politics get Trump elected?
The Guardian, 10 November. Retrieved from:

www.theguardian.com/technology/20 16/nov/10/facebook-fake-news-election-
Social media and the future of open debate 32

conspiracy-theories?

Stinchcombe, A. L. (2010) Going to extremes: How like minds unite and divide. Contemporary
Sociology: A Journal of Reviews, 39, 205-206.

Sunstein, C. R. (2007). Republic.com 2.0. Princeton: Princeton University Press.

Tagg, C., & P. Seargeant (2016) Negotiating social roles in semi-public online contexts. In
Leppanen, S., 8. Kytéla, S$. Peuronen, H. Jousmaki, & E. Westinen (Eds) Discourse and
identification: diversity and heterogeneity in social media practices. Abingdon:
Routledge, pp. 211-234.

Tavernisedec, S. (2016) As fake news spreads lies, more readers shrug at the truth, New York
Times. Retrieved from: http:/Avww.nytimes.com/2016/12/06/us/fake-news-partisan-
republican-democrat.html

Van Leeuwen, B. (2010) Dealing with urban diversity: promises and challenges of city life for
intercultural citizenship. Political Theory, 38, 631-657.

Viner, K. (2016) How technology disrupted the truth, 7he Guardian, 12 July. Retrieved from:
www.theguardian.com/media/20 16/jul/12/how-technology-disrupted-the-truth/

Zuckerberg, M. (2016) 11 November. Retrieved from:

www .facebook.com/zuck/posts/10103253901916271
