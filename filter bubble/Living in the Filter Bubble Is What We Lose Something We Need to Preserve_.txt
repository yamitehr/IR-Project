ACADEMIA

Accelerating the world's research.

Living in The Filter Bubble: Is What
We Lose Something We Need to
Preserve?

Krzysztof J Jankowski

Cite this paper Downloaded from Academia.edu4

Get the citation in MLA, APA, or Chicago styles

Related papers Download a PDF Pack of the best related papers 7

ary Bursting the Filter Bubble: Democracy, Design and Ethics (PhD Thesis)
Engin Bozdag

Bias in algorithmic filtering and personalization
Engin Bozdag

Breaking the filter bubble: democracy and design
Jeroen van den Hoven, Engin Bozdag
Research Paper

Living in The Filter Bubble

 

Is What We Lose Something We Need to Pre-
serve?

By Krzysztof J. Jankowski

November 26", 2014

University of Ottawa, Faculty of Law
Living in The Filter Bubble

Table of Content
I How We Consented to Live in the Filter Bubble
1. Filtering of Information
2. Internet Search Engines
3. Do We Live in the Filter Bubble?
IL. Personalized Filtering - What Can We Lose? Search Engine Bias and Democracy.
ll. Is There Space For Regulation? Responsibility Over Comfort.

Key words: search engines bias, filter bubble, search engine, information filtering,

personalization search, personalized services.

Abstract

This paper examines the negative consequences of the filter bubble phenomenon,
described by Eli Pariser in his book “The Filter Bubble. What the Internet Is Hiding from You”—
the limitation of access to certain information due to the excessive and constant personalization
of the content on web. The focus is given to the special role the search engines like Google,
Yahoo or Bing play in the creation of filter bubble. The general aim of this paper is to raise
awareness about the drawback of the current situation, to highlight possible threats posed to the
deliberative democracy and briefly examine the possible solutions. Although it is arguable, the
problem we might be facing with the personalization of Web and search results is that it poses a
number of threats to the democratic society as well as to the values embodied in it e.g. freedom
of speech, access to information or pluralism of opinions.

The first chapter examines the filter bubble phenomenon in the context of how search
engines contribute and might contribute to its existence. In this author’s view, although the
search engines are just one of the personalized services creating the filter bubble, because of the
role they play as actual information intermediaries in the information-based society, they are one
of the most important factors in creation or destruction of the filter bubble. The part of the

present paper discusses this interplay between search engines and information cocoons in which

1
Living in The Filter Bubble

we apparently live. The second chapter examines the threats posed by the filter bubble and so
thus by the personalized Web search services. Following Sunstein’s thought, this paper assumes
that the requirement of the deliberative democracy is not only that citizens have freedom of
speech and the right to pluralism of thoughts, but that they are effectively exposed to other’s
views and opinions. Being close in the filter bubble does not allow that to the significant degree,
therefore it is possible that although the search engines do not block access to certain
information, but somehow ‘hide’ it from users, that might be sufficient to pose a threat to the
effective functioning of the exchange of opinions and thought, so thus to the deliberative
democracy in general.

Should then this issue be regulated? How? This issue is discussed in the final chapter of
the paper, which suggest, that while the legal regulation is possible and needed, the field where
the changes could happen now more easily and likely are social norms on the use of search
engines. On the one hand, as to the principle, the public enjoys personalized content of the Web,
as well as enhanced search results which it finds more accurate and helpful Gndividual interest).
On the other hand, as indicated previously, the public interest might be endangered. Any
discussion on possible regulation needs to acknowledge two opposite points of view. Therefore,
the question of regulation remains not easily solvable. Following Lessig’s Code, the author
examines whether the solution to the identified problem might be found through the change of
architecture, social norms, and law or by the market forces. At the end of the day, the author
suggests that the issue of the filter bubble and search engines appear to be a moral question on
civil responsibility and therefore the first response to it could be found in the proper shaping of
social norms. The ultimate response to the phenomenon of the filter bubble depends from the
choice of values to be made by the members of society — little comfort or small act of social

responsibility in pursue of protection of democratic values? Individualism over collectivism.
Living in The Filter Bubble

“Democracy requires citizens to see things from one another's point of view, but instead, we're
more and more enclosed in our own bubbles. Democracy requires a reliance on shared facts;
instead we're being offered parallel but separate universes.”

Eli Pariser, The Filter Bubble. What the Internet Is Hiding from You.

I. How We Consented to Live in The Filter Bubble

“Imagine a future in which your interface agent can read every newswire and newspaper and
catch every TV and radio broadcast on the planet, and then construct a personalized summary.
This kind of newspaper is printed in an edition of one. (...) Call it the Daily Me.”

Nicholas Negroponte,” 1995

This chapter aims to depict the several elements of our reality and to provide an
explanation of the circumstance, which (as we are going to see in the second chapter) might pose
certain threats to the deliberative democracy. In my opinion, the filter bubble, to which creation
the search engines greatly contribute, poses certain threats as to the quality of pluralism of
thoughts and ideas which we enjoy as society, and therefore to the deliberative democracy too.
While I second the need of certain legal regulation of search engines, in my view the proper
response to the indicate threat, currently could happen primarily thought the change of social
norms. Ultimately, this response to the said threat might depend on choice between responsibility
and comfort.

The present paper is divided into three parts, from which the first one aims to depict the
situation which is potentially dangerous to the quality of the democracy we enjoy; the second
one explains the nature of possible threats; the last one examines possibilities of employing
certain regulatory factors to remedy the current situation, which potentially has a deteriorating
effect.

This chapter examines subsequently (1) the general concerns connected with processing
and therefore filtering information, (2) the important role the search engines play nowadays,

particularly as information intermediaries, and (3) the phenomenon of the filter bubble i.e. the

 

'Eli Pariser, The Filter Bubble. What the Internet Is Hiding From You (New York: The Penguin Press, 2011) at 5.
*Nicholas Negroponte, Being Digital (New York: Alfred. A. Knopf, 1995) at 153.

3
Living in The Filter Bubble

information cocoon in which we might live, as well as interconnections between those issues.

1. Filtering Information

Stating that we live in the Information Age is to say almost nothing about our nowadays
reality. Information and access to it became such crucial and important part of our day-to-day
lives that no one reasonable can claim that it does not play the significant role in the modern
World. We live in the knowledge-based society, where concerns on information have been
elevated to one of the most crucial queries regarding in fact the shape and condition of societies,
economies, political systems etc.? At the much ‘lower’ level, an exemplary proof of the
importance of information is that the present paper is the fruit of extensive dimension of access
to information and the overload of information available, which the phenomena we face
nowadays. The number of sources of information which anyone can consult appears to be
indefinite and therefore also non-manageable by an individual or even a group of them. Due to
the Information Revolution, we live in the World where information has become a crucial factor
of production and a basis for whole industries built around the value information can have.*

Noteworthy, even though we might want to see ourselves as flooded with a stream of
information and therefore being placed in the extraordinary and new reality, the problems
concerning information the human mankind currently faces appear to remain the same from the
very beginning of our history. The questions regarding the load of existing knowledge, which
people have been asking themselves for several hundred years, appear to be built around several
general issues of which the following two are worth mentioning in the context of the subject
matter of present paper: (1) how to process and make use of information, and (what appears
more important in the context of the present paper) (2) how to filter information to obtain only
relevant data. As previously stated, these problems are not new. Seneca complained about the
overflow of information already in ancient times: “What is the point of having countless books

and libraries whose titles the owner could scarcely read through in his whole lifetime? The mass

 

°>Frank Webster, “Introduction: Information Society Studies” in Frank Webster ed., The Information Society Reader
(London and New York: Routledge, 2004) at 9.

“For more information on the Information Age and its development please see: Kevin Robins & Frank Webster, “The
Long History of The Information Revolution” in Frank Webster ed., supra at 55-80.

4
Living in The Filter Bubble
of books burden the student without instructing.”*> Nowadays such complaint would be probably

welcomed with a charitable smile. However, even though the dimension of influx of information
has changed, the problem of processing amounts of data too huge to allow one to comprehend
them has remained the same.° According to the research published in 2009, during the precedent
year only U.S. citizens ‘consumed’ 3.6 zettabytes of information,’ what is truly the BIG number.®
It is easy to get confused and lost while operating on such amounts of data. The problem of their
digestibility arises — the form of data, level to which they are comprehensive etc. The processing
of information is preceded by an elementary choice of the input to be processed, what leads us
straight to the second of the mentioned general issues concerning information and its usage.
Notably, most of the information we receive from the reality surrounding us is of no true
relevance; there is a limited number of data we need to obtain and process in order to achieve a
given goal (e.g. to pass an exam). That forces us to pose a question on how to distinguish the
relevant data from those which are not important. The filtering of obtained information remains
as important part of the whole process of comprehension as its other stages, namely collection of
data and subsequent processing and analyzing with the view to obtain certain outcome. The form
and the manner in which the employed filter operates have undeniable influence on the effects of
information processing.

Therefore, to effectively control the process one needs to analyse the nature and features
of the used information filter. How does it operate? What kind of factors does it take into account
while deciding whether the given information is important or not? What factors are decisive?
What is the algorithm behind it? How many information of what kind and form can it filter in a
given time period? These are questions referring to the technical aspects of the filter and they
determine whether it is efficient or not. There are, however, queries of different nature which are
more important is evaluating whether the filter is good for its user.” Is the filter value-neutral? If
not, what kind of values, view and opinions does it support? Is a given tendency visible to the

user? Is the process of selection of information transparent? Is the user conscious of how the

 

*Lucius Annaeus Seneca (trans. C.D.N. Costa), Dialogues and Letters (Penguin UK, 1997) at 45.

6 Alexander Halavais, Search Engine Society (Polity Press, 2009) at 10.

7For you reference, the mentioned number amounts to 3.6 times 10?'.

SRoger E. Bohn, James E. Short, How Much Information? 2009 Report on American Consumers (University of
California — San Diego: Global Information Industry Center, 2009), online: Global Information Industry Center
<http://hmi.ucsd.edu/howmuchinfo.php>.

°Compare: Halavais, supra at 32.
Living in The Filter Bubble
information is selected? What influence the user has on the manner in which a given filter

operates? To translate these questions into example, if a professor proposes several leading
handbooks to a class, each student willing to pass would first (most probably) briefly familiarize
him- or herself with the books (collection of data), analyse pros and cons of each title (too long,
too short, too theoretical etc.), make a choice basing on the adopted criteria (those merely willing
to pass would chose the shorter handbook; those more ambitious — the one giving more in-depth
sight etc.), and then read the content of chosen book with the view to learn from it (processing
data for a given purpose). While in that simple as well as simplified example the students were
given a limited amount of possible input data (handbooks to choose from) and they used their
‘internal filters' (that is the mere human perception what proved to be sufficient to handle the size
of input information) the situation changes dramatically with the increase of number of data to be
processed. For the number of years traditional medias like radio, newspapers and even TV have
served not only as a source of information to people, but also as pre-filters of the information,
providing the audience with data which for some reason were considered to be important or
worth mentioning. '° With the raise of the World Wide Web, the situation has grown even more
complex. The Internet appears to be almost bottomless source and repository of knowledge; the
volume of existing information fairly exceeded the state which Seneca already found excessive.
Finding an Internet blog which interests us and fits our purposes might be quite difficult as
apparently there are ca. 150.000.000 blogs on the Web.'! How to filter such volume of data or, in
other words, how to reduce such amount of data to the dimension comprehensive by an
individual? This fairly exceeds the scope of the present paper, but in this context it would be
interesting to notice psychological aspects connected with the filtering big volumes of
information, namely the information anxiety, fear of processing not enough information, of
having filtered too less data what could subsequently negatively influenced our further actions.'”
In order to cure such and other problems, as David Wienberger indicates, “we have rapidly

evolved a set of technologies to help us. They fall into two categories, algorithmic and social

 

10See: Cass R. Sunstein, Republic.com 2 (Princeton and Oxford: Princeton University Press, 2007) at 29-32.

"How Many Blogs are on the Internet, WPVirtuoso, online: <http://www.wpvirtuoso.com/how-many-blogs-are-on-
the-Internet/>. The author does not provide source of these data, thus the mentioned number remains unconfirmed.
Because of technical reasons it can be only, accurate or not, estimation. It does not however differ substantially from
the similar calculations which can be found.

For further information please see: David Weinberger, Too Big To Know. Rethinking Knowledge Now That the
Facts Aren't the Facts, Experts Are Everywhere, and the Smartest Person in the Room Is the Room (New York: Basic
Books, 2011) at 9.

6
Living in The Filter Bubble

(...). Although techniques use the vast memories and processing power of computers to
manipulate swirling nebulae of data to find answers. The social tools help us find what's
interesting by using our friends' choices as guides.”'? These two techniques are both employed
in processing Internet data and importantly, as Wienberger also accurately points, they are
usually both combined. This is the case of the modern Internet search engines — technology
which changed the way we filter and process data and which, as we are going to see, have very

meaningful repercussions on how do we perceive the reality.

2. Internet Search Engines

Alexander Halavais indicates that the term “search engine might refer to an information
retrieval system that allows for keyword searches of distributed digital text.”'* Even though he
refers to a search engine in general, he clearly means the Internet search engines explaining
further that “while a search engine is usually a system that indexes web pages, the term has been
extended more broadly to include range of information environments and media forms, including
multimedia and other content found on restricted intranets and individual computers.”'> The
idea of Internet search engine is generally as old as Internet in its modern form - the first search
engine was invented in 1990.'° Since then we could observe a rapid development of search
mechanisms out of which one has become particularly well known. In 1996 two students of
Stanford University, Sergey Brin and Larry Page, came up with the algorithm called PageRank. !”
In two years later, the same students incorporated the small company, giving its creation the
little-then-meaning name Google.'® The rest remains the history.

In order to move forward, to analyse a phenomenon of so-called filter bubble we might
live in, there are several comments to be made on search engines. These are merely observations
concerning the manner and environment in which the search engines operates, however each of

them should be given a high significance while attempting to create any regulatory framework

 

David Weinberger, supra at 9.

“Halavais, supra at 5-6.

Ibid.

'6Interestingly it was invented by a student of McGill University, Montreal. See: Tom Chatfield, 50 Digital Ideas
You Really Need to Know (London: Quercus, 2011) at 36.

"Chatfield, supra at 36-37.

18Tbid.
Living in The Filter Bubble
(what in my view could be of certain benefit) concerning Web search and filtering and while
trying to discover whether there is any problem with the way the search engines operate at all.
There are at least four comments to be made. Firstly, obvious as it is, the search engines play
very important role in the day-to-day life of millions of people all around the World.'? Secondly,
the search engines field remains widely non-regulated space, what apparently is an exceptional
case among information intermediaries.”° Thirdly, the search services market is dominated by
several major players out of which just one name has been vigorously discussed both by public
and antitrust regulatory bodies.”! Finally, the way in which a search algorithm operates is far way
more complex than an average person could expect and usually takes into consideration not only
fact-based criteria, but also whole volume of personal information on an engine's user.
Interestingly, the survey published in 2012 indicated that 66% of respondents agreed with the
statement “Yes, I think Internet search engines are a fair and unbiased source of information. ”?
The last observation forces us to ask questions as to the nature of personalization of search
results and will lead us straight to the next section of this paper. Before that happens the
abovementioned comments deserve some further explanatory remarks.

The role which search engines play in modern societies is undeniably great and at the
same time (maybe quite surprisingly) appears to be inversely proportional to the interest
regulators put in the search engines. Leaving behind the complex and usually well-justified
reasons of the lack of general regulation of search engines, in order to prove to what extent the
search engines play the important role in our lives the following numbers might be helpful.

The Paw Internet study from 2012 indicated that 91% of Internet users uses search

engines too, what has always been — next to using an email — the most popular activity on the

 

Ken Hillis, Michael Petit & Kylie Jarrett, Google and The Culture of Search (New York and London: Routledge,
2013) at 3-4.

2°See for example: The Structure of the Mass Media and Government Regulation, Cliffs Notes, online:
<http://www.cliffsnotes.com/more-subjects/american-government/the-mass-media/the-structure-of-the-mass-media-

and-government-regulation>. For more information see for example official Federal Communication Commission
site: <http://www.fec.gov>.

21As to the antitrust proceedings against Google see for example: Federal Trade Commission. Statement Regarding
Google's Search Practices. In the Matter of Google Inc., FTC File No. 111-0163 (2013) and Google Inc.
Commitments. Foundem and Others, Case COMP/C-3/39.740 (2013).

The Pew Research Center's Internet & American Life Project Winter 2012 Tracking Survey (January 20- February
19, 2012), online: PewlInternet.org <http://www.pewinternet.org/files/old-
media/Files/Reports/2012/PIP_ Search Engine Use_2012.pdf>. See also: Kristen Purcell, Joanna Brenner, Lee
Rainie, Main findings, PewResearch Internet Project <http://www.pewInternet.org/2012/03/09/main-findings-11/>.

8
Living in The Filter Bubble
Web.”? Out of all search engines users, more than the half do it at least once a day. The numbers

should be found convincing, however their true significance is clearly revealed when confronted
with the actual number of Internet users world-wide, amounting to nearly three billion people at
the end of the year 2014. Even though this is the statistic and therefore the numbers are by their
nature arguable, they clearly show that (as to the principle) when we discuss the role of search
engines we refer to the phenomenon which is a part of everyday life of most of us. This is just
one reason why the issue of information filtering deserves proper attention. Moreover, it should
be noticed that because of the extent to which we use search engines, they have become leading
intermediaries in people's access to information, news etc. Like other entities or mechanisms of
such kind, they are regulated, however, in this author’s opinion — to the lesser degree and with
the less holistic approach.” While TV, radio or newspapers and magazines industries are widely
subjected to legal rules posed by governmental bodies, the search engines (which apparently
have started playing a role similar to the one the mentioned mass media means used to play in
the past century) are somehow out of scope of media regulation, besides several commercial

aspects arising from the antitrust law, content liability and advertising. *°

Deciding not to
evaluate whether it is good or bad situation, it is worth to realize that our everyday filter of
information is generally not subject to any other verification than of its own, private-based
creators.

Mentioning search service providers, what a word comes to your mind first when hearing
the term 'search engines’? Basing on different researches, there is from 65 to 90% chance that
this word was 'Google'.’ The Silicon Valley potentate is undeniably the most popular search
service provider all over the World, even if its dominance over concurrence in different
jurisdictions varies. In fact, Google managed to become to some extent a generic name for a
search engine and for a search process. You might not believe it? ‘Just google it.' Under the
record 'to google' in The Oxford English Dictionary the following definition can be found: “to

search for information about (a person or thing) (...)”.?8 While Google nowadays is certainly

 

Ibid. See also: Hillis, Petit & Jarrett, supra at 3.

Internet Users in The World (2014) Internet Live Stats, online: <http://www.internetlivestats.com/internet-users/>.
25 For more information on overall regulation of search engines in U.S. please consult: Urs Gasser, “Regulating
Search Engines: Taking Stock and Looking Ahead” 8:1 Yale Journal of Law and Technology 201.

26 See: Ibid at 216-219.

"The Pew Research Center's Internet & American Life Project Winter 2012 Tracking Survey (January 20- February
19, 2012). See also: Hillis, Petit & Jarrett, supra at 3.

*®The Oxford English Dictionary, online: <www.oed.com>.

9
Living in The Filter Bubble
something much more than merely search services providers, the PageRank mechanism and its
subsequent developments remained the core part of Google's business. That company is not the
only player present in the market. There are other services providers out of which only few
however are worth mentioning e.g. Bing, Ask.com, Yahoo or Baidu. The fact is, that even though
we might find several entities competing in the market, the researches show that just three of
those companies hold at least over 90% of the market.”? The number even grows, depending on
jurisdiction but as to the principle never decreases. This reveals another important circumstance
regarding the reality which any possible regulation or change concerning the search engines
needs to take into account — the search services market is almost fully dominated by the three
companies, if not monopolized by one of them. While the economical perspective falls out of
scope of the present paper, this might make us wonder about the fact that these are practically no
more than three private entities which act in the realm of Internet as information intermediaries
and filter for us relevant information from trifles. While it is hard to argue that this is not the case
of traditional mass medias, with the leading example of Mr. Murdoch's empire, yet the described
situation might rise questions as to the neutrality of search results, their accurateness and
quality.°°

Being aware of the above, in order to decide whether there could be any kind of problem
with the current state of search engine services, one need to at least briefly analyse the scheme of
manner in which the search process is operated. As to the principle the following remarks
concern all search engines — functions and general structure of each of them are the same.*! In its
simplified version, the whole process can be framed into three interdependent stages: (1)
providing input data, (2) processing a query and (3) obtaining a search record.*” At each of these
stages several important questions should be asked and answered in order to fully understand
significance of each process step for the overall scheme. As to the initial query it is relevant to
realize what kind of information do we seek. Is that information we need or we think we need,
or, the one we want or think we want? Do we know exactly what we are searching for? What do

we expect to find by making a given query? These are the thinking points referring primarily to

 

The Pew Research Center's Internet & American Life Project Winter 2012 Tracking Survey (January 20- February
19, 2012) at 35. Baidu operates in only in Chinese market.

Keith Robert Murdoch is an owner of News Corporation which owns, among other, The Sun, New York Post, The
Times, Daily News, British Sky.

31Halavais, supra at 14.

>See: Ibid.

10
Living in The Filter Bubble

the psychological aspect of the individual in his pursuit of knowledge. As to the second stage of
the process we might want to know how the search algorithm operates. What kinds of criteria are
taken into account in determination of relevance of search results and which criteria are decisive.
Is the search engine value-neutral? Does it prefer some records from the others? Is the used
algorithm transparent and comprehensive? Lastly, when the input data are processed by the
search engine what we receive are search results. Are they accurate? Are they satisfactory? Do
they answer the initial query? Do they respond for the query we actually made or we think we
made or even — what is more and more often the case currently — the query of which the
algorithm somehow knew we had wanted to make it in real? Is the search result something we
wanted to see or the particular outcome is something what someone else wanted us to see (what
about advertisements?)? That third set of questions obviously refers to the very core reason for
which we use search engines, namely obtaining accurate and trustworthy results and so thus an
answer for our question. As indicated above, these three stages are interdependent, but not only
in the way in which input information influences processing of data and subsequently obviously
the results. The web of connection is much more complex as e.g. the search results of one query
influences the others. We already learned from Weinberger that both the algorithmic and social
techniques are employed. The high-end complex search engines take into consideration whole
volume of personal data of its user and notably of other (correlated or not) users: browsing
history, former queries, established habits, strictly personal information, geospatial data etc.*”
The analysis of these data allows the engine not only to process the query but also to influence
the content of query itself throughout the system of automatic suggestions.

What in my view emerges from the above scheme is that the level crucial for the whole
process is the second stage of it — the query processing. Although arguable, if we acknowledge
the dominant role of search engine in the process (and even more importantly the extraordinary
level of influence the search engine has on the other stages of the process) we would need to
realize that any possible regulation of the Internet-based information search needs to focus
exactly on that element, if only intended to be effective. As we will see in the last chapter, this

notion is not isolated and at the same time creates certain troubles.

 

In fact, in strictly legal terms very few information used by Google in its search algorithm are personal information
in statutory meaning. The algorithm generally operates on 'depersonalized' data. Still, the fact remains, that even
though these data are not personal in legal terms, they are of importance from the privacy perspective and are
‘personal’ in the ordinary meaning. See: Randall Stross, Planet Google. One Company's Audacious Plan to Organize
Everything We Know (New York: Free Press, 2008) at 64.

11
Living in The Filter Bubble

More than ever before and to the greater extent, the key element of the process of
filtering information is now the search engine. That is due to the dimension of use of personal (in
its wide meaning) data regarding users. These data are collected, processed and used with one
purpose — to provide more accurate and more satisfactory search results. Worth mentioning, the
search records are to be accurate and satisfactory from the subjective individualistic perspective
— the use of subjective criteria to determine the search results implies that the results would be
also subjective. To the great extent, all Internet search results are personalized, to fit better the
search engines' users. The underlying explanation is that by personalization of search records
users are granted faster and more effective access to the information. But what if it is just the half

of truth and the personalization has further, less desirable consequences?

3. Do We Live im the Filter Bubble?

In 2011 Eli Pariser* published the book under the title “The Filter Bubble. What the
Internet Is Hiding from You”. The main argument of the book has been widely disputed since
then and while there are several voices opposing Pariser’s findings,*> most of the public has been
attracted with the smoothness of idea of phenomenon he described. In short, due to the
personalization of the content, although still free to choose what we read and find on the Web,
we lose the freedom as what we see on our screens depends less and less from our actual choices
but rather from what someone (or more accurately - something) else chooses for us. Quite
ironically, what has been chosen for us is to the big extend decided upon our former decisions
and preferences. The significance of our small everyday Internet choices has been strongly
amplified as the content we find on the Web is more and more tailored for cach of us, with the
aim to let us see more of the content we want, more of the information we seek and more
experiences we want to share. In the result we might find ourselves to be closed in the filter
bubble — our own sphere where interests are satisfied to the greater extend and where the access
to any information or experience we want is easier and faster than ever before. That is the
positive side of the results of personalized filtering giving the huge significance to our personal

needs and choices. On the other hand, what was not often being mentioned before Pariser’s

 

4US. Internet and left-wing political activist, born in 1980.
35 See for example: Louis Grey, Why The Filter Bubble Is No Bubble and It's Not Bad Either (2011) Louis Grey
Blog, online: <http://blog.louisgray.com/2011/05/why-filter-bubble-is-no-bubble-and-its.html>.

12
Living in The Filter Bubble

publication, there is a whole class of data which is left beyond our bubble, the access to which is
in fact harder as in order to reach such information one need first to ‘pop’ the bubble surrounding
him or her.*° While familiarizing with Pariser’s idea, one might wonder whether it is the real
problem — the filter bubble does not create any psychical and actual barriers for access to other
data than those which can be found ‘inside’ the bubble. Weinberger rightly points that “Filters no
longer filter out. They filter forward, bringing their results to the front. What doesn't make it
through a filter is still visible and available in the background.”%’ The whole point is however,
that in order to find what we are looking for we need first to be aware of its existence. Even if the
bubble does not stop us from searching for content on the Web, it does however hide a big part of
it from us, making it less or not visible at all. Provided we find a value in pluralism of thoughts
that might be quite a problem.

Yet, it must be noted that the filter bubble is not just the phenomenon regarding the way
in which current search engines operate. Regardless our opinion, the fact is that personalization
is present everywhere on the Web.** Everywhere. Robert W. McChesney notices that “Pariser's
Filter Bubble documented how the Internet is quickly becoming a personalized experience
wherein people get different results on Google searches for identical queries (...) They are soon
to get different websites on the screen than other people who enter the same URL.”*° In 2010
Google CEO Eric Schmidt predicted: “The technology will be so good, it will be very hard for
people to watch or consume something that has not in some sense been tailored for them.”*° This
tells us something about our reality — there is less and less space for our idealistically understood
free choice in the Internet medium as well as less freedom of free speech as the possible
audience has been closed within its own filter bubbles. John Parry Barlow‘! is his famous
“Declaration of the Independence of Cyberspace” claimed that “The global conveyance of

thought no longer requires your <i.e. governmental> factories to accomplish.” underlining the

 

36 Edi ~=s- Pariser, Beware online “filter bubbles (TED Talk, 2011) online. TED.com
<http://www.ted.com/talks/eli_pariser_beware_online_filter_bubbles?language=en>.

37 Weinberger, supra at 11.

*8Pariser, The Filter Bubble at 8. For further reference see also footnotes there.

Robert W. McChesney, Digital Disconnect. How Capitalism Is Turning The Internet Against Democracy (New
York, London: The New Press, 2013) at 157.

“Pariser, The Filter Bubble at 47 after Holman W. Jenkins Jr, Google and the Search for the Future (Wall Street
Journal, Aug. 14, 2010).

41Co-founder of the Electronic Frontier Foundation, to some might be better known as a musician of Grateful Dead.
“John Perry Barlow, A Declaration of the Independence of Cyberspace (Davos: 1996), online: Electronic Frontier
Foundation <https://projects.eff.org/~barlow/Declaration-Final.html>.

13
Living in The Filter Bubble

freedom of Web and circulation of thoughts or ideas on the Internet, which where underlying
promises of this communication mean. Well, that might not be a case anymore as apparently
even without any ‘help’ from governmental bodies the Barlow’s vision of the extent to which the
free speech is ensured on the web has been slowly turning into the past. The filter bubble in
Pariser’s view is the sum of all personalization mechanisms we are forced to use during surfing
the Web.? While it would be an exaggeration to claim that just one website, service etc. can limit
us from recognizing the existence of ‘other’ content and create our own bubble, it is important to
notice that there is in fact only one kind of services which always plays big role in the creation of
the filter bubble. The one which is used by nearly all Internet users out of which more than the
half use it on daily basis. If only there is one decisive factor and mechanism contributing to the
existence of the personalized closed bubble for each of us, this is the search engine.

The role of search engines in creation of the information cocoons is a simple derivative of
significance we give to such services by using it every single day. The dimension of that
phenomenon has already been described above. Additionally, referring again to our previous
findings, it is worth to realize that the search engines are modern information intermediaries and
to the great extent they have replaced the traditional mass media. While hearing the news it is
easier and faster to type the query on the phone search than to find a pilot and launch a TV, in
order to hear more of on the given topic. While most of the websites include both some kind of
search mechanism and personalized content, still it is more about the content possible to find on
the site than about filtering it. As to the contrary, search services providers focus much less on
the content and more on the filtering of what already exists in the depths of the Web. As the
filtering is the key process for the creation of bubbles, the key generator of our reality is who or
what filters the information for us. I am far from making such exaggerated statements like “What
does not appear on the first site of Google search results does not exist at all’, however one
cannot deny that there is some point in such belief.

In order to deliver personalized search results Google takes into account tens of different
factors.“ As indicated before, that comprises e.g. our localization, other geospatial data, type of
browser we use, our previous browsing history, our previous clicks on search results, former

queries as well as whole bunch of public or personal (not in strict legal sense) data on our

 

“Pariser, Be Ware of Filter Bubbles.
“Danny Sullivan, Dear Bing, “We Have 10,000 Ranking Signals To Your 1,000. Love, Google,” Search Engine
Land (November 11, 2010), online: <http://searchengineland.com/bing-10000-ranking-signals-google-55473>.

14
Living in The Filter Bubble

activity on the Web, consumer preferences etc. Because of the variety of information the
complex algorithm uses for processing purposes, there is no an easy way out, no obvious
solution to escape personalization. Certainly, every individual might tick the box ‘opt-out from
personalization services' on Google’ but this could just partial and none systemic solution. The
problem in question overlaps with the issues of privacy and control over personal data on the
Web. The rise of Information Age and universe fast access to Internet has revolutionized our
thinking about privacy and materially decreased the sphere of life which still can be firmly
described as fully private. Unlike many people might think, everything what one does on the
Internet is visible and leaves a trace. It constitutes information which in the modern World in
economic terms is practically a commodity, as has value to many companies present in the

market.*5

Elementary deduction based on the set of information on a given user might easily lead
to discovering other, more vulnerable data. Google and other search engines gathers those
information to provide what they describe as better and more accurate search services. Because
of the complexity of this process and the huge volume of data concerning ourselves we publish
or make available every single day, there is no easy way to stop personalization. Besides, even if
we manage to opt out from personalized search services that only decreases the bubble — it is not
possible to opt-out from the personalization of Web as it became fully personalized. To quit
personalization practically means to stop using the Internet. Therefore, the filter bubble develops
and it is hard to expect that this trend would revert.

On the other hand — why should we want the trend to revert? We might live in the filter
bubble, however as I presume basing on my own experience such situation is not unpleasant to
our minds. Quite to the contrary, I am of view that many would agree that they truly enjoy the
search results they obtain as they find them trustworthy and handful. In fact, as already shown,
the statistic provides that most of us find the search results accurate and unbiased. The
personalization mechanism makes the search service more tailored to my needs. I can find the
information I seek faster and access it easier. If for years e.g. I used to go to RPA for holidays I
am glad to find a good new hotel and current car rental offers on my search. I am not necessarily
interested in learning on economic and political issues as well as on apartheid and Mr. Pistorius’

judicial proceeding. I could, but I might not want to. Is there any problem then? Is there any

 

* Brian J. Perry, “Is Information a Commodity?” (October 20, 1999) online: National Institute of Informatics
<http://www.nii.ac.jp/publications/kaken/HTML1999/99Perry02-E.html>.

15
Living in The Filter Bubble

reason I should or should want to ‘pop’ my filter bubble and subsequently use less comfortable

non-personalized search engines?

II. _—_— Personalized Filtering - What Can We Lose? Search Engines Bias and Democracy.

“Everything which bars freedom and fullness of communication sets up barriers that divide
human beings into sets and cliques, into antagonistic sects and factions, and thereby undermines
the democratic way of life.”

John Dewey“

At the dawn of Information Era, in 1995 Nicholas Negraponte, the MIT engineer, faced
the problem most of us might have experienced and which some people tend to escalate on
Saturday evenings into the one of the most important problems of human mankind — what to
watch on TV while there is literally nothing interesting there?*’ Instead of solving this vital
problem, Negraponte predicted that the problem itself could easily disappear if only the future
TV was personalized so thus instead of watching news or any other general programs or channels
any person in front of a TV screen would receive an information package tailored just for him or
her. Such package would be “printed in an edition of one (...) Call it the Daily Me.’** The
prophecy has proved to be right — as already shown, the personalization mechanisms are present
everywhere and even to the greater extent on the Web than on TV. The personalization of content
in its current form, where this is the third party who decides what the effect of personalization is,
and where an Internet user has in fact little control over what he or she sees on the Web, leads to
the situation where “you don’t need to create a Daily Me. Others can create it for you (...) can
discover, and tell you, what ‘people like you’ tend to like (...) in a matter of seconds.’ Notably,
on the Internet these are not governmental but private entities who decide on personalization of
content we find, including the search engines realm. In this context, Sunstein, in his well-known

early Internet age piece “Republic.com” poses a question: “How will the increasing power of

 

“John Dewey, Essays, Reviews and Miscellany, 1939-1941, The Later Works of John Dewey, 1925-1953. Vol. 14
(Carbondale: Southern Illinois University Press, 1998) at 227.

*7Pariser, The Filter Bubble at 22. Sunstein, supra at 4.

*8Negroponte, supra at 153.

“Sunstein, supra at 4.

16
Living in The Filter Bubble

private control affect democracy?”*® While the question is extremely broad he further gives
focus to the interplay between filtering information and freedom of speech as the democratic
value, presenting two requirements which must be met to create an effective system of
democratic free expression: “First, people should be exposed to materials that they would not
have chosen in advance (...) Second, many or most citizen should have a range of common
experiences.” He calls for pluralism and circulation of thoughts and ideas within the civic
society, what unarguably is crucial to its existence. The principal problem connected to the
personalized filtering of information (and therefore to the search engines) is that it neither foster
pluralism of thoughts, nor strengthen sharing common experiences between members of the
society. Moreover, the threats arising from the manner in which personalization of content is
made are that it ultimately limits pluralism and might effectively block us from sharing
experiences, discussing different opinion and therefore weaken the very principle mechanism on
which democracy is based — freedom of thought and their exchange. As noticed above, many
could argue that there cannot be any threat to pluralism as the search engines technically do not
block the access to any information, they filter forward instead of filtering out. Still, the
underlying question is here not whether there is pluralism of thoughts on the Web, as it
undoubtedly exists, but rather whether the quality material access to diverse information is
ensured and people have a real chance to be exposed to other views.

Halvani notices that numerous ethical concerns as to the functioning of search engines
might be organized in “four broad categories: (i) search-engine bias and the problem of
opacity/non-transparency, (ii) personal privacy and informed consent, (iii) monitoring and
surveillance, and (iv) censorship and democracy.”>' The second and the third ones fall out of the
scope of the present paper, while the first and the last categories overlap — in my view the search
engines bias greatly contribute to the creation of possibility of threat to democracy, what I will
try to picture in this chapter. The brief analysis of them would bring us the broader picture of
how search engines' contribution to the filter bubble poses threats to the values we embodied in
the society and to our political system of “the rule of the people, by the people, for the people”.>

As already established, the search engines greatly contribute to the creation of

 

Sunstein, supra at 5. Even though I use the second edition of his book, published in 2007, in its core its is just
revised and enhanced version of the previous Republic.com published six years earlier.

!Halvani, supra.

Lech Walesa, Address to the U.S. Congress (Nov. 15, 1989) text of the speech available online: Milestone
Documents <https://www.milestonedocuments.com/documents/view/lech-wasa-address-to-the-u.s.-congress/text>.

17
Living in The Filter Bubble

information cocoons we might live in. The form and the content of the bubble - and therefore our
perception of the World, pluralism we notice and experiences we share — highly depend on the
manner in which information are filtered for us. In this context, many authors indicate possible
“search engines bias” under which term the following general concerns can be understood: that
“(L) search-engine technology is not neutral (...) (2) major search engines systematically favor
some sites (and some kind of sites) over others (...); and (3) search algorithms do not use
objective criteria in generating their lists of results for search queries.” Starting from the first
of mentioned doubts, if the search engine is value-neutral our cocoon will be too; if the search
service is not biased and provides truthful and trustworthy results, the data bubble around us will
reflect the objective reality and therefore will not be biased neither.** However, there are several
ground to claim that this is not the case. Quite to reverse, “while some users may assume that
search engines are “neutral” or value-free, critics argue that search engine technology, as well
as computer technology in general, is value-laden and thus biased because of the kinds of
features typically included in their design.”*> Going further, Introna and Nissenbaum indicate
that the search engines “systematically exclude certain sites and certain types of sites, in favor of
others, systematically giving prominence to some at the expense of others.”°° One of the many
reasons of such concern is the fact that all relevant search engines are private-based and private-
sponsored.>’ For Google Inc., the Web search advertising still remains the most crucial and
income-gaining part of its business.°* The doubt in question has been for long recognized by the
stakeholders: “We expect that advertising funded search engines will be inherently biased
towards the advertisers and away from the needs of the consumers (...) The better the search
engines is, the fewer advertisements will be needed for the consumer to find what they want (...)
We believe the issue of advertising causes enough mixed incentives that it is crucial to have a
competitive search engine that is transparent and in the academic realm.” Tronically, these are

the very own words of Google’s co-creators, which they wrote in 1998.*° Moreover, many

 

*Halvani, supra.

For sake of those consideration, let’s assume that there is some sort or form of objective reality or at least the
reality we might agree to deem for some reasons to be objective.

*Halvani, supra.

Lucas Introna, Helen Nissenbaum, “Shaping the Web: Why The Politics of Search Engines Matters” 16:3 The
Information Society 169.

*7Halvani, supra.

Omar El Akkad, “Google falls short as ad business shows cracks”, The Globe and Mail (October 17, 2014) B1.
Sergey Brin, Lawrence Page, “Anatomy of a Large-Scale Hypertextual Web Search Engine” Section 8 Appendix

18
Living in The Filter Bubble

companies and individuals present on the Web try to manipulate search results by introducing
various search engine optimization. To appear on the first page of Google results is often crucial
to the mere existence of the business, as “Jn the world of Web, esse est indicato in Google: to
exist is to be indexed on Google.”® Additionally, the problem of search algorithm objectivity
arises, particularly as to “(A) objectivity regarding criteria used in search algorithms; and (B)
objectivity with respect to the results returned by a particular search engine in its responses to
multiple users entering the same search query.”®' Importantly, we must acknowledge that any
discussion on the first remark is fundamentally biased as the algorithms used by search services
providers are not publicly known and therefore cach discussion is to some degree hypothetical.
The lack of transparency is often raised in the literature as a separate fundamental problem of
search engines itself, as well as an obvious field were the possible remedy can be found.”
Hinsman seems to believe however, the search algorithm should remain unrevealed to the
public.© All in all, they are trade secrets of the companies.“ Additionally, if the manner they
operate was fully known to the public, that would only equip the stakeholders with new tools and
possibilities of search results optimization and manipulation, what would probably not fix the
more general problem of search engine possible bias. We know however, that the numerous and
various criteria are taken into account for processing each search query and that they are aimed
to provide personalized results. Pariser in his book gives various examples of how different
search results people might receive while making the same query on Google’s website. The
phenomenon of Web personalization is therefore another ground on which the search engines
bias can be found. Personalized content is different for each user; it does not allow to share
experiences as they are differently tailored for everyone; it does not facilitate the access to
opposing views as such opinions are not the part of one's 'Web identity’ and are in fact in the
contrary to it. These observations lead us to the next out of two Halvani's general concerns
indicated at the beginning of this chapter — the ethical interplay between democracy and search

engines.

 

A, online: Stanford.edu <http://infolab.stanford.edu/~backrub/google.html>.

6°] awrence M. Hinman, “Esse est indicato in Google: ethical and political issues in search engines” 3 International
Review of Information Ethics 20 at 21.

61Halvani, supra.

®Halvani, supra.

Hinman, supra at 22.

Tbid.

Tbid.

19
Living in The Filter Bubble
The possible search engines bias (and the biased filter bubble being created in the result)

could equally significantly contribute to threatening the democratic ideals and democracy itself.
As indicated above, the threat of some kind of censorship has been recognized by Introna and
Nissenbaum, while the same authors acknowledge that there are possible advantages of Internet
as it could “give voice to diverse social, economic, and cultural groups, to members of society
not frequently heard in the public sphere [and] empower the traditionally disempowered, giving
them access both to typically unreachable modes of power and to previously unavailable troves
of information” °° The search engine bias might have important impact on pluralism of thoughts
in the society, as the search engines direct users “towards some content and not others, towards
some sources and not others.’’°’ The US Supreme Court in 1945 ruled that “the dissemination of
the widest possible information from diverse and antagonistic sources is essential to the welfare
of the public” ® what is generally the core of the concept of deliberate democracy. It is
generally agreed that in order to let democracy function well, the members of society need to not
only to have a chance to access to the opposing views but actually be exposed to the different
views and opinions.” It might not be a case in the World where we all live in the filter bubbles.
So the ultimate question is whether the search engines, creating information cocoons around us,
somehow block us from being exposed to the views being contrary to ours. This lead us
subsequently straight to the question on the intermediary role, the search engines play in the
realm of Internet.

Many commentators underline, that the search engines are modern gatekeepers to
knowledge.’! Like the traditional mass media before, Google and other filter information for us.
The promise of Internet was to eliminate any intermediaries and to give people unlimited direct
access to all kind of information.” With the raise of massive private-sponsored search engines
that promise has been revised and the questions then actual as to the traditional mass media
became once again current and important in the cyberspace. Diaz accurately summaries this

situation in the following way: “So when Steven Levy (1995) said that “instead of a gatekeeper,

 

®Introna, Nissenbaum, supra at 169.

7A. Diaz, “Through the Google Goggles: Sociopolitical Bias in Search Engine Design.” in A. Spink and M. Zimmer
ed., Web Search: Multidisciplinary Perspectives (Berlin: Springer-Verlag, 2008) at 11.

°8 Associated Press v. United States, 1945 U.S. Supreme Court [1945] 326 U.S. 20.

“Diaz, supra at 12.

Hinman, supra at 25,

“Halvani, supra.

™Pariser, Beware of The Filter Bubbles.

20
Living in The Filter Bubble

users get an open invitation to the electronic world and can choose whatever they want’, he was
being less than accurate. Internet users do get a gatekeeper — the search engine — and they
choose primarily among the sites it offers to them. As with all such intermediaries, we expect
search engines to present the available information in a fair and diverse manner; we expect
them, in other words, to be “democratic.” We should ask about search engines like Google the
same questions scholars have asked about the traditional media: Can underrepresented voices
and diverse viewpoints be heard through the filter of search engines? What role does advertising
play in the returned results? Do a few players dominate the industry? Only by answering these
questions — as we will do in turn — can one assess the true “deliberativeness” of the Web
itself”? These questions ask for what kind of intermediaries we want to have between us and
information we seek. Therefore, we cannot stick to the thinking on the search engines as merely
private services, while they play very important public role too. In my view that justifies public
interest in the way Google and others run their businesses and attempts to regulate it.

Following that, in order to realize, what I argue, that there might be quite a problem with
the effect of search engines on the society another remark must be made. People have embodied
internal ethic, so do the information intermediary of the past. The content we could find on the
pages of newspaper, on a TV screen and on radio used to be chosen for us by the group of
people, individuals, program boards etc. Certainly, there was always present threat that these
people would act in morally doubtful manner while choosing what to show to the public or not.
The example of the remedy used in the past is the so-called fairness doctrine, “once requiring
radio and television broadcasters to devote time to public issues and to allow an opportunity for
opposing views to speak.””* Unlike their human equivalent, the new cyber intermediaries do not
have ethics. Obvious as it is, the algorithm itself has no moral sense as to what should be shown
in search results. As the role which the human beings and machine accordingly used to play and
currently play is as to the principle the same, should we expect from them the same — to be
responsible for the quality of information they forward?

It is important to realize that even though the search engines might not have any ethics or
might be value-neutral, their creators must have some moral views or other aims which

inherently influence the form and operation manner of the engines. As these mechanisms are not

 

®Diaz, supra at 15.
“Sunstein, supra at 72.

21
Living in The Filter Bubble

transparent, we do not know whether they prefer some site or view than the other because they
were ‘told’ to do so. What we however know is that they are generally fully controlled by the
three private companies, incorporated with the view of creating financial profit. And as much as
we want to believe that they act for our common good in the best case they act a/so for the
common good. I do not argue that the present situation is materially different from the private-
founded mass media companies, besides the ‘ethical’ difference indicated above. I am rather of
the view that, as Diaz suggested, we need to deserve from the search engines the same as from
any other relevant information intermediaries. We should expect them and possibly force them to

work for the good of society and not to the contrary of democracy and its ideals.

II. Is There Space For Regulation? Responsibility Over Comfort.

In this final chapter I am going to elaborate on the following question: is there any space
for regulation of the problems we previously identified? My argument is that the current state of
affairs does not leave much space for any regulatory framework (yet there might be some
possibilities, among others, to regulate architecture of algorithms throughout various means,
including both soft- and hard-law). I do not intend to provide the deep in-sight into regulatory
possibilities, rather to come to some general conclusions on regulation. However, what in my
view ultimately emerges from this analysis is that at the end of the day the only sphere where
changes might happen now lays beyond the elements of information search process we have
previously identified. Pathetically as it sounds, if we want to preserve some democratic ideals,
the change needs to start from ourselves. It is about the little everyday choices — comfort over
responsibility, to act more consciously or to remain pleasantly negligent.

In his well-known classic piece “Code” Lawrence Lessig indicated four regulatory
factors of each given situation: (1) the market, (2) architecture, (3) law and (4) social norms.”>
The scheme aspirates to be universally applicable for each and every class of situation, when it
comes to regulation of any issues connected with broadly understood technology. ’°I find it
helpful for a purpose of analysis of the case of search engines and filter bubbles too.

The regulation by the (1) market forces is unrealistic and therefore unlikely to happen.

 

™Lawrence Lessig, Code. Version 2.0. (New York: Basic Books, 2006) at 120.
See: Ibid.

22
Living in The Filter Bubble

The search engines market is dominated by several international corporations with the strong
position of the dominant company. In economic terms that situation can be easily described as an
oligopoly being actually close to a monopoly. That does not leave much space or create a need
for the market self-regulation. Besides, I doubt whether the issues of deliberative democracy,
pluralism of thoughts and access to information might be efficiently and correctly regulated by
market forces, which have (as to the principle) an economic nature. Probably they could
somehow contribute to ensuring the existence of mentioned values; however, as they tend to fall
out of scope of interests of economics I would exclude possibility to efficiently regulate the said
problem by the market forces.

The (2) architecture of search engines is the field where the changes theoretically can
happen more easily than in other fields, as we identified it in the first chapter. All we need is the
decision of engines’ operators to employ their creations to work for our good in broader sense as
they allegedly do it now. There are, however, too many unknowns in the discussion on fixing the
architecture of algorithms. As noted above, we do not know any of these algorithms for real as
they are trade-secrets. Therefore, we even do not exactly know what can be changed. Still, the
search engines are created and being operated by people. If we believe that algorithms create the
filter bubbles for us and threat deliberative democracy, we should try to influence their creators.
That would be ironic indeed to try to protect deliberative democracy and not to use its principal
tool — discussion and exchange of thoughts and ideas.

There are firm grounds for the discussion in case of the (3) legal framework. I found the
problems described in the second chapter of the present paper to be the sufficient non-legal
justification for regulation, so thus also — or rather primarily, as we voluntarily subject ourselves
under the rule of law” — for legal regulation. In order to act however, the legislators (or judges if
we believe that the change can happen throughout precedents, over which process there would be
no general control) need to identify the clear legal basis for regulation first. Without going into
details, in my view the pluralism of thoughts and deliberative democracy are deemed to be not
only non-legal values but also as legal ideals, embodied either in letter or the spirit of law.
Finding the proper statutory basis or precedence for legislative action is however not sufficient

per se. We discuss highly controversial issue as it refers to the values and possibly to the choice

 

“Whereas Canada is founded upon principles that recognize the supremacy of God and the rule of law (..)”,
Canadian Charter Of Rights And Freedoms, Preamble.

23
Living in The Filter Bubble

of balance which needs to be made between concurrent values present in the legal system. At the
level of legal meta-norms, the question of legal regulation of search engines and information
cocoons can be phrased as following: is there any legal value concurrent to deliberative
democracy and its derivatives in the current system of law, and, if so, should that legal value be
given a preference and therefore the regulation could not happen?

The proper in-depth answer for the above questions is not my aim and would deserve
some further comments and analysis. I would like, however, to draw attention to the one
particular circumstance which, personally, put me into doubts as to whether there is any space
and need of regulation at all.

So far we have adopted the approach of analyzing functioning of search engines
throughout the prism of democracy and its ideals. The other possible approach is a commercial
view. Search engines are aimed to provide commercial services. As we already established, they
are provided by private entities, which were incorporated for one aim — gaining profits. None of
the search engines operators would be keen on developing their inventions if they could not
somehow cash it. While in my view there is a need of ensuring the public interest by regulating
search engines, we need to realize that there is the great risk of excessive inference with very
privately-based commercial issues. All in all, this is the choice of values to be made: private over
public. Going further however, it is not hard to notice that on the site of 'private' forces there is
another class of stakeholders, namely us all — the search engines’ users, consumers, members of
society and citizens. Our position in the dispute differs significantly depending on the approach
we adopt to analyse it — the individualistic or collective one. In the first scenario, me, an
individual, I am entirely free to make my own choices and to enter into contractual relationships
with anyone I choose. That embraces my freedom to turn on a computer, open a browser and
make use of any search engine I choose. The following finding may in legal terms vary from
jurisdiction to jurisdiction, but in broad terms by using search engine I, a consumer, conclude a
contract with the service provider. I agree to the terms of use and to the clause on personalization
of search results. As the service is allegedly free, I pay' with my personal data, feeding up the
algorithm with information which let it function better and better. Additionally, I know I will be
exposed to advertisements as this is the way in which my service provider creates an income. By
concluding the contract I agree to receive this and not the other service or product, which can be

characterized, among others, by the following features: auto suggestions and personalized

24
Living in The Filter Bubble

results. The transparency of the service is not the subject of contract as much as the knowledge
of how they make fries and cheeseburgers is not a subject of agreement concluded with an
employee of McDonald's. If I feel cheated because I expected to receive the trustworthy and
unbiased results, I should have read the terms of use first and familiarize myself with the features
of the service. Still, I concluded it because I wanted to do so. Most probably, it is not the first and
not the last time neither — I am quite satisfied with the service I receive, like millions of people
every day. Usually I am able to find the desired information very fast. Using my search engine is
convenient, handful and the service is rather accurate.

Not to acknowledge the fact that people are rather happy than upset with the services
provided by the search engines’* in my view means to omit very core of the problem of the
possible legal regulatory framework. From the individualistic standpoint everyone is free to enter
into contractual relationships, what subsequently embraces the freedom to shape these relations
and their content. One could argue that if I am not satisfied with the 'product' search engine
operators 'sell' me, than I am free not to use such engine. What is to some degree convincing
from the individualistic perspective, does not necessary needs to be such from the collective
standpoint. In the context of the important role the search engines play in the society as
information intermediaries, the suggestion that I can simply stop using search engines is boldly
simplified solution and therefore is not realistic — not to use the search engines is to resign on
discovering the depths of Internet, being a bottomless source of data, crucial in the modern
World (and by these very words, following Introna and Nissenbaum I acknowledge the good
features of the search engines). The individualistic argument underlining my free choice as to
whether to use the search engines or not reminds me the ever-lasting argument in the discussions
on privacy — ‘one has nothing to fear if one has nothing to hide'.” To the big extent we have less
and less control over our privacy than it was the case several years ago and the level to which we
enjoy privacy might in fact not depend from us anymore. The situation with search engines

appears to be the same. The big question then is not whether I stop using the search engines or

 

78 “91% of search engine users say they always or most of the time find the information they are seeking when they

use search engines 73% of search engine users say that most or all the information they find as they use search
engines is accurate and trustworthy (...)” The Pew Research Center's Internet & American Life Project Winter 2012
Tracking Survey (January 20- February 19, 2012) at 3.

For more information on use and misuse of the 'nothing to hide' argument in on going public discussion on the
privacy please consult: Daniel J. Solove, Nothing to Hide: The False Tradeoff Between Privacy and Security (Yale
University Press, 2011).

25
Living in The Filter Bubble

not, but rather how to ensure that the algorithms work for my good — understood either
individualistically or collectively and idealistically — in both ways jointly.

In collective terms there is much more to lose than to gain. While one person using
personalized search engines is rather just a happy user of the Web tailored for him or her, from
the point of view of society a mass of people exercising their right to freedom and free
contractual relationships might be somehow scary, as in the result instead of civil society we
would have a mass of non-interconnected individuals closed in their own information bubbles,
each of them presenting rather polarized own views. Needless to say, this is not what the civil
society is about. Therefore, to correctly comprehend whether there is a legal meta-norm, a value
underlying the possible regulation one need to make a choice between personal, individualistic
freedom and some kind of common, public good of civil society. Any future regulation needs to
take these two approaches into account and balance them. Even though I do recognize that there
is a threat to the society and its citizen — and therefore to the deliberative democracy we would
like (?) to enjoy, I am far from suggesting what the night choice here is. In fact, I believe there is
nothing like 'the right choice’ when it comes to telling the preference of one democratic value
over another. The history gives us arguments for both sides. Too much personal freedom enjoyed
by nobles of XVI-century Poland, combined with their lack of common identity (we can call it
‘the lack of shared experience’) contributed to the collapse of the state which could be described
as one of the longest-lasting progenitors of modern republics. On the other hand, we perfectly
know the political systems created in the first half of the last century, which put the collective
interest over the good of individuals in the hierarchy of values. We also know their consequences
and the fact that they ultimately collapsed too. At the end of the day, it is all about balancing
rights and values. Checks and balances — this is what the democracy is about, isn't?

The above considerations show that the principal question of legal regulation — whether
to regulate or not at all — is extremely hard to answer. What emerges to me from the above
analysis is that the big picture of the regulatory problem touches the issue of individual
responsibility. The choice of values to be made by a legislator is in fact an echo of the question
on responsibility each citizen, the member of civil society, should ask him- or herself. The
society is strong by the strength of 1ts members and responsibility they take for the group.
Needless to say, that it is not possible to create well-functioning democracy without the civil

society which takes responsibility and shape the reality it functions in. With that, I must admit,

26
Living in The Filter Bubble

somehow pathetic notion we come to the last of Lessig's factors — (4) social norms. I argue that
for now this is the proper ground where the most can be achieved. It is at the same time the field
where the changes are the hardest to be introduced and followed.

In the first chapter I concluded that out of three stages of search process this is the part
concerning an algorithm where the possible regulation is most likely to happen and be provided.
While I upheld the previous finding I wonder whether — bearing the nature of the choice-of-value
problem - isn't it worth to draw our attention to the other stage of the process, namely the initial
one? Or even further, leaving the process behind, focusing on an individual being a rational for
any search process to happen. In my opinion we might do so, provided that we see some chances
of regulating the problem in question throughout the social norms. This regulation in idealistic
words could be as following. People shall be aware of the way the search engines operate; aware
of the biases and possible threats. We shall use the algorithms consciously and do not stop on
what is given to us by the engines ‘on the plate’ but pursue further for deeper and broader
understanding of the given matter. In that pursue of knowledge, we should try to consciously
expose ourselves to the opposing views with an aim to comprehend and debate them. Even
though I felt uncomfortable with these pathetic and general instructions as to ensure the well-
functioning civil society, the solution to the problem might be hidden in these very actions and
could be shortly described by the following suggestion: be responsible. These big words and
ideas can be easily transformed into more specific and far less pathetic instruction to be followed
if the change has to happen throughout shift of social norms. Take care for your privacy — do not
let the engines to be fed up with information allowing them to personalize search records to the
greater extent than they do now. Do not just stick to the search results on the first page. Use
different search engines. Familiarize yourself with different research tools and techniques. Use
software which does not allow websites to track your activity. Check sometimes what your
political opponents have to say on a given topic. Think ‘out of the box’. Do not consume culture
and information, rather explore. Google certainly is not evil, but if it does not work for our good
let just howl down the possible negative effects it creates. This might be just temporary solution,
by if combined with changes regarding the other three regulatory factors, might prove to be
efficient in preserving deliberate democracy, if not in ‘popping’ the filter bubble.

All these simple things deserve us to take some little responsibility over what we do on

the Web and force us to make the ultimate choice: little comfort or some signs of social

27
Living in The Filter Bubble

responsibility? All of that without even moving out from in front of the screen. Would that
solution to the problem work? It depends only whether we believe that people are able to
sacrifice some comfort for the public good. In the pessimistic or maybe more realistic version,
the same question can phrased as whether we are able to fight for some deliberative and abstract
idea of civil society and give up on our quite accurate, satisfactory, fast and handful search
results Google and others provide us every single day.

Lessig's modalities are interdependent. Therefore a claim that it is enough to change just
one of them is both too simplified and untrue. While I believe that as for now the change could
happen throughout the social norms, I think we should constantly encourage ourselves to ask
question about other three modalities to be employed for regulatory actions. It is important to
notice that change of social norms is more likely to preserve ideals of deliberative democracy,
while in my opinion it does not constitute sufficient response to the general problem of
personalization.

At the end of the day, the question of the form of regulation is just a derivative of the
much more basic query, whether there is the problem at all. I believe that there is certain threat to
the deliberative democracy, caused by the way the search engines operate. The question of how

and with what tools provide the remedy for this situation remains open.

Conclusions

Undoubtedly, the search engines constitute the important part of our day-to-day lives. To
the great extent, they are the first source of information to many people and as such play the
important role of information intermediaries. Therefore, the manner in which the search results
are rendered and delivered is not only of concern of separate users, but should relevant to the
whole society. That being said, the search engines bias may contribute to the creation of the filter
bubbles. As the information cocoons surrounding us create the threat to the concepts of
deliberative democracy, its ideals and civil society, there might be a need to find a remedy
against that. If we acknowledge that there is the need of regulation, the primary question
becomes 'How to regulate?'. As the regulatory force of the market is out of question, we know
little about the algorithms of search engines and the ground for legal response are highly

controversial, as for now the only appropriate ground for changes are social norms concerning

28
Living in The Filter Bubble

the way we use search engines, our awareness of its possible biases etc. At the end of the day, it
is the moral question on responsibility everyone needs to take for its own activity on the Web,
provided he or she sees the described threat to the civil society. There is a choice to be made: to
act more consciously and responsibly or rather to stick to what others give? Responsibility over
comfort. At the same time, the regulatory question is the derivative of the more basic problem: is
there the threat to the civil society? I argue that there is, but as the matter of fact I would not

mind being wrong.

Bibliography

1. Akkad Omar El, “Google falls short as ad business shows cracks”, The Globe and Mail
(October 17, 2014) B1.

2. Associated Press v. United States, 1945 U.S. Supreme Court [1945] 326 U.S.

3. Barlow John Perry, A Declaration of the Independence of Cyberspace (Davos: 1996)
online: Electronic Frontier Fundation <https://projects.eff.org/~barlow/Declaration-
Final. html>.

4. Bohn Roger E. & Short James E., How Much Information?2009 Report on American
Consumers (University of California — San Diego: Global Information Industry Center,
2009), online: Global Information Industry Center
<http://hmi.ucsd.edw/howmuchinfo.php>.

5. Brin Sergey & Page Lawrence, “Anatomy of a Large-Scale Hypertextual Web Search En-
gine” Section 8 Appendix A, online: Stanford.edu
<http://infolab.stanford.edu/~backrub/google.html>.

6. Chatfield Tom, 50 Digital Ideas You Really Need to Know (London: Quercus, 2011).

7. Dewey John, Essays, Reviews and Miscellany, 1939-1941, The Later Works of John Dew-
ey, 1925-1953. Vol. 14 (Carbondale: Southern Illinois University Press, 1998).

8. Diaz A., “Through the Google Goggles: Sociopolitical Bias in Search Engine Design.” in
A. Spink and M. Zimmer ed., Web Search: Multidisciplinary Perspectives (Berlin:
Springer-Verlag, 2008).

9. Gasser Urs, “Regulating Search Engines: Taking Stock and Looking Ahead” 8:1 Yale
Journal of Law and Technology 201.

29
Living in The Filter Bubble

10.
11.

12.

13.

14.

15.

16.

17.
18.

19.

20.
21.

22.

23.

24.

25.

Halavais Alexander, Search Engine Society (Polity Press, 2009).

Hillis Ken et al., Google and The Culture of Search (New York and London: Routledge,
2013).

Hinman Lawrence M., “Esse est indicato in Google: ethical and political issues in search
engines” 3 International Review of Information Ethics 20.

How Many Blogs — are on the _—_ Internet, WP Virtuoso, online:
<http://www.wpvittuoso.com/how-many -blogs-are-on-the-Internet/>.

Intemet Users in The World (2014) Internet Live Stats, online:
<http://www.intemetlivestats.com/intemnet-users/>.

Introna Lucas & Nissenbaum Helen, “Shaping the Web: Why The Politics of Search En-
gines Matters” 16:3 The Information Society 169.

Lech Walesa, Address to the U.S. Congress (November 15, 1989) text of the speech
available online: Milestone Documents
<https:/Avww.milestonedocuments.com/documents/view/lech-wasa-address-to-the-u.s.-
congress/text>.

Lessig Lawrence, Code. Version 2.0. (New York: Basic Books, 2006).

Louis Grey, Why The Filter Bubble Is No Bubble and It's Not Bad Either (2011), online:
<http://blog louis gray.com/2011/05/why-filter-bubble-is-no-bubble-and-its.html>.
McChesney Robert W., Digital Disconnect. How Capitalism Is Turning The Internet
Against Democracy (New York, London: The New Press, 2013).

Nicholas Negroponte, Being Digital (New York: Alfred. A. Knopf, 1995).

Pariser Edi, “Beware online “filter bubbles”’” (TED Talk, 2011), online: TED.com
<http://www.ted.com/talks/eli_pariser_beware_online_filter_bubbles?language=en>.
Pariser Eli, The Filter Bubble. What the Internet Is Hiding From You (New York: The
Penguin Press, 2011).

Perry Brian J., “Is Information a Commodity?” (October 20, 1999) online: National Insti-
tute of Informatics <http://www.nii.ac.jp/publications/kaken/HTML1999/99Perry02-
E.html>.

Purcell Kristen et al., Main findings, PewResearch Internet Project, online: PewInter-
net.org <http:/Avww.pewlnternet.org/20 12/03/09/main-findings- 11/>.

Robins Kevin & Webster Frank, “The Long History of The Information Revolution” in

30
Living in The Filter Bubble

26.

27.

28.

29.

30.

31.

32.

33.

34,

Webster Frank ed., The Information Society Reader (London and New York: Routledge,
2004).

Seneca Lucius Annaeus (trans. C.D.N. Costa), Dialogues and Letters (Penguin UK,
1997).

Stross Randall, Planet Google. One Company's Audacious Plan to Organize Everything
We Know (New York: Free Press, 2008).

Sullivan Danny, “Dear Bing, We Have 10,000 Ranking Signals To Your 1,000. Love,
Google,” Search Engine Land (November 11, 2010), online:
<http://searchengineland.com/bing-10000-ranking-signals-google-55473>.

Sunstein Cass R., Republic.com 2 (Princeton and Oxford: Princeton University Press,
2007).

Tavani Herman, “Search Engines and Ethics” in Edward N. Zalta (red.), Spring ed., The
Stanford Encyclopedia of Philosophy (2014) online: Stanford Encyclopedia of Philosophy
<http://plato.stanford.edu/entries/ethics-search/>.

The Pew Research Center's Internet & American Life Project Winter 2012 Tracking Sur-
vey (January 20 - February 19, 2012), online: Pewlnternet.org
<http://www.pewintermet.org/files/old-

media/Files/Reports/2012/PIP_ Search Engine Use_2012.pdf>.

The Structure of the Mass Media and Government Regulation, Cliffs Notes, online:
<http://www.cliffsnotes.com/more-subjects/american-government/the-mass-media/the-
structure-of-the-mass-media-and-government-regulation>.

Webster Frank, “Introduction: Information Society Studies” in Webster Frank ed., The In-
formation Society Reader (London and New York: Routledge, 2004).

Weinberger David, Too Big To Know. Rethinking Knowledge Now That the Facts Aren't
the Facts, Experts Are Everywhere, and the Smartest Person in the Room Is the Room
(New York: Basic Books, 2011).

31
